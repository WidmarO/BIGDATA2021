{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Tarea 5 Algoritmos - Mineria de Datos.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## Examen Parcial de Mineria de Datos\n",
        "\n",
        "\n",
        "\n",
        "```\n",
        "# Estudiante : Widmar Raul Quispe Leon\n",
        "# Codigo     : 171259\n",
        "# Curso      : Mineria de Datos\n",
        "```\n",
        "\n"
      ],
      "metadata": {
        "id": "d4yuKQTyU5go"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9EctFXgDUCqq",
        "outputId": "6952bdf3-57f1-429f-83b2-5923491ff4fd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r0% [Working]\r            \rGet:1 https://cloud.r-project.org/bin/linux/ubuntu bionic-cran40/ InRelease [3,626 B]\n",
            "\r0% [Connecting to archive.ubuntu.com (91.189.88.152)] [Connecting to security.u\r0% [Connecting to archive.ubuntu.com (91.189.88.152)] [Connecting to security.u\r0% [1 InRelease gpgv 3,626 B] [Waiting for headers] [Connecting to security.ubu\r                                                                               \rHit:2 http://archive.ubuntu.com/ubuntu bionic InRelease\n",
            "\r0% [1 InRelease gpgv 3,626 B] [Waiting for headers] [Waiting for headers] [Wait\r                                                                               \rGet:3 http://ppa.launchpad.net/c2d4u.team/c2d4u4.0+/ubuntu bionic InRelease [15.9 kB]\n",
            "Ign:4 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  InRelease\n",
            "Get:5 http://security.ubuntu.com/ubuntu bionic-security InRelease [88.7 kB]\n",
            "Ign:6 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  InRelease\n",
            "Get:7 http://archive.ubuntu.com/ubuntu bionic-updates InRelease [88.7 kB]\n",
            "Hit:8 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  Release\n",
            "Hit:9 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  Release\n",
            "Hit:10 http://ppa.launchpad.net/cran/libgit2/ubuntu bionic InRelease\n",
            "Hit:11 http://archive.ubuntu.com/ubuntu bionic-backports InRelease\n",
            "Get:12 http://ppa.launchpad.net/deadsnakes/ppa/ubuntu bionic InRelease [15.9 kB]\n",
            "Get:13 http://ppa.launchpad.net/graphics-drivers/ppa/ubuntu bionic InRelease [21.3 kB]\n",
            "Get:14 http://ppa.launchpad.net/c2d4u.team/c2d4u4.0+/ubuntu bionic/main Sources [1,822 kB]\n",
            "Get:17 http://ppa.launchpad.net/c2d4u.team/c2d4u4.0+/ubuntu bionic/main amd64 Packages [934 kB]\n",
            "Get:18 http://security.ubuntu.com/ubuntu bionic-security/main amd64 Packages [2,489 kB]\n",
            "Get:19 http://security.ubuntu.com/ubuntu bionic-security/multiverse amd64 Packages [26.8 kB]\n",
            "Get:20 http://security.ubuntu.com/ubuntu bionic-security/universe amd64 Packages [1,459 kB]\n",
            "Get:21 http://security.ubuntu.com/ubuntu bionic-security/restricted amd64 Packages [716 kB]\n",
            "Get:22 http://archive.ubuntu.com/ubuntu bionic-updates/restricted amd64 Packages [749 kB]\n",
            "Get:23 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 Packages [2,929 kB]\n",
            "Get:24 http://archive.ubuntu.com/ubuntu bionic-updates/multiverse amd64 Packages [34.5 kB]\n",
            "Get:25 http://archive.ubuntu.com/ubuntu bionic-updates/universe amd64 Packages [2,238 kB]\n",
            "Get:26 http://ppa.launchpad.net/deadsnakes/ppa/ubuntu bionic/main amd64 Packages [45.3 kB]\n",
            "Get:27 http://ppa.launchpad.net/graphics-drivers/ppa/ubuntu bionic/main amd64 Packages [44.7 kB]\n",
            "Fetched 13.7 MB in 4s (3,097 kB/s)\n",
            "Reading package lists... Done\n",
            "spark-3.2.0-bin-hadoop2.7/\n",
            "spark-3.2.0-bin-hadoop2.7/NOTICE\n",
            "spark-3.2.0-bin-hadoop2.7/kubernetes/\n",
            "spark-3.2.0-bin-hadoop2.7/kubernetes/tests/\n",
            "spark-3.2.0-bin-hadoop2.7/kubernetes/tests/python_executable_check.py\n",
            "spark-3.2.0-bin-hadoop2.7/kubernetes/tests/autoscale.py\n",
            "spark-3.2.0-bin-hadoop2.7/kubernetes/tests/worker_memory_check.py\n",
            "spark-3.2.0-bin-hadoop2.7/kubernetes/tests/py_container_checks.py\n",
            "spark-3.2.0-bin-hadoop2.7/kubernetes/tests/decommissioning.py\n",
            "spark-3.2.0-bin-hadoop2.7/kubernetes/tests/pyfiles.py\n",
            "spark-3.2.0-bin-hadoop2.7/kubernetes/tests/decommissioning_cleanup.py\n",
            "spark-3.2.0-bin-hadoop2.7/kubernetes/dockerfiles/\n",
            "spark-3.2.0-bin-hadoop2.7/kubernetes/dockerfiles/spark/\n",
            "spark-3.2.0-bin-hadoop2.7/kubernetes/dockerfiles/spark/decom.sh\n",
            "spark-3.2.0-bin-hadoop2.7/kubernetes/dockerfiles/spark/entrypoint.sh\n",
            "spark-3.2.0-bin-hadoop2.7/kubernetes/dockerfiles/spark/bindings/\n",
            "spark-3.2.0-bin-hadoop2.7/kubernetes/dockerfiles/spark/bindings/R/\n",
            "spark-3.2.0-bin-hadoop2.7/kubernetes/dockerfiles/spark/bindings/R/Dockerfile\n",
            "spark-3.2.0-bin-hadoop2.7/kubernetes/dockerfiles/spark/bindings/python/\n",
            "spark-3.2.0-bin-hadoop2.7/kubernetes/dockerfiles/spark/bindings/python/Dockerfile\n",
            "spark-3.2.0-bin-hadoop2.7/kubernetes/dockerfiles/spark/Dockerfile\n",
            "spark-3.2.0-bin-hadoop2.7/jars/\n",
            "spark-3.2.0-bin-hadoop2.7/jars/jackson-xc-1.9.13.jar\n",
            "spark-3.2.0-bin-hadoop2.7/jars/RoaringBitmap-0.9.0.jar\n",
            "spark-3.2.0-bin-hadoop2.7/jars/commons-digester-1.8.jar\n",
            "spark-3.2.0-bin-hadoop2.7/jars/api-util-1.0.0-M20.jar\n",
            "spark-3.2.0-bin-hadoop2.7/jars/spark-graphx_2.12-3.2.0.jar\n",
            "spark-3.2.0-bin-hadoop2.7/jars/kubernetes-model-metrics-5.4.1.jar\n",
            "spark-3.2.0-bin-hadoop2.7/jars/commons-beanutils-1.9.4.jar\n",
            "spark-3.2.0-bin-hadoop2.7/jars/okhttp-3.12.12.jar\n",
            "spark-3.2.0-bin-hadoop2.7/jars/hive-shims-common-2.3.9.jar\n",
            "spark-3.2.0-bin-hadoop2.7/jars/spire_2.12-0.17.0.jar\n",
            "spark-3.2.0-bin-hadoop2.7/jars/logging-interceptor-3.12.12.jar\n",
            "spark-3.2.0-bin-hadoop2.7/jars/hive-serde-2.3.9.jar\n",
            "spark-3.2.0-bin-hadoop2.7/jars/hadoop-yarn-api-2.7.4.jar\n",
            "spark-3.2.0-bin-hadoop2.7/jars/zookeeper-3.6.2.jar\n",
            "spark-3.2.0-bin-hadoop2.7/jars/kryo-shaded-4.0.2.jar\n",
            "spark-3.2.0-bin-hadoop2.7/jars/hive-jdbc-2.3.9.jar\n",
            "spark-3.2.0-bin-hadoop2.7/jars/xercesImpl-2.12.0.jar\n",
            "spark-3.2.0-bin-hadoop2.7/jars/commons-logging-1.1.3.jar\n",
            "spark-3.2.0-bin-hadoop2.7/jars/commons-compiler-3.0.16.jar\n",
            "spark-3.2.0-bin-hadoop2.7/jars/jdo-api-3.0.1.jar\n",
            "spark-3.2.0-bin-hadoop2.7/jars/JLargeArrays-1.5.jar\n",
            "spark-3.2.0-bin-hadoop2.7/jars/jsp-api-2.1.jar\n",
            "spark-3.2.0-bin-hadoop2.7/jars/metrics-jvm-4.2.0.jar\n",
            "spark-3.2.0-bin-hadoop2.7/jars/httpcore-4.4.14.jar\n",
            "spark-3.2.0-bin-hadoop2.7/jars/commons-codec-1.15.jar\n",
            "spark-3.2.0-bin-hadoop2.7/jars/jcl-over-slf4j-1.7.30.jar\n",
            "spark-3.2.0-bin-hadoop2.7/jars/spark-repl_2.12-3.2.0.jar\n",
            "spark-3.2.0-bin-hadoop2.7/jars/apacheds-i18n-2.0.0-M15.jar\n",
            "spark-3.2.0-bin-hadoop2.7/jars/stax-api-1.0.1.jar\n",
            "spark-3.2.0-bin-hadoop2.7/jars/hive-storage-api-2.7.2.jar\n",
            "spark-3.2.0-bin-hadoop2.7/jars/hadoop-annotations-2.7.4.jar\n",
            "spark-3.2.0-bin-hadoop2.7/jars/guice-servlet-3.0.jar\n",
            "spark-3.2.0-bin-hadoop2.7/jars/zookeeper-jute-3.6.2.jar\n",
            "spark-3.2.0-bin-hadoop2.7/jars/spark-sketch_2.12-3.2.0.jar\n",
            "spark-3.2.0-bin-hadoop2.7/jars/kubernetes-model-policy-5.4.1.jar\n",
            "spark-3.2.0-bin-hadoop2.7/jars/jline-2.14.6.jar\n",
            "spark-3.2.0-bin-hadoop2.7/jars/jackson-dataformat-yaml-2.12.3.jar\n",
            "spark-3.2.0-bin-hadoop2.7/jars/kubernetes-model-coordination-5.4.1.jar\n",
            "spark-3.2.0-bin-hadoop2.7/jars/dropwizard-metrics-hadoop-metrics2-reporter-0.1.2.jar\n",
            "spark-3.2.0-bin-hadoop2.7/jars/spark-hive-thriftserver_2.12-3.2.0.jar\n",
            "spark-3.2.0-bin-hadoop2.7/jars/commons-pool-1.5.4.jar\n",
            "spark-3.2.0-bin-hadoop2.7/jars/metrics-json-4.2.0.jar\n",
            "spark-3.2.0-bin-hadoop2.7/jars/xbean-asm9-shaded-4.20.jar\n",
            "spark-3.2.0-bin-hadoop2.7/jars/cats-kernel_2.12-2.1.1.jar\n",
            "spark-3.2.0-bin-hadoop2.7/jars/jta-1.1.jar\n",
            "spark-3.2.0-bin-hadoop2.7/jars/spark-streaming_2.12-3.2.0.jar\n",
            "spark-3.2.0-bin-hadoop2.7/jars/kubernetes-model-extensions-5.4.1.jar\n",
            "spark-3.2.0-bin-hadoop2.7/jars/istack-commons-runtime-3.0.8.jar\n",
            "spark-3.2.0-bin-hadoop2.7/jars/hadoop-hdfs-2.7.4.jar\n",
            "spark-3.2.0-bin-hadoop2.7/jars/kubernetes-client-5.4.1.jar\n",
            "spark-3.2.0-bin-hadoop2.7/jars/hive-common-2.3.9.jar\n",
            "spark-3.2.0-bin-hadoop2.7/jars/kubernetes-model-discovery-5.4.1.jar\n",
            "spark-3.2.0-bin-hadoop2.7/jars/objenesis-2.6.jar\n",
            "spark-3.2.0-bin-hadoop2.7/jars/commons-collections-3.2.2.jar\n",
            "spark-3.2.0-bin-hadoop2.7/jars/audience-annotations-0.5.0.jar\n",
            "spark-3.2.0-bin-hadoop2.7/jars/jpam-1.1.jar\n",
            "spark-3.2.0-bin-hadoop2.7/jars/jakarta.annotation-api-1.3.5.jar\n",
            "spark-3.2.0-bin-hadoop2.7/jars/xmlenc-0.52.jar\n",
            "spark-3.2.0-bin-hadoop2.7/jars/lapack-2.2.0.jar\n",
            "spark-3.2.0-bin-hadoop2.7/jars/spark-network-common_2.12-3.2.0.jar\n",
            "spark-3.2.0-bin-hadoop2.7/jars/jersey-common-2.34.jar\n",
            "spark-3.2.0-bin-hadoop2.7/jars/api-asn1-api-1.0.0-M20.jar\n",
            "spark-3.2.0-bin-hadoop2.7/jars/kubernetes-model-core-5.4.1.jar\n",
            "spark-3.2.0-bin-hadoop2.7/jars/hadoop-mapreduce-client-common-2.7.4.jar\n",
            "spark-3.2.0-bin-hadoop2.7/jars/jaxb-api-2.2.11.jar\n",
            "spark-3.2.0-bin-hadoop2.7/jars/snakeyaml-1.27.jar\n",
            "spark-3.2.0-bin-hadoop2.7/jars/curator-client-2.7.1.jar\n",
            "spark-3.2.0-bin-hadoop2.7/jars/javax.inject-1.jar\n",
            "spark-3.2.0-bin-hadoop2.7/jars/avro-1.10.2.jar\n",
            "spark-3.2.0-bin-hadoop2.7/jars/antlr4-runtime-4.8.jar\n",
            "spark-3.2.0-bin-hadoop2.7/jars/avro-mapred-1.10.2.jar\n",
            "spark-3.2.0-bin-hadoop2.7/jars/kubernetes-model-node-5.4.1.jar\n",
            "spark-3.2.0-bin-hadoop2.7/jars/javax.jdo-3.2.0-m3.jar\n",
            "spark-3.2.0-bin-hadoop2.7/jars/hadoop-auth-2.7.4.jar\n",
            "spark-3.2.0-bin-hadoop2.7/jars/commons-io-2.4.jar\n",
            "spark-3.2.0-bin-hadoop2.7/jars/paranamer-2.8.jar\n",
            "spark-3.2.0-bin-hadoop2.7/jars/spark-core_2.12-3.2.0.jar\n",
            "spark-3.2.0-bin-hadoop2.7/jars/flatbuffers-java-1.9.0.jar\n",
            "spark-3.2.0-bin-hadoop2.7/jars/json4s-core_2.12-3.7.0-M11.jar\n",
            "spark-3.2.0-bin-hadoop2.7/jars/spark-catalyst_2.12-3.2.0.jar\n",
            "spark-3.2.0-bin-hadoop2.7/jars/stream-2.9.6.jar\n",
            "spark-3.2.0-bin-hadoop2.7/jars/kubernetes-model-flowcontrol-5.4.1.jar\n",
            "spark-3.2.0-bin-hadoop2.7/jars/hive-shims-2.3.9.jar\n",
            "spark-3.2.0-bin-hadoop2.7/jars/datanucleus-api-jdo-4.2.4.jar\n",
            "spark-3.2.0-bin-hadoop2.7/jars/gson-2.2.4.jar\n",
            "spark-3.2.0-bin-hadoop2.7/jars/jersey-container-servlet-2.34.jar\n",
            "spark-3.2.0-bin-hadoop2.7/jars/commons-compress-1.21.jar\n",
            "spark-3.2.0-bin-hadoop2.7/jars/xml-apis-1.4.01.jar\n",
            "spark-3.2.0-bin-hadoop2.7/jars/apacheds-kerberos-codec-2.0.0-M15.jar\n",
            "spark-3.2.0-bin-hadoop2.7/jars/metrics-graphite-4.2.0.jar\n",
            "spark-3.2.0-bin-hadoop2.7/jars/hadoop-mapreduce-client-shuffle-2.7.4.jar\n",
            "spark-3.2.0-bin-hadoop2.7/jars/kubernetes-model-common-5.4.1.jar\n",
            "spark-3.2.0-bin-hadoop2.7/jars/opencsv-2.3.jar\n",
            "spark-3.2.0-bin-hadoop2.7/jars/hive-exec-2.3.9-core.jar\n",
            "spark-3.2.0-bin-hadoop2.7/jars/jsr305-3.0.0.jar\n",
            "spark-3.2.0-bin-hadoop2.7/jars/macro-compat_2.12-1.1.1.jar\n",
            "spark-3.2.0-bin-hadoop2.7/jars/kubernetes-model-rbac-5.4.1.jar\n",
            "spark-3.2.0-bin-hadoop2.7/jars/derby-10.14.2.0.jar\n",
            "spark-3.2.0-bin-hadoop2.7/jars/jackson-annotations-2.12.3.jar\n",
            "spark-3.2.0-bin-hadoop2.7/jars/commons-dbcp-1.4.jar\n",
            "spark-3.2.0-bin-hadoop2.7/jars/scala-reflect-2.12.15.jar\n",
            "spark-3.2.0-bin-hadoop2.7/jars/okio-1.14.0.jar\n",
            "spark-3.2.0-bin-hadoop2.7/jars/kubernetes-model-certificates-5.4.1.jar\n",
            "spark-3.2.0-bin-hadoop2.7/jars/hk2-api-2.6.1.jar\n",
            "spark-3.2.0-bin-hadoop2.7/jars/spark-unsafe_2.12-3.2.0.jar\n",
            "spark-3.2.0-bin-hadoop2.7/jars/mesos-1.4.0-shaded-protobuf.jar\n",
            "spark-3.2.0-bin-hadoop2.7/jars/hive-shims-0.23-2.3.9.jar\n",
            "spark-3.2.0-bin-hadoop2.7/jars/jakarta.servlet-api-4.0.3.jar\n",
            "spark-3.2.0-bin-hadoop2.7/jars/commons-lang3-3.12.0.jar\n",
            "spark-3.2.0-bin-hadoop2.7/jars/automaton-1.11-8.jar\n",
            "spark-3.2.0-bin-hadoop2.7/jars/commons-lang-2.6.jar\n",
            "spark-3.2.0-bin-hadoop2.7/jars/ivy-2.5.0.jar\n",
            "spark-3.2.0-bin-hadoop2.7/jars/hk2-utils-2.6.1.jar\n",
            "spark-3.2.0-bin-hadoop2.7/jars/parquet-jackson-1.12.1.jar\n",
            "spark-3.2.0-bin-hadoop2.7/jars/velocity-1.5.jar\n",
            "spark-3.2.0-bin-hadoop2.7/jars/htrace-core-3.1.0-incubating.jar\n",
            "spark-3.2.0-bin-hadoop2.7/jars/jul-to-slf4j-1.7.30.jar\n",
            "spark-3.2.0-bin-hadoop2.7/jars/httpclient-4.5.13.jar\n",
            "spark-3.2.0-bin-hadoop2.7/jars/JTransforms-3.1.jar\n",
            "spark-3.2.0-bin-hadoop2.7/jars/spark-mllib-local_2.12-3.2.0.jar\n",
            "spark-3.2.0-bin-hadoop2.7/jars/json4s-scalap_2.12-3.7.0-M11.jar\n",
            "spark-3.2.0-bin-hadoop2.7/jars/zstd-jni-1.5.0-4.jar\n",
            "spark-3.2.0-bin-hadoop2.7/jars/jersey-server-2.34.jar\n",
            "spark-3.2.0-bin-hadoop2.7/jars/jetty-sslengine-6.1.26.jar\n",
            "spark-3.2.0-bin-hadoop2.7/jars/aircompressor-0.21.jar\n",
            "spark-3.2.0-bin-hadoop2.7/jars/commons-math3-3.4.1.jar\n",
            "spark-3.2.0-bin-hadoop2.7/jars/joda-time-2.10.10.jar\n",
            "spark-3.2.0-bin-hadoop2.7/jars/jakarta.validation-api-2.0.2.jar\n",
            "spark-3.2.0-bin-hadoop2.7/jars/kubernetes-model-batch-5.4.1.jar\n",
            "spark-3.2.0-bin-hadoop2.7/jars/spark-mesos_2.12-3.2.0.jar\n",
            "spark-3.2.0-bin-hadoop2.7/jars/slf4j-log4j12-1.7.30.jar\n",
            "spark-3.2.0-bin-hadoop2.7/jars/hadoop-mapreduce-client-app-2.7.4.jar\n",
            "spark-3.2.0-bin-hadoop2.7/jars/slf4j-api-1.7.30.jar\n",
            "spark-3.2.0-bin-hadoop2.7/jars/guava-14.0.1.jar\n",
            "spark-3.2.0-bin-hadoop2.7/jars/spark-mllib_2.12-3.2.0.jar\n",
            "spark-3.2.0-bin-hadoop2.7/jars/kubernetes-model-autoscaling-5.4.1.jar\n",
            "spark-3.2.0-bin-hadoop2.7/jars/zjsonpatch-0.3.0.jar\n",
            "spark-3.2.0-bin-hadoop2.7/jars/hive-service-rpc-3.1.2.jar\n",
            "spark-3.2.0-bin-hadoop2.7/jars/kubernetes-model-networking-5.4.1.jar\n",
            "spark-3.2.0-bin-hadoop2.7/jars/spark-launcher_2.12-3.2.0.jar\n",
            "spark-3.2.0-bin-hadoop2.7/jars/shapeless_2.12-2.3.3.jar\n",
            "spark-3.2.0-bin-hadoop2.7/jars/kubernetes-model-events-5.4.1.jar\n",
            "spark-3.2.0-bin-hadoop2.7/jars/parquet-hadoop-1.12.1.jar\n",
            "spark-3.2.0-bin-hadoop2.7/jars/oro-2.0.8.jar\n",
            "spark-3.2.0-bin-hadoop2.7/jars/metrics-jmx-4.2.0.jar\n",
            "spark-3.2.0-bin-hadoop2.7/jars/arrow-memory-netty-2.0.0.jar\n",
            "spark-3.2.0-bin-hadoop2.7/jars/hadoop-yarn-client-2.7.4.jar\n",
            "spark-3.2.0-bin-hadoop2.7/jars/libfb303-0.9.3.jar\n",
            "spark-3.2.0-bin-hadoop2.7/jars/core-1.1.2.jar\n",
            "spark-3.2.0-bin-hadoop2.7/jars/orc-core-1.6.11.jar\n",
            "spark-3.2.0-bin-hadoop2.7/jars/datanucleus-rdbms-4.1.19.jar\n",
            "spark-3.2.0-bin-hadoop2.7/jars/super-csv-2.2.0.jar\n",
            "spark-3.2.0-bin-hadoop2.7/jars/compress-lzf-1.0.3.jar\n",
            "spark-3.2.0-bin-hadoop2.7/jars/scala-compiler-2.12.15.jar\n",
            "spark-3.2.0-bin-hadoop2.7/jars/aopalliance-1.0.jar\n",
            "spark-3.2.0-bin-hadoop2.7/jars/osgi-resource-locator-1.0.3.jar\n",
            "spark-3.2.0-bin-hadoop2.7/jars/hadoop-yarn-server-common-2.7.4.jar\n",
            "spark-3.2.0-bin-hadoop2.7/jars/json-1.8.jar\n",
            "spark-3.2.0-bin-hadoop2.7/jars/antlr-runtime-3.5.2.jar\n",
            "spark-3.2.0-bin-hadoop2.7/jars/threeten-extra-1.5.0.jar\n",
            "spark-3.2.0-bin-hadoop2.7/jars/jetty-6.1.26.jar\n",
            "spark-3.2.0-bin-hadoop2.7/jars/scala-library-2.12.15.jar\n",
            "spark-3.2.0-bin-hadoop2.7/jars/arrow-vector-2.0.0.jar\n",
            "spark-3.2.0-bin-hadoop2.7/jars/lz4-java-1.7.1.jar\n",
            "spark-3.2.0-bin-hadoop2.7/jars/snappy-java-1.1.8.4.jar\n",
            "spark-3.2.0-bin-hadoop2.7/jars/hadoop-client-2.7.4.jar\n",
            "spark-3.2.0-bin-hadoop2.7/jars/activation-1.1.1.jar\n",
            "spark-3.2.0-bin-hadoop2.7/jars/annotations-17.0.0.jar\n",
            "spark-3.2.0-bin-hadoop2.7/jars/commons-crypto-1.1.0.jar\n",
            "spark-3.2.0-bin-hadoop2.7/jars/libthrift-0.12.0.jar\n",
            "spark-3.2.0-bin-hadoop2.7/jars/HikariCP-2.5.1.jar\n",
            "spark-3.2.0-bin-hadoop2.7/jars/generex-1.0.2.jar\n",
            "spark-3.2.0-bin-hadoop2.7/jars/jackson-module-scala_2.12-2.12.3.jar\n",
            "spark-3.2.0-bin-hadoop2.7/jars/leveldbjni-all-1.8.jar\n",
            "spark-3.2.0-bin-hadoop2.7/jars/orc-shims-1.6.11.jar\n",
            "spark-3.2.0-bin-hadoop2.7/jars/jaxb-runtime-2.3.2.jar\n",
            "spark-3.2.0-bin-hadoop2.7/jars/rocksdbjni-6.20.3.jar\n",
            "spark-3.2.0-bin-hadoop2.7/jars/kubernetes-model-scheduling-5.4.1.jar\n",
            "spark-3.2.0-bin-hadoop2.7/jars/kubernetes-model-admissionregistration-5.4.1.jar\n",
            "spark-3.2.0-bin-hadoop2.7/jars/jackson-datatype-jsr310-2.11.2.jar\n",
            "spark-3.2.0-bin-hadoop2.7/jars/commons-httpclient-3.1.jar\n",
            "spark-3.2.0-bin-hadoop2.7/jars/shims-0.9.0.jar\n",
            "spark-3.2.0-bin-hadoop2.7/jars/jackson-core-asl-1.9.13.jar\n",
            "spark-3.2.0-bin-hadoop2.7/jars/hive-cli-2.3.9.jar\n",
            "spark-3.2.0-bin-hadoop2.7/jars/kubernetes-model-storageclass-5.4.1.jar\n",
            "spark-3.2.0-bin-hadoop2.7/jars/hive-beeline-2.3.9.jar\n",
            "spark-3.2.0-bin-hadoop2.7/jars/scala-xml_2.12-1.2.0.jar\n",
            "spark-3.2.0-bin-hadoop2.7/jars/hk2-locator-2.6.1.jar\n",
            "spark-3.2.0-bin-hadoop2.7/jars/hadoop-common-2.7.4.jar\n",
            "spark-3.2.0-bin-hadoop2.7/jars/spark-sql_2.12-3.2.0.jar\n",
            "spark-3.2.0-bin-hadoop2.7/jars/curator-recipes-2.7.1.jar\n",
            "spark-3.2.0-bin-hadoop2.7/jars/kubernetes-model-apiextensions-5.4.1.jar\n",
            "spark-3.2.0-bin-hadoop2.7/jars/jackson-mapper-asl-1.9.13.jar\n",
            "spark-3.2.0-bin-hadoop2.7/jars/ST4-4.0.4.jar\n",
            "spark-3.2.0-bin-hadoop2.7/jars/spark-kubernetes_2.12-3.2.0.jar\n",
            "spark-3.2.0-bin-hadoop2.7/jars/chill_2.12-0.10.0.jar\n",
            "spark-3.2.0-bin-hadoop2.7/jars/json4s-jackson_2.12-3.7.0-M11.jar\n",
            "spark-3.2.0-bin-hadoop2.7/jars/spark-yarn_2.12-3.2.0.jar\n",
            "spark-3.2.0-bin-hadoop2.7/jars/breeze-macros_2.12-1.2.jar\n",
            "spark-3.2.0-bin-hadoop2.7/jars/spark-tags_2.12-3.2.0.jar\n",
            "spark-3.2.0-bin-hadoop2.7/jars/spark-network-shuffle_2.12-3.2.0.jar\n",
            "spark-3.2.0-bin-hadoop2.7/jars/xz-1.8.jar\n",
            "spark-3.2.0-bin-hadoop2.7/jars/commons-configuration-1.6.jar\n",
            "spark-3.2.0-bin-hadoop2.7/jars/jackson-databind-2.12.3.jar\n",
            "spark-3.2.0-bin-hadoop2.7/jars/blas-2.2.0.jar\n",
            "spark-3.2.0-bin-hadoop2.7/jars/minlog-1.3.0.jar\n",
            "spark-3.2.0-bin-hadoop2.7/jars/jersey-hk2-2.34.jar\n",
            "spark-3.2.0-bin-hadoop2.7/jars/jakarta.ws.rs-api-2.1.6.jar\n",
            "spark-3.2.0-bin-hadoop2.7/jars/jersey-container-servlet-core-2.34.jar\n",
            "spark-3.2.0-bin-hadoop2.7/jars/aopalliance-repackaged-2.6.1.jar\n",
            "spark-3.2.0-bin-hadoop2.7/jars/spark-tags_2.12-3.2.0-tests.jar\n",
            "spark-3.2.0-bin-hadoop2.7/jars/parquet-common-1.12.1.jar\n",
            "spark-3.2.0-bin-hadoop2.7/jars/bonecp-0.8.0.RELEASE.jar\n",
            "spark-3.2.0-bin-hadoop2.7/jars/jodd-core-3.5.2.jar\n",
            "spark-3.2.0-bin-hadoop2.7/jars/hadoop-yarn-server-web-proxy-2.7.4.jar\n",
            "spark-3.2.0-bin-hadoop2.7/jars/spire-util_2.12-0.17.0.jar\n",
            "spark-3.2.0-bin-hadoop2.7/jars/spark-hive_2.12-3.2.0.jar\n",
            "spark-3.2.0-bin-hadoop2.7/jars/protobuf-java-2.5.0.jar\n",
            "spark-3.2.0-bin-hadoop2.7/jars/jersey-client-2.34.jar\n",
            "spark-3.2.0-bin-hadoop2.7/jars/commons-net-3.1.jar\n",
            "spark-3.2.0-bin-hadoop2.7/jars/hadoop-mapreduce-client-jobclient-2.7.4.jar\n",
            "spark-3.2.0-bin-hadoop2.7/jars/datanucleus-core-4.1.17.jar\n",
            "spark-3.2.0-bin-hadoop2.7/jars/jackson-jaxrs-1.9.13.jar\n",
            "spark-3.2.0-bin-hadoop2.7/jars/janino-3.0.16.jar\n",
            "spark-3.2.0-bin-hadoop2.7/jars/spire-platform_2.12-0.17.0.jar\n",
            "spark-3.2.0-bin-hadoop2.7/jars/javolution-5.5.1.jar\n",
            "spark-3.2.0-bin-hadoop2.7/jars/transaction-api-1.1.jar\n",
            "spark-3.2.0-bin-hadoop2.7/jars/jackson-core-2.12.3.jar\n",
            "spark-3.2.0-bin-hadoop2.7/jars/commons-cli-1.2.jar\n",
            "spark-3.2.0-bin-hadoop2.7/jars/jakarta.inject-2.6.1.jar\n",
            "spark-3.2.0-bin-hadoop2.7/jars/hive-llap-common-2.3.9.jar\n",
            "spark-3.2.0-bin-hadoop2.7/jars/tink-1.6.0.jar\n",
            "spark-3.2.0-bin-hadoop2.7/jars/jakarta.xml.bind-api-2.3.2.jar\n",
            "spark-3.2.0-bin-hadoop2.7/jars/algebra_2.12-2.0.1.jar\n",
            "spark-3.2.0-bin-hadoop2.7/jars/metrics-core-4.2.0.jar\n",
            "spark-3.2.0-bin-hadoop2.7/jars/hadoop-yarn-common-2.7.4.jar\n",
            "spark-3.2.0-bin-hadoop2.7/jars/curator-framework-2.7.1.jar\n",
            "spark-3.2.0-bin-hadoop2.7/jars/arpack_combined_all-0.1.jar\n",
            "spark-3.2.0-bin-hadoop2.7/jars/hive-vector-code-gen-2.3.9.jar\n",
            "spark-3.2.0-bin-hadoop2.7/jars/orc-mapreduce-1.6.11.jar\n",
            "spark-3.2.0-bin-hadoop2.7/jars/parquet-format-structures-1.12.1.jar\n",
            "spark-3.2.0-bin-hadoop2.7/jars/arrow-format-2.0.0.jar\n",
            "spark-3.2.0-bin-hadoop2.7/jars/json4s-ast_2.12-3.7.0-M11.jar\n",
            "spark-3.2.0-bin-hadoop2.7/jars/parquet-column-1.12.1.jar\n",
            "spark-3.2.0-bin-hadoop2.7/jars/javassist-3.25.0-GA.jar\n",
            "spark-3.2.0-bin-hadoop2.7/jars/scala-collection-compat_2.12-2.1.1.jar\n",
            "spark-3.2.0-bin-hadoop2.7/jars/arrow-memory-core-2.0.0.jar\n",
            "spark-3.2.0-bin-hadoop2.7/jars/jetty-util-6.1.26.jar\n",
            "spark-3.2.0-bin-hadoop2.7/jars/arpack-2.2.0.jar\n",
            "spark-3.2.0-bin-hadoop2.7/jars/guice-3.0.jar\n",
            "spark-3.2.0-bin-hadoop2.7/jars/commons-text-1.6.jar\n",
            "spark-3.2.0-bin-hadoop2.7/jars/hadoop-mapreduce-client-core-2.7.4.jar\n",
            "spark-3.2.0-bin-hadoop2.7/jars/parquet-encoding-1.12.1.jar\n",
            "spark-3.2.0-bin-hadoop2.7/jars/kubernetes-model-apps-5.4.1.jar\n",
            "spark-3.2.0-bin-hadoop2.7/jars/univocity-parsers-2.9.1.jar\n",
            "spark-3.2.0-bin-hadoop2.7/jars/hive-shims-scheduler-2.3.9.jar\n",
            "spark-3.2.0-bin-hadoop2.7/jars/breeze_2.12-1.2.jar\n",
            "spark-3.2.0-bin-hadoop2.7/jars/pyrolite-4.30.jar\n",
            "spark-3.2.0-bin-hadoop2.7/jars/chill-java-0.10.0.jar\n",
            "spark-3.2.0-bin-hadoop2.7/jars/spire-macros_2.12-0.17.0.jar\n",
            "spark-3.2.0-bin-hadoop2.7/jars/spark-kvstore_2.12-3.2.0.jar\n",
            "spark-3.2.0-bin-hadoop2.7/jars/log4j-1.2.17.jar\n",
            "spark-3.2.0-bin-hadoop2.7/jars/netty-all-4.1.68.Final.jar\n",
            "spark-3.2.0-bin-hadoop2.7/jars/avro-ipc-1.10.2.jar\n",
            "spark-3.2.0-bin-hadoop2.7/jars/scala-parser-combinators_2.12-1.1.2.jar\n",
            "spark-3.2.0-bin-hadoop2.7/jars/hive-metastore-2.3.9.jar\n",
            "spark-3.2.0-bin-hadoop2.7/jars/py4j-0.10.9.2.jar\n",
            "spark-3.2.0-bin-hadoop2.7/data/\n",
            "spark-3.2.0-bin-hadoop2.7/data/mllib/\n",
            "spark-3.2.0-bin-hadoop2.7/data/mllib/sample_lda_data.txt\n",
            "spark-3.2.0-bin-hadoop2.7/data/mllib/sample_libsvm_data.txt\n",
            "spark-3.2.0-bin-hadoop2.7/data/mllib/sample_svm_data.txt\n",
            "spark-3.2.0-bin-hadoop2.7/data/mllib/sample_multiclass_classification_data.txt\n",
            "spark-3.2.0-bin-hadoop2.7/data/mllib/sample_linear_regression_data.txt\n",
            "spark-3.2.0-bin-hadoop2.7/data/mllib/sample_lda_libsvm_data.txt\n",
            "spark-3.2.0-bin-hadoop2.7/data/mllib/sample_fpgrowth.txt\n",
            "spark-3.2.0-bin-hadoop2.7/data/mllib/sample_binary_classification_data.txt\n",
            "spark-3.2.0-bin-hadoop2.7/data/mllib/sample_isotonic_regression_libsvm_data.txt\n",
            "spark-3.2.0-bin-hadoop2.7/data/mllib/iris_libsvm.txt\n",
            "spark-3.2.0-bin-hadoop2.7/data/mllib/sample_movielens_data.txt\n",
            "spark-3.2.0-bin-hadoop2.7/data/mllib/als/\n",
            "spark-3.2.0-bin-hadoop2.7/data/mllib/als/test.data\n",
            "spark-3.2.0-bin-hadoop2.7/data/mllib/als/sample_movielens_ratings.txt\n",
            "spark-3.2.0-bin-hadoop2.7/data/mllib/sample_kmeans_data.txt\n",
            "spark-3.2.0-bin-hadoop2.7/data/mllib/pic_data.txt\n",
            "spark-3.2.0-bin-hadoop2.7/data/mllib/images/\n",
            "spark-3.2.0-bin-hadoop2.7/data/mllib/images/origin/\n",
            "spark-3.2.0-bin-hadoop2.7/data/mllib/images/origin/kittens/\n",
            "spark-3.2.0-bin-hadoop2.7/data/mllib/images/origin/kittens/54893.jpg\n",
            "spark-3.2.0-bin-hadoop2.7/data/mllib/images/origin/kittens/not-image.txt\n",
            "spark-3.2.0-bin-hadoop2.7/data/mllib/images/origin/kittens/DP802813.jpg\n",
            "spark-3.2.0-bin-hadoop2.7/data/mllib/images/origin/kittens/29.5.a_b_EGDP022204.jpg\n",
            "spark-3.2.0-bin-hadoop2.7/data/mllib/images/origin/kittens/DP153539.jpg\n",
            "spark-3.2.0-bin-hadoop2.7/data/mllib/images/origin/license.txt\n",
            "spark-3.2.0-bin-hadoop2.7/data/mllib/images/origin/multi-channel/\n",
            "spark-3.2.0-bin-hadoop2.7/data/mllib/images/origin/multi-channel/BGRA.png\n",
            "spark-3.2.0-bin-hadoop2.7/data/mllib/images/origin/multi-channel/BGRA_alpha_60.png\n",
            "spark-3.2.0-bin-hadoop2.7/data/mllib/images/origin/multi-channel/grayscale.jpg\n",
            "spark-3.2.0-bin-hadoop2.7/data/mllib/images/origin/multi-channel/chr30.4.184.jpg\n",
            "spark-3.2.0-bin-hadoop2.7/data/mllib/images/partitioned/\n",
            "spark-3.2.0-bin-hadoop2.7/data/mllib/images/partitioned/cls=multichannel/\n",
            "spark-3.2.0-bin-hadoop2.7/data/mllib/images/partitioned/cls=multichannel/date=2018-01/\n",
            "spark-3.2.0-bin-hadoop2.7/data/mllib/images/partitioned/cls=multichannel/date=2018-01/BGRA.png\n",
            "spark-3.2.0-bin-hadoop2.7/data/mllib/images/partitioned/cls=multichannel/date=2018-01/BGRA_alpha_60.png\n",
            "spark-3.2.0-bin-hadoop2.7/data/mllib/images/partitioned/cls=multichannel/date=2018-02/\n",
            "spark-3.2.0-bin-hadoop2.7/data/mllib/images/partitioned/cls=multichannel/date=2018-02/grayscale.jpg\n",
            "spark-3.2.0-bin-hadoop2.7/data/mllib/images/partitioned/cls=multichannel/date=2018-02/chr30.4.184.jpg\n",
            "spark-3.2.0-bin-hadoop2.7/data/mllib/images/partitioned/cls=kittens/\n",
            "spark-3.2.0-bin-hadoop2.7/data/mllib/images/partitioned/cls=kittens/date=2018-01/\n",
            "spark-3.2.0-bin-hadoop2.7/data/mllib/images/partitioned/cls=kittens/date=2018-01/not-image.txt\n",
            "spark-3.2.0-bin-hadoop2.7/data/mllib/images/partitioned/cls=kittens/date=2018-01/29.5.a_b_EGDP022204.jpg\n",
            "spark-3.2.0-bin-hadoop2.7/data/mllib/images/partitioned/cls=kittens/date=2018-02/\n",
            "spark-3.2.0-bin-hadoop2.7/data/mllib/images/partitioned/cls=kittens/date=2018-02/54893.jpg\n",
            "spark-3.2.0-bin-hadoop2.7/data/mllib/images/partitioned/cls=kittens/date=2018-02/DP802813.jpg\n",
            "spark-3.2.0-bin-hadoop2.7/data/mllib/images/partitioned/cls=kittens/date=2018-02/DP153539.jpg\n",
            "spark-3.2.0-bin-hadoop2.7/data/mllib/images/license.txt\n",
            "spark-3.2.0-bin-hadoop2.7/data/mllib/ridge-data/\n",
            "spark-3.2.0-bin-hadoop2.7/data/mllib/ridge-data/lpsa.data\n",
            "spark-3.2.0-bin-hadoop2.7/data/mllib/kmeans_data.txt\n",
            "spark-3.2.0-bin-hadoop2.7/data/mllib/streaming_kmeans_data_test.txt\n",
            "spark-3.2.0-bin-hadoop2.7/data/mllib/pagerank_data.txt\n",
            "spark-3.2.0-bin-hadoop2.7/data/mllib/gmm_data.txt\n",
            "spark-3.2.0-bin-hadoop2.7/data/graphx/\n",
            "spark-3.2.0-bin-hadoop2.7/data/graphx/users.txt\n",
            "spark-3.2.0-bin-hadoop2.7/data/graphx/followers.txt\n",
            "spark-3.2.0-bin-hadoop2.7/data/streaming/\n",
            "spark-3.2.0-bin-hadoop2.7/data/streaming/AFINN-111.txt\n",
            "spark-3.2.0-bin-hadoop2.7/R/\n",
            "spark-3.2.0-bin-hadoop2.7/R/lib/\n",
            "spark-3.2.0-bin-hadoop2.7/R/lib/sparkr.zip\n",
            "spark-3.2.0-bin-hadoop2.7/R/lib/SparkR/\n",
            "spark-3.2.0-bin-hadoop2.7/R/lib/SparkR/tests/\n",
            "spark-3.2.0-bin-hadoop2.7/R/lib/SparkR/tests/testthat/\n",
            "spark-3.2.0-bin-hadoop2.7/R/lib/SparkR/tests/testthat/test_basic.R\n",
            "spark-3.2.0-bin-hadoop2.7/R/lib/SparkR/DESCRIPTION\n",
            "spark-3.2.0-bin-hadoop2.7/R/lib/SparkR/profile/\n",
            "spark-3.2.0-bin-hadoop2.7/R/lib/SparkR/profile/shell.R\n",
            "spark-3.2.0-bin-hadoop2.7/R/lib/SparkR/profile/general.R\n",
            "spark-3.2.0-bin-hadoop2.7/R/lib/SparkR/INDEX\n",
            "spark-3.2.0-bin-hadoop2.7/R/lib/SparkR/Meta/\n",
            "spark-3.2.0-bin-hadoop2.7/R/lib/SparkR/Meta/features.rds\n",
            "spark-3.2.0-bin-hadoop2.7/R/lib/SparkR/Meta/links.rds\n",
            "spark-3.2.0-bin-hadoop2.7/R/lib/SparkR/Meta/nsInfo.rds\n",
            "spark-3.2.0-bin-hadoop2.7/R/lib/SparkR/Meta/package.rds\n",
            "spark-3.2.0-bin-hadoop2.7/R/lib/SparkR/Meta/Rd.rds\n",
            "spark-3.2.0-bin-hadoop2.7/R/lib/SparkR/Meta/hsearch.rds\n",
            "spark-3.2.0-bin-hadoop2.7/R/lib/SparkR/help/\n",
            "spark-3.2.0-bin-hadoop2.7/R/lib/SparkR/help/SparkR.rdb\n",
            "spark-3.2.0-bin-hadoop2.7/R/lib/SparkR/help/aliases.rds\n",
            "spark-3.2.0-bin-hadoop2.7/R/lib/SparkR/help/SparkR.rdx\n",
            "spark-3.2.0-bin-hadoop2.7/R/lib/SparkR/help/AnIndex\n",
            "spark-3.2.0-bin-hadoop2.7/R/lib/SparkR/help/paths.rds\n",
            "spark-3.2.0-bin-hadoop2.7/R/lib/SparkR/R/\n",
            "spark-3.2.0-bin-hadoop2.7/R/lib/SparkR/R/SparkR.rdb\n",
            "spark-3.2.0-bin-hadoop2.7/R/lib/SparkR/R/SparkR.rdx\n",
            "spark-3.2.0-bin-hadoop2.7/R/lib/SparkR/R/SparkR\n",
            "spark-3.2.0-bin-hadoop2.7/R/lib/SparkR/NAMESPACE\n",
            "spark-3.2.0-bin-hadoop2.7/R/lib/SparkR/html/\n",
            "spark-3.2.0-bin-hadoop2.7/R/lib/SparkR/html/00Index.html\n",
            "spark-3.2.0-bin-hadoop2.7/R/lib/SparkR/html/R.css\n",
            "spark-3.2.0-bin-hadoop2.7/R/lib/SparkR/worker/\n",
            "spark-3.2.0-bin-hadoop2.7/R/lib/SparkR/worker/worker.R\n",
            "spark-3.2.0-bin-hadoop2.7/R/lib/SparkR/worker/daemon.R\n",
            "spark-3.2.0-bin-hadoop2.7/README.md\n",
            "spark-3.2.0-bin-hadoop2.7/RELEASE\n",
            "spark-3.2.0-bin-hadoop2.7/yarn/\n",
            "spark-3.2.0-bin-hadoop2.7/yarn/spark-3.2.0-yarn-shuffle.jar\n",
            "spark-3.2.0-bin-hadoop2.7/LICENSE\n",
            "spark-3.2.0-bin-hadoop2.7/sbin/\n",
            "spark-3.2.0-bin-hadoop2.7/sbin/start-workers.sh\n",
            "spark-3.2.0-bin-hadoop2.7/sbin/stop-mesos-shuffle-service.sh\n",
            "spark-3.2.0-bin-hadoop2.7/sbin/start-master.sh\n",
            "spark-3.2.0-bin-hadoop2.7/sbin/workers.sh\n",
            "spark-3.2.0-bin-hadoop2.7/sbin/start-worker.sh\n",
            "spark-3.2.0-bin-hadoop2.7/sbin/spark-config.sh\n",
            "spark-3.2.0-bin-hadoop2.7/sbin/start-history-server.sh\n",
            "spark-3.2.0-bin-hadoop2.7/sbin/start-slaves.sh\n",
            "spark-3.2.0-bin-hadoop2.7/sbin/spark-daemon.sh\n",
            "spark-3.2.0-bin-hadoop2.7/sbin/stop-worker.sh\n",
            "spark-3.2.0-bin-hadoop2.7/sbin/stop-mesos-dispatcher.sh\n",
            "spark-3.2.0-bin-hadoop2.7/sbin/decommission-worker.sh\n",
            "spark-3.2.0-bin-hadoop2.7/sbin/start-mesos-shuffle-service.sh\n",
            "spark-3.2.0-bin-hadoop2.7/sbin/decommission-slave.sh\n",
            "spark-3.2.0-bin-hadoop2.7/sbin/slaves.sh\n",
            "spark-3.2.0-bin-hadoop2.7/sbin/stop-history-server.sh\n",
            "spark-3.2.0-bin-hadoop2.7/sbin/start-thriftserver.sh\n",
            "spark-3.2.0-bin-hadoop2.7/sbin/stop-thriftserver.sh\n",
            "spark-3.2.0-bin-hadoop2.7/sbin/start-slave.sh\n",
            "spark-3.2.0-bin-hadoop2.7/sbin/start-all.sh\n",
            "spark-3.2.0-bin-hadoop2.7/sbin/stop-slave.sh\n",
            "spark-3.2.0-bin-hadoop2.7/sbin/spark-daemons.sh\n",
            "spark-3.2.0-bin-hadoop2.7/sbin/stop-workers.sh\n",
            "spark-3.2.0-bin-hadoop2.7/sbin/stop-slaves.sh\n",
            "spark-3.2.0-bin-hadoop2.7/sbin/stop-all.sh\n",
            "spark-3.2.0-bin-hadoop2.7/sbin/start-mesos-dispatcher.sh\n",
            "spark-3.2.0-bin-hadoop2.7/sbin/stop-master.sh\n",
            "spark-3.2.0-bin-hadoop2.7/examples/\n",
            "spark-3.2.0-bin-hadoop2.7/examples/src/\n",
            "spark-3.2.0-bin-hadoop2.7/examples/src/main/\n",
            "spark-3.2.0-bin-hadoop2.7/examples/src/main/r/\n",
            "spark-3.2.0-bin-hadoop2.7/examples/src/main/r/ml/\n",
            "spark-3.2.0-bin-hadoop2.7/examples/src/main/r/ml/survreg.R\n",
            "spark-3.2.0-bin-hadoop2.7/examples/src/main/r/ml/glm.R\n",
            "spark-3.2.0-bin-hadoop2.7/examples/src/main/r/ml/prefixSpan.R\n",
            "spark-3.2.0-bin-hadoop2.7/examples/src/main/r/ml/lm_with_elastic_net.R\n",
            "spark-3.2.0-bin-hadoop2.7/examples/src/main/r/ml/powerIterationClustering.R\n",
            "spark-3.2.0-bin-hadoop2.7/examples/src/main/r/ml/lda.R\n",
            "spark-3.2.0-bin-hadoop2.7/examples/src/main/r/ml/kstest.R\n",
            "spark-3.2.0-bin-hadoop2.7/examples/src/main/r/ml/isoreg.R\n",
            "spark-3.2.0-bin-hadoop2.7/examples/src/main/r/ml/ml.R\n",
            "spark-3.2.0-bin-hadoop2.7/examples/src/main/r/ml/naiveBayes.R\n",
            "spark-3.2.0-bin-hadoop2.7/examples/src/main/r/ml/fmRegressor.R\n",
            "spark-3.2.0-bin-hadoop2.7/examples/src/main/r/ml/mlp.R\n",
            "spark-3.2.0-bin-hadoop2.7/examples/src/main/r/ml/als.R\n",
            "spark-3.2.0-bin-hadoop2.7/examples/src/main/r/ml/kmeans.R\n",
            "spark-3.2.0-bin-hadoop2.7/examples/src/main/r/ml/svmLinear.R\n",
            "spark-3.2.0-bin-hadoop2.7/examples/src/main/r/ml/fmClassifier.R\n",
            "spark-3.2.0-bin-hadoop2.7/examples/src/main/r/ml/logit.R\n",
            "spark-3.2.0-bin-hadoop2.7/examples/src/main/r/ml/randomForest.R\n",
            "spark-3.2.0-bin-hadoop2.7/examples/src/main/r/ml/gbt.R\n",
            "spark-3.2.0-bin-hadoop2.7/examples/src/main/r/ml/decisionTree.R\n",
            "spark-3.2.0-bin-hadoop2.7/examples/src/main/r/ml/gaussianMixture.R\n",
            "spark-3.2.0-bin-hadoop2.7/examples/src/main/r/ml/bisectingKmeans.R\n",
            "spark-3.2.0-bin-hadoop2.7/examples/src/main/r/ml/fpm.R\n",
            "spark-3.2.0-bin-hadoop2.7/examples/src/main/r/dataframe.R\n",
            "spark-3.2.0-bin-hadoop2.7/examples/src/main/r/RSparkSQLExample.R\n",
            "spark-3.2.0-bin-hadoop2.7/examples/src/main/r/data-manipulation.R\n",
            "spark-3.2.0-bin-hadoop2.7/examples/src/main/r/streaming/\n",
            "spark-3.2.0-bin-hadoop2.7/examples/src/main/r/streaming/structured_network_wordcount.R\n",
            "spark-3.2.0-bin-hadoop2.7/examples/src/main/scala/\n",
            "spark-3.2.0-bin-hadoop2.7/examples/src/main/scala/org/\n",
            "spark-3.2.0-bin-hadoop2.7/examples/src/main/scala/org/apache/\n",
            "spark-3.2.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/\n",
            "spark-3.2.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/\n",
            "spark-3.2.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/SparkPageRank.scala\n",
            "spark-3.2.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/SkewedGroupByTest.scala\n",
            "spark-3.2.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/AccumulatorMetricsTest.scala\n",
            "spark-3.2.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/HdfsTest.scala\n",
            "spark-3.2.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/\n",
            "spark-3.2.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/Word2VecExample.scala\n",
            "spark-3.2.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/DeveloperApiExample.scala\n",
            "spark-3.2.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/MinHashLSHExample.scala\n",
            "spark-3.2.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/IndexToStringExample.scala\n",
            "spark-3.2.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/BisectingKMeansExample.scala\n",
            "spark-3.2.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/CorrelationExample.scala\n",
            "spark-3.2.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/MulticlassLogisticRegressionWithElasticNetExample.scala\n",
            "spark-3.2.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/VectorSizeHintExample.scala\n",
            "spark-3.2.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/NGramExample.scala\n",
            "spark-3.2.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/BucketedRandomProjectionLSHExample.scala\n",
            "spark-3.2.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/BinarizerExample.scala\n",
            "spark-3.2.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/RandomForestExample.scala\n",
            "spark-3.2.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/StandardScalerExample.scala\n",
            "spark-3.2.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/LogisticRegressionExample.scala\n",
            "spark-3.2.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/FeatureHasherExample.scala\n",
            "spark-3.2.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/OneVsRestExample.scala\n",
            "spark-3.2.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/StopWordsRemoverExample.scala\n",
            "spark-3.2.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/LinearSVCExample.scala\n",
            "spark-3.2.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/GaussianMixtureExample.scala\n",
            "spark-3.2.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/MaxAbsScalerExample.scala\n",
            "spark-3.2.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/VarianceThresholdSelectorExample.scala\n",
            "spark-3.2.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/GBTExample.scala\n",
            "spark-3.2.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/IsotonicRegressionExample.scala\n",
            "spark-3.2.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/ModelSelectionViaCrossValidationExample.scala\n",
            "spark-3.2.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/EstimatorTransformerParamExample.scala\n",
            "spark-3.2.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/DecisionTreeRegressionExample.scala\n",
            "spark-3.2.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/RandomForestRegressorExample.scala\n",
            "spark-3.2.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/PrefixSpanExample.scala\n",
            "spark-3.2.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/KMeansExample.scala\n",
            "spark-3.2.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/ModelSelectionViaTrainValidationSplitExample.scala\n",
            "spark-3.2.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/LogisticRegressionSummaryExample.scala\n",
            "spark-3.2.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/MultilayerPerceptronClassifierExample.scala\n",
            "spark-3.2.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/PCAExample.scala\n",
            "spark-3.2.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/DCTExample.scala\n",
            "spark-3.2.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/FPGrowthExample.scala\n",
            "spark-3.2.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/ElementwiseProductExample.scala\n",
            "spark-3.2.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/GeneralizedLinearRegressionExample.scala\n",
            "spark-3.2.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/UnivariateFeatureSelectorExample.scala\n",
            "spark-3.2.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/CountVectorizerExample.scala\n",
            "spark-3.2.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/MinMaxScalerExample.scala\n",
            "spark-3.2.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/ChiSquareTestExample.scala\n",
            "spark-3.2.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/LogisticRegressionWithElasticNetExample.scala\n",
            "spark-3.2.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/FMRegressorExample.scala\n",
            "spark-3.2.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/VectorSlicerExample.scala\n",
            "spark-3.2.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/LinearRegressionExample.scala\n",
            "spark-3.2.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/StringIndexerExample.scala\n",
            "spark-3.2.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/GradientBoostedTreeRegressorExample.scala\n",
            "spark-3.2.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/ALSExample.scala\n",
            "spark-3.2.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/DecisionTreeClassificationExample.scala\n",
            "spark-3.2.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/PolynomialExpansionExample.scala\n",
            "spark-3.2.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/FMClassifierExample.scala\n",
            "spark-3.2.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/UnaryTransformerExample.scala\n",
            "spark-3.2.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/ImputerExample.scala\n",
            "spark-3.2.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/TokenizerExample.scala\n",
            "spark-3.2.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/DecisionTreeExample.scala\n",
            "spark-3.2.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/GradientBoostedTreeClassifierExample.scala\n",
            "spark-3.2.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/PowerIterationClusteringExample.scala\n",
            "spark-3.2.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/SQLTransformerExample.scala\n",
            "spark-3.2.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/SummarizerExample.scala\n",
            "spark-3.2.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/DataFrameExample.scala\n",
            "spark-3.2.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/BucketizerExample.scala\n",
            "spark-3.2.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/TfIdfExample.scala\n",
            "spark-3.2.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/AFTSurvivalRegressionExample.scala\n",
            "spark-3.2.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/QuantileDiscretizerExample.scala\n",
            "spark-3.2.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/OneHotEncoderExample.scala\n",
            "spark-3.2.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/PipelineExample.scala\n",
            "spark-3.2.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/InteractionExample.scala\n",
            "spark-3.2.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/LDAExample.scala\n",
            "spark-3.2.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/RFormulaExample.scala\n",
            "spark-3.2.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/VectorIndexerExample.scala\n",
            "spark-3.2.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/VectorAssemblerExample.scala\n",
            "spark-3.2.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/NormalizerExample.scala\n",
            "spark-3.2.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/ChiSqSelectorExample.scala\n",
            "spark-3.2.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/NaiveBayesExample.scala\n",
            "spark-3.2.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/RandomForestClassifierExample.scala\n",
            "spark-3.2.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/LinearRegressionWithElasticNetExample.scala\n",
            "spark-3.2.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/RobustScalerExample.scala\n",
            "spark-3.2.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/LogQuery.scala\n",
            "spark-3.2.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/SparkRemoteFileTest.scala\n",
            "spark-3.2.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ExceptionHandlingTest.scala\n",
            "spark-3.2.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/pythonconverters/\n",
            "spark-3.2.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/pythonconverters/AvroConverters.scala\n",
            "spark-3.2.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/BroadcastTest.scala\n",
            "spark-3.2.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/SparkHdfsLR.scala\n",
            "spark-3.2.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/mllib/\n",
            "spark-3.2.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/mllib/Word2VecExample.scala\n",
            "spark-3.2.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/mllib/GradientBoostedTreesRunner.scala\n",
            "spark-3.2.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/mllib/RandomRDDGeneration.scala\n",
            "spark-3.2.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/mllib/PMMLModelExportExample.scala\n",
            "spark-3.2.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/mllib/BisectingKMeansExample.scala\n",
            "spark-3.2.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/mllib/DecisionTreeRunner.scala\n",
            "spark-3.2.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/mllib/MultiLabelMetricsExample.scala\n",
            "spark-3.2.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/mllib/CorrelationsExample.scala\n",
            "spark-3.2.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/mllib/LBFGSExample.scala\n",
            "spark-3.2.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/mllib/TFIDFExample.scala\n",
            "spark-3.2.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/mllib/StandardScalerExample.scala\n",
            "spark-3.2.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/mllib/LogisticRegressionWithLBFGSExample.scala\n",
            "spark-3.2.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/mllib/StreamingTestExample.scala\n",
            "spark-3.2.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/mllib/BinaryClassification.scala\n",
            "spark-3.2.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/mllib/DenseKMeans.scala\n",
            "spark-3.2.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/mllib/GradientBoostingClassificationExample.scala\n",
            "spark-3.2.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/mllib/RankingMetricsExample.scala\n",
            "spark-3.2.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/mllib/GaussianMixtureExample.scala\n",
            "spark-3.2.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/mllib/MultivariateSummarizer.scala\n",
            "spark-3.2.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/mllib/IsotonicRegressionExample.scala\n",
            "spark-3.2.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/mllib/PCAOnSourceVectorExample.scala\n",
            "spark-3.2.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/mllib/Correlations.scala\n",
            "spark-3.2.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/mllib/HypothesisTestingExample.scala\n",
            "spark-3.2.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/mllib/DecisionTreeRegressionExample.scala\n",
            "spark-3.2.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/mllib/AssociationRulesExample.scala\n",
            "spark-3.2.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/mllib/StreamingLogisticRegression.scala\n",
            "spark-3.2.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/mllib/SVDExample.scala\n",
            "spark-3.2.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/mllib/PrefixSpanExample.scala\n",
            "spark-3.2.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/mllib/KMeansExample.scala\n",
            "spark-3.2.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/mllib/SparseNaiveBayes.scala\n",
            "spark-3.2.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/mllib/AbstractParams.scala\n",
            "spark-3.2.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/mllib/BinaryClassificationMetricsExample.scala\n",
            "spark-3.2.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/mllib/SampledRDDs.scala\n",
            "spark-3.2.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/mllib/FPGrowthExample.scala\n",
            "spark-3.2.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/mllib/ElementwiseProductExample.scala\n",
            "spark-3.2.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/mllib/RecommendationExample.scala\n",
            "spark-3.2.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/mllib/TallSkinnySVD.scala\n",
            "spark-3.2.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/mllib/HypothesisTestingKolmogorovSmirnovTestExample.scala\n",
            "spark-3.2.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/mllib/GradientBoostingRegressionExample.scala\n",
            "spark-3.2.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/mllib/StreamingKMeansExample.scala\n",
            "spark-3.2.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/mllib/CosineSimilarity.scala\n",
            "spark-3.2.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/mllib/RandomForestRegressionExample.scala\n",
            "spark-3.2.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/mllib/StreamingLinearRegressionExample.scala\n",
            "spark-3.2.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/mllib/StratifiedSamplingExample.scala\n",
            "spark-3.2.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/mllib/DecisionTreeClassificationExample.scala\n",
            "spark-3.2.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/mllib/TallSkinnyPCA.scala\n",
            "spark-3.2.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/mllib/RandomForestClassificationExample.scala\n",
            "spark-3.2.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/mllib/SimpleFPGrowth.scala\n",
            "spark-3.2.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/mllib/LatentDirichletAllocationExample.scala\n",
            "spark-3.2.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/mllib/KernelDensityEstimationExample.scala\n",
            "spark-3.2.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/mllib/PowerIterationClusteringExample.scala\n",
            "spark-3.2.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/mllib/SVMWithSGDExample.scala\n",
            "spark-3.2.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/mllib/LDAExample.scala\n",
            "spark-3.2.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/mllib/MovieLensALS.scala\n",
            "spark-3.2.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/mllib/NormalizerExample.scala\n",
            "spark-3.2.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/mllib/MulticlassMetricsExample.scala\n",
            "spark-3.2.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/mllib/ChiSqSelectorExample.scala\n",
            "spark-3.2.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/mllib/SummaryStatisticsExample.scala\n",
            "spark-3.2.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/mllib/PCAOnRowMatrixExample.scala\n",
            "spark-3.2.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/mllib/NaiveBayesExample.scala\n",
            "spark-3.2.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/SparkTC.scala\n",
            "spark-3.2.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/DriverSubmissionTest.scala\n",
            "spark-3.2.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/MultiBroadcastTest.scala\n",
            "spark-3.2.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/SparkLR.scala\n",
            "spark-3.2.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/SparkPi.scala\n",
            "spark-3.2.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/graphx/\n",
            "spark-3.2.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/graphx/ConnectedComponentsExample.scala\n",
            "spark-3.2.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/graphx/LiveJournalPageRank.scala\n",
            "spark-3.2.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/graphx/AggregateMessagesExample.scala\n",
            "spark-3.2.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/graphx/SSSPExample.scala\n",
            "spark-3.2.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/graphx/SynthBenchmark.scala\n",
            "spark-3.2.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/graphx/TriangleCountingExample.scala\n",
            "spark-3.2.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/graphx/PageRankExample.scala\n",
            "spark-3.2.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/graphx/ComprehensiveExample.scala\n",
            "spark-3.2.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/graphx/Analytics.scala\n",
            "spark-3.2.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/SparkKMeans.scala\n",
            "spark-3.2.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/streaming/\n",
            "spark-3.2.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/streaming/clickstream/\n",
            "spark-3.2.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/streaming/clickstream/PageViewGenerator.scala\n",
            "spark-3.2.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/streaming/clickstream/PageViewStream.scala\n",
            "spark-3.2.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/streaming/DirectKafkaWordCount.scala\n",
            "spark-3.2.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/streaming/HdfsWordCount.scala\n",
            "spark-3.2.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/streaming/DirectKerberizedKafkaWordCount.scala\n",
            "spark-3.2.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/streaming/RecoverableNetworkWordCount.scala\n",
            "spark-3.2.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/streaming/NetworkWordCount.scala\n",
            "spark-3.2.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/streaming/QueueStream.scala\n",
            "spark-3.2.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/streaming/SqlNetworkWordCount.scala\n",
            "spark-3.2.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/streaming/CustomReceiver.scala\n",
            "spark-3.2.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/streaming/RawNetworkGrep.scala\n",
            "spark-3.2.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/streaming/StatefulNetworkWordCount.scala\n",
            "spark-3.2.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/streaming/StreamingExamples.scala\n",
            "spark-3.2.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/LocalLR.scala\n",
            "spark-3.2.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/LocalKMeans.scala\n",
            "spark-3.2.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/GroupByTest.scala\n",
            "spark-3.2.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/LocalALS.scala\n",
            "spark-3.2.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/sql/\n",
            "spark-3.2.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/sql/SimpleTypedAggregator.scala\n",
            "spark-3.2.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/sql/UserDefinedUntypedAggregation.scala\n",
            "spark-3.2.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/sql/hive/\n",
            "spark-3.2.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/sql/hive/SparkHiveExample.scala\n",
            "spark-3.2.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/sql/RDDRelation.scala\n",
            "spark-3.2.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/sql/SparkSQLExample.scala\n",
            "spark-3.2.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/sql/SQLDataSourceExample.scala\n",
            "spark-3.2.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/sql/streaming/\n",
            "spark-3.2.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/sql/streaming/StructuredKerberizedKafkaWordCount.scala\n",
            "spark-3.2.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/sql/streaming/StructuredComplexSessionization.scala\n",
            "spark-3.2.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/sql/streaming/StructuredNetworkWordCount.scala\n",
            "spark-3.2.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/sql/streaming/StructuredNetworkWordCountWindowed.scala\n",
            "spark-3.2.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/sql/streaming/StructuredKafkaWordCount.scala\n",
            "spark-3.2.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/sql/streaming/StructuredSessionization.scala\n",
            "spark-3.2.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/sql/UserDefinedTypedAggregation.scala\n",
            "spark-3.2.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/sql/UserDefinedScalar.scala\n",
            "spark-3.2.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/sql/jdbc/\n",
            "spark-3.2.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/sql/jdbc/ExampleJdbcConnectionProvider.scala\n",
            "spark-3.2.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/SimpleSkewedGroupByTest.scala\n",
            "spark-3.2.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/extensions/\n",
            "spark-3.2.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/extensions/SparkSessionExtensionsTest.scala\n",
            "spark-3.2.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/extensions/SessionExtensionsWithoutLoader.scala\n",
            "spark-3.2.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/extensions/SessionExtensionsWithLoader.scala\n",
            "spark-3.2.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/extensions/AgeExample.scala\n",
            "spark-3.2.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/LocalFileLR.scala\n",
            "spark-3.2.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/LocalPi.scala\n",
            "spark-3.2.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/DFSReadWriteTest.scala\n",
            "spark-3.2.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/SparkALS.scala\n",
            "spark-3.2.0-bin-hadoop2.7/examples/src/main/resources/\n",
            "spark-3.2.0-bin-hadoop2.7/examples/src/main/resources/people.json\n",
            "spark-3.2.0-bin-hadoop2.7/examples/src/main/resources/users.avro\n",
            "spark-3.2.0-bin-hadoop2.7/examples/src/main/resources/people.csv\n",
            "spark-3.2.0-bin-hadoop2.7/examples/src/main/resources/users.parquet\n",
            "spark-3.2.0-bin-hadoop2.7/examples/src/main/resources/META-INF/\n",
            "spark-3.2.0-bin-hadoop2.7/examples/src/main/resources/META-INF/services/\n",
            "spark-3.2.0-bin-hadoop2.7/examples/src/main/resources/META-INF/services/org.apache.spark.sql.SparkSessionExtensionsProvider\n",
            "spark-3.2.0-bin-hadoop2.7/examples/src/main/resources/META-INF/services/org.apache.spark.sql.jdbc.JdbcConnectionProvider\n",
            "spark-3.2.0-bin-hadoop2.7/examples/src/main/resources/users.orc\n",
            "spark-3.2.0-bin-hadoop2.7/examples/src/main/resources/dir1/\n",
            "spark-3.2.0-bin-hadoop2.7/examples/src/main/resources/dir1/file1.parquet\n",
            "spark-3.2.0-bin-hadoop2.7/examples/src/main/resources/dir1/dir2/\n",
            "spark-3.2.0-bin-hadoop2.7/examples/src/main/resources/dir1/dir2/file2.parquet\n",
            "spark-3.2.0-bin-hadoop2.7/examples/src/main/resources/dir1/file3.json\n",
            "spark-3.2.0-bin-hadoop2.7/examples/src/main/resources/user.avsc\n",
            "spark-3.2.0-bin-hadoop2.7/examples/src/main/resources/full_user.avsc\n",
            "spark-3.2.0-bin-hadoop2.7/examples/src/main/resources/kv1.txt\n",
            "spark-3.2.0-bin-hadoop2.7/examples/src/main/resources/people.txt\n",
            "spark-3.2.0-bin-hadoop2.7/examples/src/main/resources/employees.json\n",
            "spark-3.2.0-bin-hadoop2.7/examples/src/main/java/\n",
            "spark-3.2.0-bin-hadoop2.7/examples/src/main/java/org/\n",
            "spark-3.2.0-bin-hadoop2.7/examples/src/main/java/org/apache/\n",
            "spark-3.2.0-bin-hadoop2.7/examples/src/main/java/org/apache/spark/\n",
            "spark-3.2.0-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/\n",
            "spark-3.2.0-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/ml/\n",
            "spark-3.2.0-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/ml/JavaStringIndexerExample.java\n",
            "spark-3.2.0-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/ml/JavaChiSqSelectorExample.java\n",
            "spark-3.2.0-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/ml/JavaLabeledDocument.java\n",
            "spark-3.2.0-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/ml/JavaLogisticRegressionWithElasticNetExample.java\n",
            "spark-3.2.0-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/ml/JavaPolynomialExpansionExample.java\n",
            "spark-3.2.0-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/ml/JavaTfIdfExample.java\n",
            "spark-3.2.0-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/ml/JavaBucketizerExample.java\n",
            "spark-3.2.0-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/ml/JavaLogisticRegressionSummaryExample.java\n",
            "spark-3.2.0-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/ml/JavaSummarizerExample.java\n",
            "spark-3.2.0-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/ml/JavaQuantileDiscretizerExample.java\n",
            "spark-3.2.0-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/ml/JavaBinarizerExample.java\n",
            "spark-3.2.0-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/ml/JavaOneHotEncoderExample.java\n",
            "spark-3.2.0-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/ml/JavaStandardScalerExample.java\n",
            "spark-3.2.0-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/ml/JavaDCTExample.java\n",
            "spark-3.2.0-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/ml/JavaDecisionTreeRegressionExample.java\n",
            "spark-3.2.0-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/ml/JavaRandomForestClassifierExample.java\n",
            "spark-3.2.0-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/ml/JavaOneVsRestExample.java\n",
            "spark-3.2.0-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/ml/JavaGeneralizedLinearRegressionExample.java\n",
            "spark-3.2.0-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/ml/JavaGaussianMixtureExample.java\n",
            "spark-3.2.0-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/ml/JavaWord2VecExample.java\n",
            "spark-3.2.0-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/ml/JavaNormalizerExample.java\n",
            "spark-3.2.0-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/ml/JavaLDAExample.java\n",
            "spark-3.2.0-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/ml/JavaCountVectorizerExample.java\n",
            "spark-3.2.0-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/ml/JavaMultilayerPerceptronClassifierExample.java\n",
            "spark-3.2.0-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/ml/JavaMinMaxScalerExample.java\n",
            "spark-3.2.0-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/ml/JavaCorrelationExample.java\n",
            "spark-3.2.0-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/ml/JavaNGramExample.java\n",
            "spark-3.2.0-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/ml/JavaImputerExample.java\n",
            "spark-3.2.0-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/ml/JavaMinHashLSHExample.java\n",
            "spark-3.2.0-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/ml/JavaVectorSizeHintExample.java\n",
            "spark-3.2.0-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/ml/JavaFMClassifierExample.java\n",
            "spark-3.2.0-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/ml/JavaFeatureHasherExample.java\n",
            "spark-3.2.0-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/ml/JavaModelSelectionViaTrainValidationSplitExample.java\n",
            "spark-3.2.0-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/ml/JavaSQLTransformerExample.java\n",
            "spark-3.2.0-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/ml/JavaKMeansExample.java\n",
            "spark-3.2.0-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/ml/JavaVectorAssemblerExample.java\n",
            "spark-3.2.0-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/ml/JavaGradientBoostedTreeRegressorExample.java\n",
            "spark-3.2.0-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/ml/JavaPrefixSpanExample.java\n",
            "spark-3.2.0-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/ml/JavaFMRegressorExample.java\n",
            "spark-3.2.0-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/ml/JavaNaiveBayesExample.java\n",
            "spark-3.2.0-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/ml/JavaMulticlassLogisticRegressionWithElasticNetExample.java\n",
            "spark-3.2.0-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/ml/JavaModelSelectionViaCrossValidationExample.java\n",
            "spark-3.2.0-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/ml/JavaDocument.java\n",
            "spark-3.2.0-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/ml/JavaUnivariateFeatureSelectorExample.java\n",
            "spark-3.2.0-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/ml/JavaGradientBoostedTreeClassifierExample.java\n",
            "spark-3.2.0-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/ml/JavaRandomForestRegressorExample.java\n",
            "spark-3.2.0-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/ml/JavaAFTSurvivalRegressionExample.java\n",
            "spark-3.2.0-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/ml/JavaIsotonicRegressionExample.java\n",
            "spark-3.2.0-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/ml/JavaElementwiseProductExample.java\n",
            "spark-3.2.0-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/ml/JavaALSExample.java\n",
            "spark-3.2.0-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/ml/JavaBucketedRandomProjectionLSHExample.java\n",
            "spark-3.2.0-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/ml/JavaVarianceThresholdSelectorExample.java\n",
            "spark-3.2.0-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/ml/JavaVectorSlicerExample.java\n",
            "spark-3.2.0-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/ml/JavaTokenizerExample.java\n",
            "spark-3.2.0-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/ml/JavaRFormulaExample.java\n",
            "spark-3.2.0-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/ml/JavaEstimatorTransformerParamExample.java\n",
            "spark-3.2.0-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/ml/JavaPowerIterationClusteringExample.java\n",
            "spark-3.2.0-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/ml/JavaBisectingKMeansExample.java\n",
            "spark-3.2.0-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/ml/JavaMaxAbsScalerExample.java\n",
            "spark-3.2.0-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/ml/JavaDecisionTreeClassificationExample.java\n",
            "spark-3.2.0-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/ml/JavaPCAExample.java\n",
            "spark-3.2.0-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/ml/JavaPipelineExample.java\n",
            "spark-3.2.0-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/ml/JavaStopWordsRemoverExample.java\n",
            "spark-3.2.0-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/ml/JavaIndexToStringExample.java\n",
            "spark-3.2.0-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/ml/JavaFPGrowthExample.java\n",
            "spark-3.2.0-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/ml/JavaVectorIndexerExample.java\n",
            "spark-3.2.0-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/ml/JavaInteractionExample.java\n",
            "spark-3.2.0-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/ml/JavaChiSquareTestExample.java\n",
            "spark-3.2.0-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/ml/JavaRobustScalerExample.java\n",
            "spark-3.2.0-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/ml/JavaLinearRegressionWithElasticNetExample.java\n",
            "spark-3.2.0-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/ml/JavaLinearSVCExample.java\n",
            "spark-3.2.0-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/JavaWordCount.java\n",
            "spark-3.2.0-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/JavaHdfsLR.java\n",
            "spark-3.2.0-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/JavaStatusTrackerDemo.java\n",
            "spark-3.2.0-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/mllib/\n",
            "spark-3.2.0-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/mllib/JavaChiSqSelectorExample.java\n",
            "spark-3.2.0-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/mllib/JavaHypothesisTestingKolmogorovSmirnovTestExample.java\n",
            "spark-3.2.0-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/mllib/JavaRandomForestRegressionExample.java\n",
            "spark-3.2.0-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/mllib/JavaSimpleFPGrowth.java\n",
            "spark-3.2.0-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/mllib/JavaRandomForestClassificationExample.java\n",
            "spark-3.2.0-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/mllib/JavaMulticlassClassificationMetricsExample.java\n",
            "spark-3.2.0-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/mllib/JavaKernelDensityEstimationExample.java\n",
            "spark-3.2.0-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/mllib/JavaSummaryStatisticsExample.java\n",
            "spark-3.2.0-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/mllib/JavaDecisionTreeRegressionExample.java\n",
            "spark-3.2.0-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/mllib/JavaGradientBoostingClassificationExample.java\n",
            "spark-3.2.0-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/mllib/JavaGaussianMixtureExample.java\n",
            "spark-3.2.0-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/mllib/JavaStratifiedSamplingExample.java\n",
            "spark-3.2.0-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/mllib/JavaSVDExample.java\n",
            "spark-3.2.0-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/mllib/JavaAssociationRulesExample.java\n",
            "spark-3.2.0-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/mllib/JavaALS.java\n",
            "spark-3.2.0-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/mllib/JavaKMeansExample.java\n",
            "spark-3.2.0-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/mllib/JavaSVMWithSGDExample.java\n",
            "spark-3.2.0-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/mllib/JavaPrefixSpanExample.java\n",
            "spark-3.2.0-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/mllib/JavaNaiveBayesExample.java\n",
            "spark-3.2.0-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/mllib/JavaLogisticRegressionWithLBFGSExample.java\n",
            "spark-3.2.0-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/mllib/JavaLBFGSExample.java\n",
            "spark-3.2.0-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/mllib/JavaGradientBoostingRegressionExample.java\n",
            "spark-3.2.0-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/mllib/JavaRankingMetricsExample.java\n",
            "spark-3.2.0-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/mllib/JavaIsotonicRegressionExample.java\n",
            "spark-3.2.0-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/mllib/JavaElementwiseProductExample.java\n",
            "spark-3.2.0-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/mllib/JavaCorrelationsExample.java\n",
            "spark-3.2.0-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/mllib/JavaPowerIterationClusteringExample.java\n",
            "spark-3.2.0-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/mllib/JavaBisectingKMeansExample.java\n",
            "spark-3.2.0-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/mllib/JavaDecisionTreeClassificationExample.java\n",
            "spark-3.2.0-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/mllib/JavaPCAExample.java\n",
            "spark-3.2.0-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/mllib/JavaRecommendationExample.java\n",
            "spark-3.2.0-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/mllib/JavaLatentDirichletAllocationExample.java\n",
            "spark-3.2.0-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/mllib/JavaHypothesisTestingExample.java\n",
            "spark-3.2.0-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/mllib/JavaMultiLabelClassificationMetricsExample.java\n",
            "spark-3.2.0-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/mllib/JavaBinaryClassificationMetricsExample.java\n",
            "spark-3.2.0-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/mllib/JavaStreamingTestExample.java\n",
            "spark-3.2.0-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/JavaPageRank.java\n",
            "spark-3.2.0-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/JavaLogQuery.java\n",
            "spark-3.2.0-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/streaming/\n",
            "spark-3.2.0-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/streaming/JavaStatefulNetworkWordCount.java\n",
            "spark-3.2.0-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/streaming/JavaCustomReceiver.java\n",
            "spark-3.2.0-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/streaming/JavaRecord.java\n",
            "spark-3.2.0-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/streaming/JavaNetworkWordCount.java\n",
            "spark-3.2.0-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/streaming/JavaDirectKerberizedKafkaWordCount.java\n",
            "spark-3.2.0-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/streaming/JavaDirectKafkaWordCount.java\n",
            "spark-3.2.0-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/streaming/JavaSqlNetworkWordCount.java\n",
            "spark-3.2.0-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/streaming/JavaRecoverableNetworkWordCount.java\n",
            "spark-3.2.0-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/streaming/JavaQueueStream.java\n",
            "spark-3.2.0-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/JavaSparkPi.java\n",
            "spark-3.2.0-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/sql/\n",
            "spark-3.2.0-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/sql/JavaUserDefinedScalar.java\n",
            "spark-3.2.0-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/sql/hive/\n",
            "spark-3.2.0-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/sql/hive/JavaSparkHiveExample.java\n",
            "spark-3.2.0-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/sql/JavaUserDefinedTypedAggregation.java\n",
            "spark-3.2.0-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/sql/JavaSQLDataSourceExample.java\n",
            "spark-3.2.0-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/sql/JavaSparkSQLExample.java\n",
            "spark-3.2.0-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/sql/JavaUserDefinedUntypedAggregation.java\n",
            "spark-3.2.0-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/sql/streaming/\n",
            "spark-3.2.0-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/sql/streaming/JavaStructuredKafkaWordCount.java\n",
            "spark-3.2.0-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/sql/streaming/JavaStructuredComplexSessionization.java\n",
            "spark-3.2.0-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/sql/streaming/JavaStructuredNetworkWordCountWindowed.java\n",
            "spark-3.2.0-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/sql/streaming/JavaStructuredSessionization.java\n",
            "spark-3.2.0-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/sql/streaming/JavaStructuredNetworkWordCount.java\n",
            "spark-3.2.0-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/sql/streaming/JavaStructuredKerberizedKafkaWordCount.java\n",
            "spark-3.2.0-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/JavaTC.java\n",
            "spark-3.2.0-bin-hadoop2.7/examples/src/main/scripts/\n",
            "spark-3.2.0-bin-hadoop2.7/examples/src/main/scripts/getGpusResources.sh\n",
            "spark-3.2.0-bin-hadoop2.7/examples/src/main/python/\n",
            "spark-3.2.0-bin-hadoop2.7/examples/src/main/python/kmeans.py\n",
            "spark-3.2.0-bin-hadoop2.7/examples/src/main/python/ml/\n",
            "spark-3.2.0-bin-hadoop2.7/examples/src/main/python/ml/dct_example.py\n",
            "spark-3.2.0-bin-hadoop2.7/examples/src/main/python/ml/count_vectorizer_example.py\n",
            "spark-3.2.0-bin-hadoop2.7/examples/src/main/python/ml/chisq_selector_example.py\n",
            "spark-3.2.0-bin-hadoop2.7/examples/src/main/python/ml/gradient_boosted_tree_regressor_example.py\n",
            "spark-3.2.0-bin-hadoop2.7/examples/src/main/python/ml/tf_idf_example.py\n",
            "spark-3.2.0-bin-hadoop2.7/examples/src/main/python/ml/cross_validator.py\n",
            "spark-3.2.0-bin-hadoop2.7/examples/src/main/python/ml/linear_regression_with_elastic_net.py\n",
            "spark-3.2.0-bin-hadoop2.7/examples/src/main/python/ml/normalizer_example.py\n",
            "spark-3.2.0-bin-hadoop2.7/examples/src/main/python/ml/fm_regressor_example.py\n",
            "spark-3.2.0-bin-hadoop2.7/examples/src/main/python/ml/univariate_feature_selector_example.py\n",
            "spark-3.2.0-bin-hadoop2.7/examples/src/main/python/ml/polynomial_expansion_example.py\n",
            "spark-3.2.0-bin-hadoop2.7/examples/src/main/python/ml/pipeline_example.py\n",
            "spark-3.2.0-bin-hadoop2.7/examples/src/main/python/ml/generalized_linear_regression_example.py\n",
            "spark-3.2.0-bin-hadoop2.7/examples/src/main/python/ml/multilayer_perceptron_classification.py\n",
            "spark-3.2.0-bin-hadoop2.7/examples/src/main/python/ml/bisecting_k_means_example.py\n",
            "spark-3.2.0-bin-hadoop2.7/examples/src/main/python/ml/chi_square_test_example.py\n",
            "spark-3.2.0-bin-hadoop2.7/examples/src/main/python/ml/train_validation_split.py\n",
            "spark-3.2.0-bin-hadoop2.7/examples/src/main/python/ml/stopwords_remover_example.py\n",
            "spark-3.2.0-bin-hadoop2.7/examples/src/main/python/ml/linearsvc.py\n",
            "spark-3.2.0-bin-hadoop2.7/examples/src/main/python/ml/lda_example.py\n",
            "spark-3.2.0-bin-hadoop2.7/examples/src/main/python/ml/random_forest_regressor_example.py\n",
            "spark-3.2.0-bin-hadoop2.7/examples/src/main/python/ml/vector_assembler_example.py\n",
            "spark-3.2.0-bin-hadoop2.7/examples/src/main/python/ml/word2vec_example.py\n",
            "spark-3.2.0-bin-hadoop2.7/examples/src/main/python/ml/string_indexer_example.py\n",
            "spark-3.2.0-bin-hadoop2.7/examples/src/main/python/ml/decision_tree_classification_example.py\n",
            "spark-3.2.0-bin-hadoop2.7/examples/src/main/python/ml/index_to_string_example.py\n",
            "spark-3.2.0-bin-hadoop2.7/examples/src/main/python/ml/bucketizer_example.py\n",
            "spark-3.2.0-bin-hadoop2.7/examples/src/main/python/ml/vector_size_hint_example.py\n",
            "spark-3.2.0-bin-hadoop2.7/examples/src/main/python/ml/vector_indexer_example.py\n",
            "spark-3.2.0-bin-hadoop2.7/examples/src/main/python/ml/tokenizer_example.py\n",
            "spark-3.2.0-bin-hadoop2.7/examples/src/main/python/ml/robust_scaler_example.py\n",
            "spark-3.2.0-bin-hadoop2.7/examples/src/main/python/ml/standard_scaler_example.py\n",
            "spark-3.2.0-bin-hadoop2.7/examples/src/main/python/ml/kmeans_example.py\n",
            "spark-3.2.0-bin-hadoop2.7/examples/src/main/python/ml/power_iteration_clustering_example.py\n",
            "spark-3.2.0-bin-hadoop2.7/examples/src/main/python/ml/naive_bayes_example.py\n",
            "spark-3.2.0-bin-hadoop2.7/examples/src/main/python/ml/pca_example.py\n",
            "spark-3.2.0-bin-hadoop2.7/examples/src/main/python/ml/aft_survival_regression.py\n",
            "spark-3.2.0-bin-hadoop2.7/examples/src/main/python/ml/min_max_scaler_example.py\n",
            "spark-3.2.0-bin-hadoop2.7/examples/src/main/python/ml/elementwise_product_example.py\n",
            "spark-3.2.0-bin-hadoop2.7/examples/src/main/python/ml/dataframe_example.py\n",
            "spark-3.2.0-bin-hadoop2.7/examples/src/main/python/ml/n_gram_example.py\n",
            "spark-3.2.0-bin-hadoop2.7/examples/src/main/python/ml/rformula_example.py\n",
            "spark-3.2.0-bin-hadoop2.7/examples/src/main/python/ml/one_vs_rest_example.py\n",
            "spark-3.2.0-bin-hadoop2.7/examples/src/main/python/ml/als_example.py\n",
            "spark-3.2.0-bin-hadoop2.7/examples/src/main/python/ml/onehot_encoder_example.py\n",
            "spark-3.2.0-bin-hadoop2.7/examples/src/main/python/ml/vector_slicer_example.py\n",
            "spark-3.2.0-bin-hadoop2.7/examples/src/main/python/ml/logistic_regression_with_elastic_net.py\n",
            "spark-3.2.0-bin-hadoop2.7/examples/src/main/python/ml/sql_transformer.py\n",
            "spark-3.2.0-bin-hadoop2.7/examples/src/main/python/ml/multiclass_logistic_regression_with_elastic_net.py\n",
            "spark-3.2.0-bin-hadoop2.7/examples/src/main/python/ml/summarizer_example.py\n",
            "spark-3.2.0-bin-hadoop2.7/examples/src/main/python/ml/quantile_discretizer_example.py\n",
            "spark-3.2.0-bin-hadoop2.7/examples/src/main/python/ml/feature_hasher_example.py\n",
            "spark-3.2.0-bin-hadoop2.7/examples/src/main/python/ml/imputer_example.py\n",
            "spark-3.2.0-bin-hadoop2.7/examples/src/main/python/ml/bucketed_random_projection_lsh_example.py\n",
            "spark-3.2.0-bin-hadoop2.7/examples/src/main/python/ml/estimator_transformer_param_example.py\n",
            "spark-3.2.0-bin-hadoop2.7/examples/src/main/python/ml/gradient_boosted_tree_classifier_example.py\n",
            "spark-3.2.0-bin-hadoop2.7/examples/src/main/python/ml/logistic_regression_summary_example.py\n",
            "spark-3.2.0-bin-hadoop2.7/examples/src/main/python/ml/decision_tree_regression_example.py\n",
            "spark-3.2.0-bin-hadoop2.7/examples/src/main/python/ml/fm_classifier_example.py\n",
            "spark-3.2.0-bin-hadoop2.7/examples/src/main/python/ml/gaussian_mixture_example.py\n",
            "spark-3.2.0-bin-hadoop2.7/examples/src/main/python/ml/fpgrowth_example.py\n",
            "spark-3.2.0-bin-hadoop2.7/examples/src/main/python/ml/variance_threshold_selector_example.py\n",
            "spark-3.2.0-bin-hadoop2.7/examples/src/main/python/ml/random_forest_classifier_example.py\n",
            "spark-3.2.0-bin-hadoop2.7/examples/src/main/python/ml/correlation_example.py\n",
            "spark-3.2.0-bin-hadoop2.7/examples/src/main/python/ml/min_hash_lsh_example.py\n",
            "spark-3.2.0-bin-hadoop2.7/examples/src/main/python/ml/binarizer_example.py\n",
            "spark-3.2.0-bin-hadoop2.7/examples/src/main/python/ml/prefixspan_example.py\n",
            "spark-3.2.0-bin-hadoop2.7/examples/src/main/python/ml/max_abs_scaler_example.py\n",
            "spark-3.2.0-bin-hadoop2.7/examples/src/main/python/ml/isotonic_regression_example.py\n",
            "spark-3.2.0-bin-hadoop2.7/examples/src/main/python/ml/interaction_example.py\n",
            "spark-3.2.0-bin-hadoop2.7/examples/src/main/python/logistic_regression.py\n",
            "spark-3.2.0-bin-hadoop2.7/examples/src/main/python/als.py\n",
            "spark-3.2.0-bin-hadoop2.7/examples/src/main/python/mllib/\n",
            "spark-3.2.0-bin-hadoop2.7/examples/src/main/python/mllib/word2vec.py\n",
            "spark-3.2.0-bin-hadoop2.7/examples/src/main/python/mllib/correlations_example.py\n",
            "spark-3.2.0-bin-hadoop2.7/examples/src/main/python/mllib/gradient_boosting_classification_example.py\n",
            "spark-3.2.0-bin-hadoop2.7/examples/src/main/python/mllib/kernel_density_estimation_example.py\n",
            "spark-3.2.0-bin-hadoop2.7/examples/src/main/python/mllib/hypothesis_testing_example.py\n",
            "spark-3.2.0-bin-hadoop2.7/examples/src/main/python/mllib/svd_example.py\n",
            "spark-3.2.0-bin-hadoop2.7/examples/src/main/python/mllib/kmeans.py\n",
            "spark-3.2.0-bin-hadoop2.7/examples/src/main/python/mllib/latent_dirichlet_allocation_example.py\n",
            "spark-3.2.0-bin-hadoop2.7/examples/src/main/python/mllib/tf_idf_example.py\n",
            "spark-3.2.0-bin-hadoop2.7/examples/src/main/python/mllib/correlations.py\n",
            "spark-3.2.0-bin-hadoop2.7/examples/src/main/python/mllib/random_forest_regression_example.py\n",
            "spark-3.2.0-bin-hadoop2.7/examples/src/main/python/mllib/normalizer_example.py\n",
            "spark-3.2.0-bin-hadoop2.7/examples/src/main/python/mllib/logistic_regression.py\n",
            "spark-3.2.0-bin-hadoop2.7/examples/src/main/python/mllib/multi_label_metrics_example.py\n",
            "spark-3.2.0-bin-hadoop2.7/examples/src/main/python/mllib/gradient_boosting_regression_example.py\n",
            "spark-3.2.0-bin-hadoop2.7/examples/src/main/python/mllib/random_forest_classification_example.py\n",
            "spark-3.2.0-bin-hadoop2.7/examples/src/main/python/mllib/streaming_linear_regression_example.py\n",
            "spark-3.2.0-bin-hadoop2.7/examples/src/main/python/mllib/sampled_rdds.py\n",
            "spark-3.2.0-bin-hadoop2.7/examples/src/main/python/mllib/bisecting_k_means_example.py\n",
            "spark-3.2.0-bin-hadoop2.7/examples/src/main/python/mllib/logistic_regression_with_lbfgs_example.py\n",
            "spark-3.2.0-bin-hadoop2.7/examples/src/main/python/mllib/k_means_example.py\n",
            "spark-3.2.0-bin-hadoop2.7/examples/src/main/python/mllib/streaming_k_means_example.py\n",
            "spark-3.2.0-bin-hadoop2.7/examples/src/main/python/mllib/word2vec_example.py\n",
            "spark-3.2.0-bin-hadoop2.7/examples/src/main/python/mllib/multi_class_metrics_example.py\n",
            "spark-3.2.0-bin-hadoop2.7/examples/src/main/python/mllib/decision_tree_classification_example.py\n",
            "spark-3.2.0-bin-hadoop2.7/examples/src/main/python/mllib/summary_statistics_example.py\n",
            "spark-3.2.0-bin-hadoop2.7/examples/src/main/python/mllib/binary_classification_metrics_example.py\n",
            "spark-3.2.0-bin-hadoop2.7/examples/src/main/python/mllib/standard_scaler_example.py\n",
            "spark-3.2.0-bin-hadoop2.7/examples/src/main/python/mllib/power_iteration_clustering_example.py\n",
            "spark-3.2.0-bin-hadoop2.7/examples/src/main/python/mllib/gaussian_mixture_model.py\n",
            "spark-3.2.0-bin-hadoop2.7/examples/src/main/python/mllib/regression_metrics_example.py\n",
            "spark-3.2.0-bin-hadoop2.7/examples/src/main/python/mllib/naive_bayes_example.py\n",
            "spark-3.2.0-bin-hadoop2.7/examples/src/main/python/mllib/elementwise_product_example.py\n",
            "spark-3.2.0-bin-hadoop2.7/examples/src/main/python/mllib/linear_regression_with_sgd_example.py\n",
            "spark-3.2.0-bin-hadoop2.7/examples/src/main/python/mllib/pca_rowmatrix_example.py\n",
            "spark-3.2.0-bin-hadoop2.7/examples/src/main/python/mllib/hypothesis_testing_kolmogorov_smirnov_test_example.py\n",
            "spark-3.2.0-bin-hadoop2.7/examples/src/main/python/mllib/random_rdd_generation.py\n",
            "spark-3.2.0-bin-hadoop2.7/examples/src/main/python/mllib/decision_tree_regression_example.py\n",
            "spark-3.2.0-bin-hadoop2.7/examples/src/main/python/mllib/gaussian_mixture_example.py\n",
            "spark-3.2.0-bin-hadoop2.7/examples/src/main/python/mllib/recommendation_example.py\n",
            "spark-3.2.0-bin-hadoop2.7/examples/src/main/python/mllib/fpgrowth_example.py\n",
            "spark-3.2.0-bin-hadoop2.7/examples/src/main/python/mllib/ranking_metrics_example.py\n",
            "spark-3.2.0-bin-hadoop2.7/examples/src/main/python/mllib/svm_with_sgd_example.py\n",
            "spark-3.2.0-bin-hadoop2.7/examples/src/main/python/mllib/isotonic_regression_example.py\n",
            "spark-3.2.0-bin-hadoop2.7/examples/src/main/python/mllib/stratified_sampling_example.py\n",
            "spark-3.2.0-bin-hadoop2.7/examples/src/main/python/wordcount.py\n",
            "spark-3.2.0-bin-hadoop2.7/examples/src/main/python/status_api_demo.py\n",
            "spark-3.2.0-bin-hadoop2.7/examples/src/main/python/pagerank.py\n",
            "spark-3.2.0-bin-hadoop2.7/examples/src/main/python/sort.py\n",
            "spark-3.2.0-bin-hadoop2.7/examples/src/main/python/transitive_closure.py\n",
            "spark-3.2.0-bin-hadoop2.7/examples/src/main/python/avro_inputformat.py\n",
            "spark-3.2.0-bin-hadoop2.7/examples/src/main/python/pi.py\n",
            "spark-3.2.0-bin-hadoop2.7/examples/src/main/python/streaming/\n",
            "spark-3.2.0-bin-hadoop2.7/examples/src/main/python/streaming/queue_stream.py\n",
            "spark-3.2.0-bin-hadoop2.7/examples/src/main/python/streaming/stateful_network_wordcount.py\n",
            "spark-3.2.0-bin-hadoop2.7/examples/src/main/python/streaming/network_wordjoinsentiments.py\n",
            "spark-3.2.0-bin-hadoop2.7/examples/src/main/python/streaming/sql_network_wordcount.py\n",
            "spark-3.2.0-bin-hadoop2.7/examples/src/main/python/streaming/network_wordcount.py\n",
            "spark-3.2.0-bin-hadoop2.7/examples/src/main/python/streaming/hdfs_wordcount.py\n",
            "spark-3.2.0-bin-hadoop2.7/examples/src/main/python/streaming/recoverable_network_wordcount.py\n",
            "spark-3.2.0-bin-hadoop2.7/examples/src/main/python/sql/\n",
            "spark-3.2.0-bin-hadoop2.7/examples/src/main/python/sql/datasource.py\n",
            "spark-3.2.0-bin-hadoop2.7/examples/src/main/python/sql/hive.py\n",
            "spark-3.2.0-bin-hadoop2.7/examples/src/main/python/sql/arrow.py\n",
            "spark-3.2.0-bin-hadoop2.7/examples/src/main/python/sql/streaming/\n",
            "spark-3.2.0-bin-hadoop2.7/examples/src/main/python/sql/streaming/structured_network_wordcount_windowed.py\n",
            "spark-3.2.0-bin-hadoop2.7/examples/src/main/python/sql/streaming/structured_network_wordcount.py\n",
            "spark-3.2.0-bin-hadoop2.7/examples/src/main/python/sql/streaming/structured_sessionization.py\n",
            "spark-3.2.0-bin-hadoop2.7/examples/src/main/python/sql/streaming/structured_kafka_wordcount.py\n",
            "spark-3.2.0-bin-hadoop2.7/examples/src/main/python/sql/basic.py\n",
            "spark-3.2.0-bin-hadoop2.7/examples/src/main/python/parquet_inputformat.py\n",
            "spark-3.2.0-bin-hadoop2.7/examples/jars/\n",
            "spark-3.2.0-bin-hadoop2.7/examples/jars/spark-examples_2.12-3.2.0.jar\n",
            "spark-3.2.0-bin-hadoop2.7/examples/jars/scopt_2.12-3.7.1.jar\n",
            "spark-3.2.0-bin-hadoop2.7/conf/\n",
            "spark-3.2.0-bin-hadoop2.7/conf/metrics.properties.template\n",
            "spark-3.2.0-bin-hadoop2.7/conf/workers.template\n",
            "spark-3.2.0-bin-hadoop2.7/conf/fairscheduler.xml.template\n",
            "spark-3.2.0-bin-hadoop2.7/conf/log4j.properties.template\n",
            "spark-3.2.0-bin-hadoop2.7/conf/spark-defaults.conf.template\n",
            "spark-3.2.0-bin-hadoop2.7/conf/spark-env.sh.template\n",
            "spark-3.2.0-bin-hadoop2.7/bin/\n",
            "spark-3.2.0-bin-hadoop2.7/bin/sparkR.cmd\n",
            "spark-3.2.0-bin-hadoop2.7/bin/sparkR\n",
            "spark-3.2.0-bin-hadoop2.7/bin/spark-submit\n",
            "spark-3.2.0-bin-hadoop2.7/bin/pyspark2.cmd\n",
            "spark-3.2.0-bin-hadoop2.7/bin/spark-class\n",
            "spark-3.2.0-bin-hadoop2.7/bin/pyspark.cmd\n",
            "spark-3.2.0-bin-hadoop2.7/bin/spark-submit2.cmd\n",
            "spark-3.2.0-bin-hadoop2.7/bin/load-spark-env.cmd\n",
            "spark-3.2.0-bin-hadoop2.7/bin/spark-sql\n",
            "spark-3.2.0-bin-hadoop2.7/bin/docker-image-tool.sh\n",
            "spark-3.2.0-bin-hadoop2.7/bin/find-spark-home.cmd\n",
            "spark-3.2.0-bin-hadoop2.7/bin/load-spark-env.sh\n",
            "spark-3.2.0-bin-hadoop2.7/bin/pyspark\n",
            "spark-3.2.0-bin-hadoop2.7/bin/spark-shell.cmd\n",
            "spark-3.2.0-bin-hadoop2.7/bin/spark-shell2.cmd\n",
            "spark-3.2.0-bin-hadoop2.7/bin/spark-submit.cmd\n",
            "spark-3.2.0-bin-hadoop2.7/bin/beeline.cmd\n",
            "spark-3.2.0-bin-hadoop2.7/bin/find-spark-home\n",
            "spark-3.2.0-bin-hadoop2.7/bin/spark-class.cmd\n",
            "spark-3.2.0-bin-hadoop2.7/bin/sparkR2.cmd\n",
            "spark-3.2.0-bin-hadoop2.7/bin/beeline\n",
            "spark-3.2.0-bin-hadoop2.7/bin/spark-class2.cmd\n",
            "spark-3.2.0-bin-hadoop2.7/bin/spark-sql.cmd\n",
            "spark-3.2.0-bin-hadoop2.7/bin/run-example\n",
            "spark-3.2.0-bin-hadoop2.7/bin/spark-shell\n",
            "spark-3.2.0-bin-hadoop2.7/bin/run-example.cmd\n",
            "spark-3.2.0-bin-hadoop2.7/bin/spark-sql2.cmd\n",
            "spark-3.2.0-bin-hadoop2.7/python/\n",
            "spark-3.2.0-bin-hadoop2.7/python/.gitignore\n",
            "spark-3.2.0-bin-hadoop2.7/python/run-tests-with-coverage\n",
            "spark-3.2.0-bin-hadoop2.7/python/mypy.ini\n",
            "spark-3.2.0-bin-hadoop2.7/python/pylintrc\n",
            "spark-3.2.0-bin-hadoop2.7/python/MANIFEST.in\n",
            "spark-3.2.0-bin-hadoop2.7/python/README.md\n",
            "spark-3.2.0-bin-hadoop2.7/python/test_coverage/\n",
            "spark-3.2.0-bin-hadoop2.7/python/test_coverage/coverage_daemon.py\n",
            "spark-3.2.0-bin-hadoop2.7/python/test_coverage/conf/\n",
            "spark-3.2.0-bin-hadoop2.7/python/test_coverage/conf/spark-defaults.conf\n",
            "spark-3.2.0-bin-hadoop2.7/python/test_coverage/sitecustomize.py\n",
            "spark-3.2.0-bin-hadoop2.7/python/run-tests.py\n",
            "spark-3.2.0-bin-hadoop2.7/python/setup.py\n",
            "spark-3.2.0-bin-hadoop2.7/python/test_support/\n",
            "spark-3.2.0-bin-hadoop2.7/python/test_support/userlibrary.py\n",
            "spark-3.2.0-bin-hadoop2.7/python/test_support/hello/\n",
            "spark-3.2.0-bin-hadoop2.7/python/test_support/hello/sub_hello/\n",
            "spark-3.2.0-bin-hadoop2.7/python/test_support/hello/sub_hello/sub_hello.txt\n",
            "spark-3.2.0-bin-hadoop2.7/python/test_support/hello/hello.txt\n",
            "spark-3.2.0-bin-hadoop2.7/python/test_support/userlib-0.1.zip\n",
            "spark-3.2.0-bin-hadoop2.7/python/test_support/SimpleHTTPServer.py\n",
            "spark-3.2.0-bin-hadoop2.7/python/test_support/sql/\n",
            "spark-3.2.0-bin-hadoop2.7/python/test_support/sql/people.json\n",
            "spark-3.2.0-bin-hadoop2.7/python/test_support/sql/people_array.json\n",
            "spark-3.2.0-bin-hadoop2.7/python/test_support/sql/people_array_utf16le.json\n",
            "spark-3.2.0-bin-hadoop2.7/python/test_support/sql/text-test.txt\n",
            "spark-3.2.0-bin-hadoop2.7/python/test_support/sql/ages.csv\n",
            "spark-3.2.0-bin-hadoop2.7/python/test_support/sql/parquet_partitioned/\n",
            "spark-3.2.0-bin-hadoop2.7/python/test_support/sql/parquet_partitioned/year=2015/\n",
            "spark-3.2.0-bin-hadoop2.7/python/test_support/sql/parquet_partitioned/year=2015/month=10/\n",
            "spark-3.2.0-bin-hadoop2.7/python/test_support/sql/parquet_partitioned/year=2015/month=10/day=26/\n",
            "spark-3.2.0-bin-hadoop2.7/python/test_support/sql/parquet_partitioned/year=2015/month=10/day=26/.part-r-00005.gz.parquet.crc\n",
            "spark-3.2.0-bin-hadoop2.7/python/test_support/sql/parquet_partitioned/year=2015/month=10/day=26/part-r-00005.gz.parquet\n",
            "spark-3.2.0-bin-hadoop2.7/python/test_support/sql/parquet_partitioned/year=2015/month=10/day=25/\n",
            "spark-3.2.0-bin-hadoop2.7/python/test_support/sql/parquet_partitioned/year=2015/month=10/day=25/.part-r-00002.gz.parquet.crc\n",
            "spark-3.2.0-bin-hadoop2.7/python/test_support/sql/parquet_partitioned/year=2015/month=10/day=25/.part-r-00004.gz.parquet.crc\n",
            "spark-3.2.0-bin-hadoop2.7/python/test_support/sql/parquet_partitioned/year=2015/month=10/day=25/part-r-00004.gz.parquet\n",
            "spark-3.2.0-bin-hadoop2.7/python/test_support/sql/parquet_partitioned/year=2015/month=10/day=25/part-r-00002.gz.parquet\n",
            "spark-3.2.0-bin-hadoop2.7/python/test_support/sql/parquet_partitioned/year=2015/month=9/\n",
            "spark-3.2.0-bin-hadoop2.7/python/test_support/sql/parquet_partitioned/year=2015/month=9/day=1/\n",
            "spark-3.2.0-bin-hadoop2.7/python/test_support/sql/parquet_partitioned/year=2015/month=9/day=1/.part-r-00007.gz.parquet.crc\n",
            "spark-3.2.0-bin-hadoop2.7/python/test_support/sql/parquet_partitioned/year=2015/month=9/day=1/part-r-00007.gz.parquet\n",
            "spark-3.2.0-bin-hadoop2.7/python/test_support/sql/parquet_partitioned/_metadata\n",
            "spark-3.2.0-bin-hadoop2.7/python/test_support/sql/parquet_partitioned/year=2014/\n",
            "spark-3.2.0-bin-hadoop2.7/python/test_support/sql/parquet_partitioned/year=2014/month=9/\n",
            "spark-3.2.0-bin-hadoop2.7/python/test_support/sql/parquet_partitioned/year=2014/month=9/day=1/\n",
            "spark-3.2.0-bin-hadoop2.7/python/test_support/sql/parquet_partitioned/year=2014/month=9/day=1/.part-r-00008.gz.parquet.crc\n",
            "spark-3.2.0-bin-hadoop2.7/python/test_support/sql/parquet_partitioned/year=2014/month=9/day=1/part-r-00008.gz.parquet\n",
            "spark-3.2.0-bin-hadoop2.7/python/test_support/sql/parquet_partitioned/_common_metadata\n",
            "spark-3.2.0-bin-hadoop2.7/python/test_support/sql/parquet_partitioned/_SUCCESS\n",
            "spark-3.2.0-bin-hadoop2.7/python/test_support/sql/orc_partitioned/\n",
            "spark-3.2.0-bin-hadoop2.7/python/test_support/sql/orc_partitioned/b=1/\n",
            "spark-3.2.0-bin-hadoop2.7/python/test_support/sql/orc_partitioned/b=1/c=1/\n",
            "spark-3.2.0-bin-hadoop2.7/python/test_support/sql/orc_partitioned/b=1/c=1/part-r-00000-829af031-b970-49d6-ad39-30460a0be2c8.orc\n",
            "spark-3.2.0-bin-hadoop2.7/python/test_support/sql/orc_partitioned/b=1/c=1/.part-r-00000-829af031-b970-49d6-ad39-30460a0be2c8.orc.crc\n",
            "spark-3.2.0-bin-hadoop2.7/python/test_support/sql/orc_partitioned/b=0/\n",
            "spark-3.2.0-bin-hadoop2.7/python/test_support/sql/orc_partitioned/b=0/c=0/\n",
            "spark-3.2.0-bin-hadoop2.7/python/test_support/sql/orc_partitioned/b=0/c=0/part-r-00000-829af031-b970-49d6-ad39-30460a0be2c8.orc\n",
            "spark-3.2.0-bin-hadoop2.7/python/test_support/sql/orc_partitioned/b=0/c=0/.part-r-00000-829af031-b970-49d6-ad39-30460a0be2c8.orc.crc\n",
            "spark-3.2.0-bin-hadoop2.7/python/test_support/sql/orc_partitioned/_SUCCESS\n",
            "spark-3.2.0-bin-hadoop2.7/python/test_support/sql/ages_newlines.csv\n",
            "spark-3.2.0-bin-hadoop2.7/python/test_support/sql/streaming/\n",
            "spark-3.2.0-bin-hadoop2.7/python/test_support/sql/streaming/text-test.txt\n",
            "spark-3.2.0-bin-hadoop2.7/python/test_support/sql/people1.json\n",
            "spark-3.2.0-bin-hadoop2.7/python/pyspark/\n",
            "spark-3.2.0-bin-hadoop2.7/python/pyspark/tests/\n",
            "spark-3.2.0-bin-hadoop2.7/python/pyspark/tests/test_rddbarrier.py\n",
            "spark-3.2.0-bin-hadoop2.7/python/pyspark/tests/test_worker.py\n",
            "spark-3.2.0-bin-hadoop2.7/python/pyspark/tests/test_serializers.py\n",
            "spark-3.2.0-bin-hadoop2.7/python/pyspark/tests/test_util.py\n",
            "spark-3.2.0-bin-hadoop2.7/python/pyspark/tests/test_rdd.py\n",
            "spark-3.2.0-bin-hadoop2.7/python/pyspark/tests/__init__.py\n",
            "spark-3.2.0-bin-hadoop2.7/python/pyspark/tests/test_broadcast.py\n",
            "spark-3.2.0-bin-hadoop2.7/python/pyspark/tests/test_appsubmit.py\n",
            "spark-3.2.0-bin-hadoop2.7/python/pyspark/tests/test_profiler.py\n",
            "spark-3.2.0-bin-hadoop2.7/python/pyspark/tests/test_pin_thread.py\n",
            "spark-3.2.0-bin-hadoop2.7/python/pyspark/tests/test_install_spark.py\n",
            "spark-3.2.0-bin-hadoop2.7/python/pyspark/tests/test_shuffle.py\n",
            "spark-3.2.0-bin-hadoop2.7/python/pyspark/tests/test_join.py\n",
            "spark-3.2.0-bin-hadoop2.7/python/pyspark/tests/test_taskcontext.py\n",
            "spark-3.2.0-bin-hadoop2.7/python/pyspark/tests/test_context.py\n",
            "spark-3.2.0-bin-hadoop2.7/python/pyspark/tests/test_readwrite.py\n",
            "spark-3.2.0-bin-hadoop2.7/python/pyspark/tests/test_conf.py\n",
            "spark-3.2.0-bin-hadoop2.7/python/pyspark/tests/test_daemon.py\n",
            "spark-3.2.0-bin-hadoop2.7/python/pyspark/__init__.pyi\n",
            "spark-3.2.0-bin-hadoop2.7/python/pyspark/pandas/\n",
            "spark-3.2.0-bin-hadoop2.7/python/pyspark/pandas/tests/\n",
            "spark-3.2.0-bin-hadoop2.7/python/pyspark/pandas/tests/test_series.py\n",
            "spark-3.2.0-bin-hadoop2.7/python/pyspark/pandas/tests/test_utils.py\n",
            "spark-3.2.0-bin-hadoop2.7/python/pyspark/pandas/tests/test_dataframe.py\n",
            "spark-3.2.0-bin-hadoop2.7/python/pyspark/pandas/tests/indexes/\n",
            "spark-3.2.0-bin-hadoop2.7/python/pyspark/pandas/tests/indexes/__init__.py\n",
            "spark-3.2.0-bin-hadoop2.7/python/pyspark/pandas/tests/indexes/test_category.py\n",
            "spark-3.2.0-bin-hadoop2.7/python/pyspark/pandas/tests/indexes/test_datetime.py\n",
            "spark-3.2.0-bin-hadoop2.7/python/pyspark/pandas/tests/indexes/test_base.py\n",
            "spark-3.2.0-bin-hadoop2.7/python/pyspark/pandas/tests/test_window.py\n",
            "spark-3.2.0-bin-hadoop2.7/python/pyspark/pandas/tests/test_indexops_spark.py\n",
            "spark-3.2.0-bin-hadoop2.7/python/pyspark/pandas/tests/__init__.py\n",
            "spark-3.2.0-bin-hadoop2.7/python/pyspark/pandas/tests/test_stats.py\n",
            "spark-3.2.0-bin-hadoop2.7/python/pyspark/pandas/tests/test_extension.py\n",
            "spark-3.2.0-bin-hadoop2.7/python/pyspark/pandas/tests/test_default_index.py\n",
            "spark-3.2.0-bin-hadoop2.7/python/pyspark/pandas/tests/test_expanding.py\n",
            "spark-3.2.0-bin-hadoop2.7/python/pyspark/pandas/tests/test_series_datetime.py\n",
            "spark-3.2.0-bin-hadoop2.7/python/pyspark/pandas/tests/test_indexing.py\n",
            "spark-3.2.0-bin-hadoop2.7/python/pyspark/pandas/tests/test_typedef.py\n",
            "spark-3.2.0-bin-hadoop2.7/python/pyspark/pandas/tests/test_numpy_compat.py\n",
            "spark-3.2.0-bin-hadoop2.7/python/pyspark/pandas/tests/test_dataframe_spark_io.py\n",
            "spark-3.2.0-bin-hadoop2.7/python/pyspark/pandas/tests/test_repr.py\n",
            "spark-3.2.0-bin-hadoop2.7/python/pyspark/pandas/tests/test_ops_on_diff_frames_groupby_expanding.py\n",
            "spark-3.2.0-bin-hadoop2.7/python/pyspark/pandas/tests/test_namespace.py\n",
            "spark-3.2.0-bin-hadoop2.7/python/pyspark/pandas/tests/test_ops_on_diff_frames_groupby.py\n",
            "spark-3.2.0-bin-hadoop2.7/python/pyspark/pandas/tests/test_series_conversion.py\n",
            "spark-3.2.0-bin-hadoop2.7/python/pyspark/pandas/tests/test_internal.py\n",
            "spark-3.2.0-bin-hadoop2.7/python/pyspark/pandas/tests/test_series_string.py\n",
            "spark-3.2.0-bin-hadoop2.7/python/pyspark/pandas/tests/test_groupby.py\n",
            "spark-3.2.0-bin-hadoop2.7/python/pyspark/pandas/tests/test_csv.py\n",
            "spark-3.2.0-bin-hadoop2.7/python/pyspark/pandas/tests/test_ops_on_diff_frames_groupby_rolling.py\n",
            "spark-3.2.0-bin-hadoop2.7/python/pyspark/pandas/tests/test_dataframe_conversion.py\n",
            "spark-3.2.0-bin-hadoop2.7/python/pyspark/pandas/tests/data_type_ops/\n",
            "spark-3.2.0-bin-hadoop2.7/python/pyspark/pandas/tests/data_type_ops/test_categorical_ops.py\n",
            "spark-3.2.0-bin-hadoop2.7/python/pyspark/pandas/tests/data_type_ops/test_complex_ops.py\n",
            "spark-3.2.0-bin-hadoop2.7/python/pyspark/pandas/tests/data_type_ops/test_boolean_ops.py\n",
            "spark-3.2.0-bin-hadoop2.7/python/pyspark/pandas/tests/data_type_ops/test_string_ops.py\n",
            "spark-3.2.0-bin-hadoop2.7/python/pyspark/pandas/tests/data_type_ops/__init__.py\n",
            "spark-3.2.0-bin-hadoop2.7/python/pyspark/pandas/tests/data_type_ops/testing_utils.py\n",
            "spark-3.2.0-bin-hadoop2.7/python/pyspark/pandas/tests/data_type_ops/test_udt_ops.py\n",
            "spark-3.2.0-bin-hadoop2.7/python/pyspark/pandas/tests/data_type_ops/test_num_ops.py\n",
            "spark-3.2.0-bin-hadoop2.7/python/pyspark/pandas/tests/data_type_ops/test_date_ops.py\n",
            "spark-3.2.0-bin-hadoop2.7/python/pyspark/pandas/tests/data_type_ops/test_null_ops.py\n",
            "spark-3.2.0-bin-hadoop2.7/python/pyspark/pandas/tests/data_type_ops/test_datetime_ops.py\n",
            "spark-3.2.0-bin-hadoop2.7/python/pyspark/pandas/tests/data_type_ops/test_binary_ops.py\n",
            "spark-3.2.0-bin-hadoop2.7/python/pyspark/pandas/tests/data_type_ops/test_base.py\n",
            "spark-3.2.0-bin-hadoop2.7/python/pyspark/pandas/tests/test_frame_spark.py\n",
            "spark-3.2.0-bin-hadoop2.7/python/pyspark/pandas/tests/test_config.py\n",
            "spark-3.2.0-bin-hadoop2.7/python/pyspark/pandas/tests/test_categorical.py\n",
            "spark-3.2.0-bin-hadoop2.7/python/pyspark/pandas/tests/plot/\n",
            "spark-3.2.0-bin-hadoop2.7/python/pyspark/pandas/tests/plot/__init__.py\n",
            "spark-3.2.0-bin-hadoop2.7/python/pyspark/pandas/tests/plot/test_frame_plot.py\n",
            "spark-3.2.0-bin-hadoop2.7/python/pyspark/pandas/tests/plot/test_frame_plot_matplotlib.py\n",
            "spark-3.2.0-bin-hadoop2.7/python/pyspark/pandas/tests/plot/test_frame_plot_plotly.py\n",
            "spark-3.2.0-bin-hadoop2.7/python/pyspark/pandas/tests/plot/test_series_plot_matplotlib.py\n",
            "spark-3.2.0-bin-hadoop2.7/python/pyspark/pandas/tests/plot/test_series_plot_plotly.py\n",
            "spark-3.2.0-bin-hadoop2.7/python/pyspark/pandas/tests/plot/test_series_plot.py\n",
            "spark-3.2.0-bin-hadoop2.7/python/pyspark/pandas/tests/test_ops_on_diff_frames.py\n",
            "spark-3.2.0-bin-hadoop2.7/python/pyspark/pandas/tests/test_rolling.py\n",
            "spark-3.2.0-bin-hadoop2.7/python/pyspark/pandas/tests/test_reshape.py\n",
            "spark-3.2.0-bin-hadoop2.7/python/pyspark/pandas/tests/test_sql.py\n",
            "spark-3.2.0-bin-hadoop2.7/python/pyspark/pandas/tests/test_spark_functions.py\n",
            "spark-3.2.0-bin-hadoop2.7/python/pyspark/pandas/sql_processor.py\n",
            "spark-3.2.0-bin-hadoop2.7/python/pyspark/pandas/numpy_compat.py\n",
            "spark-3.2.0-bin-hadoop2.7/python/pyspark/pandas/usage_logging/\n",
            "spark-3.2.0-bin-hadoop2.7/python/pyspark/pandas/usage_logging/__init__.py\n",
            "spark-3.2.0-bin-hadoop2.7/python/pyspark/pandas/usage_logging/usage_logger.py\n",
            "spark-3.2.0-bin-hadoop2.7/python/pyspark/pandas/spark/\n",
            "spark-3.2.0-bin-hadoop2.7/python/pyspark/pandas/spark/functions.py\n",
            "spark-3.2.0-bin-hadoop2.7/python/pyspark/pandas/spark/__init__.py\n",
            "spark-3.2.0-bin-hadoop2.7/python/pyspark/pandas/spark/accessors.py\n",
            "spark-3.2.0-bin-hadoop2.7/python/pyspark/pandas/spark/utils.py\n",
            "spark-3.2.0-bin-hadoop2.7/python/pyspark/pandas/base.py\n",
            "spark-3.2.0-bin-hadoop2.7/python/pyspark/pandas/frame.py\n",
            "spark-3.2.0-bin-hadoop2.7/python/pyspark/pandas/window.py\n",
            "spark-3.2.0-bin-hadoop2.7/python/pyspark/pandas/indexes/\n",
            "spark-3.2.0-bin-hadoop2.7/python/pyspark/pandas/indexes/base.py\n",
            "spark-3.2.0-bin-hadoop2.7/python/pyspark/pandas/indexes/__init__.py\n",
            "spark-3.2.0-bin-hadoop2.7/python/pyspark/pandas/indexes/numeric.py\n",
            "spark-3.2.0-bin-hadoop2.7/python/pyspark/pandas/indexes/datetimes.py\n",
            "spark-3.2.0-bin-hadoop2.7/python/pyspark/pandas/indexes/category.py\n",
            "spark-3.2.0-bin-hadoop2.7/python/pyspark/pandas/indexes/multi.py\n",
            "spark-3.2.0-bin-hadoop2.7/python/pyspark/pandas/namespace.py\n",
            "spark-3.2.0-bin-hadoop2.7/python/pyspark/pandas/mlflow.py\n",
            "spark-3.2.0-bin-hadoop2.7/python/pyspark/pandas/indexing.py\n",
            "spark-3.2.0-bin-hadoop2.7/python/pyspark/pandas/strings.py\n",
            "spark-3.2.0-bin-hadoop2.7/python/pyspark/pandas/__init__.py\n",
            "spark-3.2.0-bin-hadoop2.7/python/pyspark/pandas/extensions.py\n",
            "spark-3.2.0-bin-hadoop2.7/python/pyspark/pandas/accessors.py\n",
            "spark-3.2.0-bin-hadoop2.7/python/pyspark/pandas/config.py\n",
            "spark-3.2.0-bin-hadoop2.7/python/pyspark/pandas/groupby.py\n",
            "spark-3.2.0-bin-hadoop2.7/python/pyspark/pandas/internal.py\n",
            "spark-3.2.0-bin-hadoop2.7/python/pyspark/pandas/missing/\n",
            "spark-3.2.0-bin-hadoop2.7/python/pyspark/pandas/missing/frame.py\n",
            "spark-3.2.0-bin-hadoop2.7/python/pyspark/pandas/missing/window.py\n",
            "spark-3.2.0-bin-hadoop2.7/python/pyspark/pandas/missing/__init__.py\n",
            "spark-3.2.0-bin-hadoop2.7/python/pyspark/pandas/missing/groupby.py\n",
            "spark-3.2.0-bin-hadoop2.7/python/pyspark/pandas/missing/series.py\n",
            "spark-3.2.0-bin-hadoop2.7/python/pyspark/pandas/missing/indexes.py\n",
            "spark-3.2.0-bin-hadoop2.7/python/pyspark/pandas/missing/common.py\n",
            "spark-3.2.0-bin-hadoop2.7/python/pyspark/pandas/ml.py\n",
            "spark-3.2.0-bin-hadoop2.7/python/pyspark/pandas/series.py\n",
            "spark-3.2.0-bin-hadoop2.7/python/pyspark/pandas/_typing.py\n",
            "spark-3.2.0-bin-hadoop2.7/python/pyspark/pandas/datetimes.py\n",
            "spark-3.2.0-bin-hadoop2.7/python/pyspark/pandas/utils.py\n",
            "spark-3.2.0-bin-hadoop2.7/python/pyspark/pandas/data_type_ops/\n",
            "spark-3.2.0-bin-hadoop2.7/python/pyspark/pandas/data_type_ops/complex_ops.py\n",
            "spark-3.2.0-bin-hadoop2.7/python/pyspark/pandas/data_type_ops/binary_ops.py\n",
            "spark-3.2.0-bin-hadoop2.7/python/pyspark/pandas/data_type_ops/base.py\n",
            "spark-3.2.0-bin-hadoop2.7/python/pyspark/pandas/data_type_ops/categorical_ops.py\n",
            "spark-3.2.0-bin-hadoop2.7/python/pyspark/pandas/data_type_ops/string_ops.py\n",
            "spark-3.2.0-bin-hadoop2.7/python/pyspark/pandas/data_type_ops/__init__.py\n",
            "spark-3.2.0-bin-hadoop2.7/python/pyspark/pandas/data_type_ops/date_ops.py\n",
            "spark-3.2.0-bin-hadoop2.7/python/pyspark/pandas/data_type_ops/udt_ops.py\n",
            "spark-3.2.0-bin-hadoop2.7/python/pyspark/pandas/data_type_ops/null_ops.py\n",
            "spark-3.2.0-bin-hadoop2.7/python/pyspark/pandas/data_type_ops/datetime_ops.py\n",
            "spark-3.2.0-bin-hadoop2.7/python/pyspark/pandas/data_type_ops/num_ops.py\n",
            "spark-3.2.0-bin-hadoop2.7/python/pyspark/pandas/data_type_ops/boolean_ops.py\n",
            "spark-3.2.0-bin-hadoop2.7/python/pyspark/pandas/plot/\n",
            "spark-3.2.0-bin-hadoop2.7/python/pyspark/pandas/plot/core.py\n",
            "spark-3.2.0-bin-hadoop2.7/python/pyspark/pandas/plot/__init__.py\n",
            "spark-3.2.0-bin-hadoop2.7/python/pyspark/pandas/plot/plotly.py\n",
            "spark-3.2.0-bin-hadoop2.7/python/pyspark/pandas/plot/matplotlib.py\n",
            "spark-3.2.0-bin-hadoop2.7/python/pyspark/pandas/typedef/\n",
            "spark-3.2.0-bin-hadoop2.7/python/pyspark/pandas/typedef/__init__.py\n",
            "spark-3.2.0-bin-hadoop2.7/python/pyspark/pandas/typedef/typehints.py\n",
            "spark-3.2.0-bin-hadoop2.7/python/pyspark/pandas/typedef/string_typehints.py\n",
            "spark-3.2.0-bin-hadoop2.7/python/pyspark/pandas/categorical.py\n",
            "spark-3.2.0-bin-hadoop2.7/python/pyspark/pandas/generic.py\n",
            "spark-3.2.0-bin-hadoop2.7/python/pyspark/pandas/exceptions.py\n",
            "spark-3.2.0-bin-hadoop2.7/python/pyspark/_typing.pyi\n",
            "spark-3.2.0-bin-hadoop2.7/python/pyspark/testing/\n",
            "spark-3.2.0-bin-hadoop2.7/python/pyspark/testing/mlutils.py\n",
            "spark-3.2.0-bin-hadoop2.7/python/pyspark/testing/__init__.py\n",
            "spark-3.2.0-bin-hadoop2.7/python/pyspark/testing/mllibutils.py\n",
            "spark-3.2.0-bin-hadoop2.7/python/pyspark/testing/pandasutils.py\n",
            "spark-3.2.0-bin-hadoop2.7/python/pyspark/testing/utils.py\n",
            "spark-3.2.0-bin-hadoop2.7/python/pyspark/testing/sqlutils.py\n",
            "spark-3.2.0-bin-hadoop2.7/python/pyspark/testing/streamingutils.py\n",
            "spark-3.2.0-bin-hadoop2.7/python/pyspark/accumulators.py\n",
            "spark-3.2.0-bin-hadoop2.7/python/pyspark/rddsampler.py\n",
            "spark-3.2.0-bin-hadoop2.7/python/pyspark/install.py\n",
            "spark-3.2.0-bin-hadoop2.7/python/pyspark/status.pyi\n",
            "spark-3.2.0-bin-hadoop2.7/python/pyspark/ml/\n",
            "spark-3.2.0-bin-hadoop2.7/python/pyspark/ml/tests/\n",
            "spark-3.2.0-bin-hadoop2.7/python/pyspark/ml/tests/test_algorithms.py\n",
            "spark-3.2.0-bin-hadoop2.7/python/pyspark/ml/tests/test_evaluation.py\n",
            "spark-3.2.0-bin-hadoop2.7/python/pyspark/ml/tests/test_util.py\n",
            "spark-3.2.0-bin-hadoop2.7/python/pyspark/ml/tests/test_feature.py\n",
            "spark-3.2.0-bin-hadoop2.7/python/pyspark/ml/tests/test_pipeline.py\n",
            "spark-3.2.0-bin-hadoop2.7/python/pyspark/ml/tests/test_wrapper.py\n",
            "spark-3.2.0-bin-hadoop2.7/python/pyspark/ml/tests/__init__.py\n",
            "spark-3.2.0-bin-hadoop2.7/python/pyspark/ml/tests/test_tuning.py\n",
            "spark-3.2.0-bin-hadoop2.7/python/pyspark/ml/tests/test_persistence.py\n",
            "spark-3.2.0-bin-hadoop2.7/python/pyspark/ml/tests/test_param.py\n",
            "spark-3.2.0-bin-hadoop2.7/python/pyspark/ml/tests/test_training_summary.py\n",
            "spark-3.2.0-bin-hadoop2.7/python/pyspark/ml/tests/test_linalg.py\n",
            "spark-3.2.0-bin-hadoop2.7/python/pyspark/ml/tests/test_image.py\n",
            "spark-3.2.0-bin-hadoop2.7/python/pyspark/ml/tests/test_stat.py\n",
            "spark-3.2.0-bin-hadoop2.7/python/pyspark/ml/tests/test_base.py\n",
            "spark-3.2.0-bin-hadoop2.7/python/pyspark/ml/evaluation.pyi\n",
            "spark-3.2.0-bin-hadoop2.7/python/pyspark/ml/_typing.pyi\n",
            "spark-3.2.0-bin-hadoop2.7/python/pyspark/ml/functions.py\n",
            "spark-3.2.0-bin-hadoop2.7/python/pyspark/ml/recommendation.pyi\n",
            "spark-3.2.0-bin-hadoop2.7/python/pyspark/ml/tuning.py\n",
            "spark-3.2.0-bin-hadoop2.7/python/pyspark/ml/fpm.pyi\n",
            "spark-3.2.0-bin-hadoop2.7/python/pyspark/ml/pipeline.py\n",
            "spark-3.2.0-bin-hadoop2.7/python/pyspark/ml/base.py\n",
            "spark-3.2.0-bin-hadoop2.7/python/pyspark/ml/feature.py\n",
            "spark-3.2.0-bin-hadoop2.7/python/pyspark/ml/wrapper.pyi\n",
            "spark-3.2.0-bin-hadoop2.7/python/pyspark/ml/__init__.py\n",
            "spark-3.2.0-bin-hadoop2.7/python/pyspark/ml/stat.pyi\n",
            "spark-3.2.0-bin-hadoop2.7/python/pyspark/ml/stat.py\n",
            "spark-3.2.0-bin-hadoop2.7/python/pyspark/ml/image.py\n",
            "spark-3.2.0-bin-hadoop2.7/python/pyspark/ml/classification.py\n",
            "spark-3.2.0-bin-hadoop2.7/python/pyspark/ml/common.pyi\n",
            "spark-3.2.0-bin-hadoop2.7/python/pyspark/ml/pipeline.pyi\n",
            "spark-3.2.0-bin-hadoop2.7/python/pyspark/ml/recommendation.py\n",
            "spark-3.2.0-bin-hadoop2.7/python/pyspark/ml/clustering.pyi\n",
            "spark-3.2.0-bin-hadoop2.7/python/pyspark/ml/regression.py\n",
            "spark-3.2.0-bin-hadoop2.7/python/pyspark/ml/param/\n",
            "spark-3.2.0-bin-hadoop2.7/python/pyspark/ml/param/__init__.pyi\n",
            "spark-3.2.0-bin-hadoop2.7/python/pyspark/ml/param/_shared_params_code_gen.py\n",
            "spark-3.2.0-bin-hadoop2.7/python/pyspark/ml/param/__init__.py\n",
            "spark-3.2.0-bin-hadoop2.7/python/pyspark/ml/param/shared.py\n",
            "spark-3.2.0-bin-hadoop2.7/python/pyspark/ml/param/_shared_params_code_gen.pyi\n",
            "spark-3.2.0-bin-hadoop2.7/python/pyspark/ml/param/shared.pyi\n",
            "spark-3.2.0-bin-hadoop2.7/python/pyspark/ml/feature.pyi\n",
            "spark-3.2.0-bin-hadoop2.7/python/pyspark/ml/classification.pyi\n",
            "spark-3.2.0-bin-hadoop2.7/python/pyspark/ml/tree.py\n",
            "spark-3.2.0-bin-hadoop2.7/python/pyspark/ml/util.pyi\n",
            "spark-3.2.0-bin-hadoop2.7/python/pyspark/ml/tuning.pyi\n",
            "spark-3.2.0-bin-hadoop2.7/python/pyspark/ml/fpm.py\n",
            "spark-3.2.0-bin-hadoop2.7/python/pyspark/ml/regression.pyi\n",
            "spark-3.2.0-bin-hadoop2.7/python/pyspark/ml/functions.pyi\n",
            "spark-3.2.0-bin-hadoop2.7/python/pyspark/ml/base.pyi\n",
            "spark-3.2.0-bin-hadoop2.7/python/pyspark/ml/wrapper.py\n",
            "spark-3.2.0-bin-hadoop2.7/python/pyspark/ml/image.pyi\n",
            "spark-3.2.0-bin-hadoop2.7/python/pyspark/ml/tree.pyi\n",
            "spark-3.2.0-bin-hadoop2.7/python/pyspark/ml/clustering.py\n",
            "spark-3.2.0-bin-hadoop2.7/python/pyspark/ml/common.py\n",
            "spark-3.2.0-bin-hadoop2.7/python/pyspark/ml/linalg/\n",
            "spark-3.2.0-bin-hadoop2.7/python/pyspark/ml/linalg/__init__.pyi\n",
            "spark-3.2.0-bin-hadoop2.7/python/pyspark/ml/linalg/__init__.py\n",
            "spark-3.2.0-bin-hadoop2.7/python/pyspark/ml/evaluation.py\n",
            "spark-3.2.0-bin-hadoop2.7/python/pyspark/ml/util.py\n",
            "spark-3.2.0-bin-hadoop2.7/python/pyspark/context.pyi\n",
            "spark-3.2.0-bin-hadoop2.7/python/pyspark/find_spark_home.py\n",
            "spark-3.2.0-bin-hadoop2.7/python/pyspark/serializers.py\n",
            "spark-3.2.0-bin-hadoop2.7/python/pyspark/java_gateway.py\n",
            "spark-3.2.0-bin-hadoop2.7/python/pyspark/traceback_utils.py\n",
            "spark-3.2.0-bin-hadoop2.7/python/pyspark/resource/\n",
            "spark-3.2.0-bin-hadoop2.7/python/pyspark/resource/tests/\n",
            "spark-3.2.0-bin-hadoop2.7/python/pyspark/resource/tests/__init__.py\n",
            "spark-3.2.0-bin-hadoop2.7/python/pyspark/resource/tests/test_resources.py\n",
            "spark-3.2.0-bin-hadoop2.7/python/pyspark/resource/profile.py\n",
            "spark-3.2.0-bin-hadoop2.7/python/pyspark/resource/__init__.py\n",
            "spark-3.2.0-bin-hadoop2.7/python/pyspark/resource/information.py\n",
            "spark-3.2.0-bin-hadoop2.7/python/pyspark/resource/requests.pyi\n",
            "spark-3.2.0-bin-hadoop2.7/python/pyspark/resource/information.pyi\n",
            "spark-3.2.0-bin-hadoop2.7/python/pyspark/resource/requests.py\n",
            "spark-3.2.0-bin-hadoop2.7/python/pyspark/resource/profile.pyi\n",
            "spark-3.2.0-bin-hadoop2.7/python/pyspark/conf.py\n",
            "spark-3.2.0-bin-hadoop2.7/python/pyspark/resultiterable.pyi\n",
            "spark-3.2.0-bin-hadoop2.7/python/pyspark/version.pyi\n",
            "spark-3.2.0-bin-hadoop2.7/python/pyspark/__init__.py\n",
            "spark-3.2.0-bin-hadoop2.7/python/pyspark/files.pyi\n",
            "spark-3.2.0-bin-hadoop2.7/python/pyspark/mllib/\n",
            "spark-3.2.0-bin-hadoop2.7/python/pyspark/mllib/tests/\n",
            "spark-3.2.0-bin-hadoop2.7/python/pyspark/mllib/tests/test_algorithms.py\n",
            "spark-3.2.0-bin-hadoop2.7/python/pyspark/mllib/tests/test_streaming_algorithms.py\n",
            "spark-3.2.0-bin-hadoop2.7/python/pyspark/mllib/tests/test_util.py\n",
            "spark-3.2.0-bin-hadoop2.7/python/pyspark/mllib/tests/test_feature.py\n",
            "spark-3.2.0-bin-hadoop2.7/python/pyspark/mllib/tests/__init__.py\n",
            "spark-3.2.0-bin-hadoop2.7/python/pyspark/mllib/tests/test_linalg.py\n",
            "spark-3.2.0-bin-hadoop2.7/python/pyspark/mllib/tests/test_stat.py\n",
            "spark-3.2.0-bin-hadoop2.7/python/pyspark/mllib/evaluation.pyi\n",
            "spark-3.2.0-bin-hadoop2.7/python/pyspark/mllib/_typing.pyi\n",
            "spark-3.2.0-bin-hadoop2.7/python/pyspark/mllib/recommendation.pyi\n",
            "spark-3.2.0-bin-hadoop2.7/python/pyspark/mllib/fpm.pyi\n",
            "spark-3.2.0-bin-hadoop2.7/python/pyspark/mllib/feature.py\n",
            "spark-3.2.0-bin-hadoop2.7/python/pyspark/mllib/__init__.py\n",
            "spark-3.2.0-bin-hadoop2.7/python/pyspark/mllib/classification.py\n",
            "spark-3.2.0-bin-hadoop2.7/python/pyspark/mllib/common.pyi\n",
            "spark-3.2.0-bin-hadoop2.7/python/pyspark/mllib/random.pyi\n",
            "spark-3.2.0-bin-hadoop2.7/python/pyspark/mllib/recommendation.py\n",
            "spark-3.2.0-bin-hadoop2.7/python/pyspark/mllib/clustering.pyi\n",
            "spark-3.2.0-bin-hadoop2.7/python/pyspark/mllib/regression.py\n",
            "spark-3.2.0-bin-hadoop2.7/python/pyspark/mllib/feature.pyi\n",
            "spark-3.2.0-bin-hadoop2.7/python/pyspark/mllib/classification.pyi\n",
            "spark-3.2.0-bin-hadoop2.7/python/pyspark/mllib/tree.py\n",
            "spark-3.2.0-bin-hadoop2.7/python/pyspark/mllib/util.pyi\n",
            "spark-3.2.0-bin-hadoop2.7/python/pyspark/mllib/fpm.py\n",
            "spark-3.2.0-bin-hadoop2.7/python/pyspark/mllib/regression.pyi\n",
            "spark-3.2.0-bin-hadoop2.7/python/pyspark/mllib/random.py\n",
            "spark-3.2.0-bin-hadoop2.7/python/pyspark/mllib/stat/\n",
            "spark-3.2.0-bin-hadoop2.7/python/pyspark/mllib/stat/__init__.pyi\n",
            "spark-3.2.0-bin-hadoop2.7/python/pyspark/mllib/stat/distribution.py\n",
            "spark-3.2.0-bin-hadoop2.7/python/pyspark/mllib/stat/__init__.py\n",
            "spark-3.2.0-bin-hadoop2.7/python/pyspark/mllib/stat/KernelDensity.py\n",
            "spark-3.2.0-bin-hadoop2.7/python/pyspark/mllib/stat/_statistics.pyi\n",
            "spark-3.2.0-bin-hadoop2.7/python/pyspark/mllib/stat/distribution.pyi\n",
            "spark-3.2.0-bin-hadoop2.7/python/pyspark/mllib/stat/test.pyi\n",
            "spark-3.2.0-bin-hadoop2.7/python/pyspark/mllib/stat/test.py\n",
            "spark-3.2.0-bin-hadoop2.7/python/pyspark/mllib/stat/_statistics.py\n",
            "spark-3.2.0-bin-hadoop2.7/python/pyspark/mllib/stat/KernelDensity.pyi\n",
            "spark-3.2.0-bin-hadoop2.7/python/pyspark/mllib/tree.pyi\n",
            "spark-3.2.0-bin-hadoop2.7/python/pyspark/mllib/clustering.py\n",
            "spark-3.2.0-bin-hadoop2.7/python/pyspark/mllib/common.py\n",
            "spark-3.2.0-bin-hadoop2.7/python/pyspark/mllib/linalg/\n",
            "spark-3.2.0-bin-hadoop2.7/python/pyspark/mllib/linalg/__init__.pyi\n",
            "spark-3.2.0-bin-hadoop2.7/python/pyspark/mllib/linalg/__init__.py\n",
            "spark-3.2.0-bin-hadoop2.7/python/pyspark/mllib/linalg/distributed.py\n",
            "spark-3.2.0-bin-hadoop2.7/python/pyspark/mllib/linalg/distributed.pyi\n",
            "spark-3.2.0-bin-hadoop2.7/python/pyspark/mllib/evaluation.py\n",
            "spark-3.2.0-bin-hadoop2.7/python/pyspark/mllib/util.py\n",
            "spark-3.2.0-bin-hadoop2.7/python/pyspark/resultiterable.py\n",
            "spark-3.2.0-bin-hadoop2.7/python/pyspark/profiler.py\n",
            "spark-3.2.0-bin-hadoop2.7/python/pyspark/statcounter.py\n",
            "spark-3.2.0-bin-hadoop2.7/python/pyspark/join.py\n",
            "spark-3.2.0-bin-hadoop2.7/python/pyspark/daemon.py\n",
            "spark-3.2.0-bin-hadoop2.7/python/pyspark/rdd.py\n",
            "spark-3.2.0-bin-hadoop2.7/python/pyspark/context.py\n",
            "spark-3.2.0-bin-hadoop2.7/python/pyspark/cloudpickle/\n",
            "spark-3.2.0-bin-hadoop2.7/python/pyspark/cloudpickle/cloudpickle_fast.py\n",
            "spark-3.2.0-bin-hadoop2.7/python/pyspark/cloudpickle/__init__.py\n",
            "spark-3.2.0-bin-hadoop2.7/python/pyspark/cloudpickle/compat.py\n",
            "spark-3.2.0-bin-hadoop2.7/python/pyspark/cloudpickle/cloudpickle.py\n",
            "spark-3.2.0-bin-hadoop2.7/python/pyspark/storagelevel.pyi\n",
            "spark-3.2.0-bin-hadoop2.7/python/pyspark/version.py\n",
            "spark-3.2.0-bin-hadoop2.7/python/pyspark/py.typed\n",
            "spark-3.2.0-bin-hadoop2.7/python/pyspark/files.py\n",
            "spark-3.2.0-bin-hadoop2.7/python/pyspark/worker.py\n",
            "spark-3.2.0-bin-hadoop2.7/python/pyspark/util.pyi\n",
            "spark-3.2.0-bin-hadoop2.7/python/pyspark/statcounter.pyi\n",
            "spark-3.2.0-bin-hadoop2.7/python/pyspark/conf.pyi\n",
            "spark-3.2.0-bin-hadoop2.7/python/pyspark/shell.py\n",
            "spark-3.2.0-bin-hadoop2.7/python/pyspark/streaming/\n",
            "spark-3.2.0-bin-hadoop2.7/python/pyspark/streaming/tests/\n",
            "spark-3.2.0-bin-hadoop2.7/python/pyspark/streaming/tests/test_listener.py\n",
            "spark-3.2.0-bin-hadoop2.7/python/pyspark/streaming/tests/test_kinesis.py\n",
            "spark-3.2.0-bin-hadoop2.7/python/pyspark/streaming/tests/__init__.py\n",
            "spark-3.2.0-bin-hadoop2.7/python/pyspark/streaming/tests/test_dstream.py\n",
            "spark-3.2.0-bin-hadoop2.7/python/pyspark/streaming/tests/test_context.py\n",
            "spark-3.2.0-bin-hadoop2.7/python/pyspark/streaming/dstream.pyi\n",
            "spark-3.2.0-bin-hadoop2.7/python/pyspark/streaming/kinesis.pyi\n",
            "spark-3.2.0-bin-hadoop2.7/python/pyspark/streaming/context.pyi\n",
            "spark-3.2.0-bin-hadoop2.7/python/pyspark/streaming/dstream.py\n",
            "spark-3.2.0-bin-hadoop2.7/python/pyspark/streaming/listener.pyi\n",
            "spark-3.2.0-bin-hadoop2.7/python/pyspark/streaming/__init__.py\n",
            "spark-3.2.0-bin-hadoop2.7/python/pyspark/streaming/kinesis.py\n",
            "spark-3.2.0-bin-hadoop2.7/python/pyspark/streaming/listener.py\n",
            "spark-3.2.0-bin-hadoop2.7/python/pyspark/streaming/context.py\n",
            "spark-3.2.0-bin-hadoop2.7/python/pyspark/streaming/util.py\n",
            "spark-3.2.0-bin-hadoop2.7/python/pyspark/accumulators.pyi\n",
            "spark-3.2.0-bin-hadoop2.7/python/pyspark/profiler.pyi\n",
            "spark-3.2.0-bin-hadoop2.7/python/pyspark/status.py\n",
            "spark-3.2.0-bin-hadoop2.7/python/pyspark/broadcast.pyi\n",
            "spark-3.2.0-bin-hadoop2.7/python/pyspark/sql/\n",
            "spark-3.2.0-bin-hadoop2.7/python/pyspark/sql/tests/\n",
            "spark-3.2.0-bin-hadoop2.7/python/pyspark/sql/tests/test_functions.py\n",
            "spark-3.2.0-bin-hadoop2.7/python/pyspark/sql/tests/test_readwriter.py\n",
            "spark-3.2.0-bin-hadoop2.7/python/pyspark/sql/tests/test_utils.py\n",
            "spark-3.2.0-bin-hadoop2.7/python/pyspark/sql/tests/test_pandas_grouped_map.py\n",
            "spark-3.2.0-bin-hadoop2.7/python/pyspark/sql/tests/test_dataframe.py\n",
            "spark-3.2.0-bin-hadoop2.7/python/pyspark/sql/tests/test_pandas_map.py\n",
            "spark-3.2.0-bin-hadoop2.7/python/pyspark/sql/tests/test_udf.py\n",
            "spark-3.2.0-bin-hadoop2.7/python/pyspark/sql/tests/test_streaming.py\n",
            "spark-3.2.0-bin-hadoop2.7/python/pyspark/sql/tests/__init__.py\n",
            "spark-3.2.0-bin-hadoop2.7/python/pyspark/sql/tests/test_serde.py\n",
            "spark-3.2.0-bin-hadoop2.7/python/pyspark/sql/tests/test_pandas_udf_window.py\n",
            "spark-3.2.0-bin-hadoop2.7/python/pyspark/sql/tests/test_group.py\n",
            "spark-3.2.0-bin-hadoop2.7/python/pyspark/sql/tests/test_pandas_udf.py\n",
            "spark-3.2.0-bin-hadoop2.7/python/pyspark/sql/tests/test_pandas_cogrouped_map.py\n",
            "spark-3.2.0-bin-hadoop2.7/python/pyspark/sql/tests/test_pandas_udf_grouped_agg.py\n",
            "spark-3.2.0-bin-hadoop2.7/python/pyspark/sql/tests/test_pandas_udf_scalar.py\n",
            "spark-3.2.0-bin-hadoop2.7/python/pyspark/sql/tests/test_catalog.py\n",
            "spark-3.2.0-bin-hadoop2.7/python/pyspark/sql/tests/test_datasources.py\n",
            "spark-3.2.0-bin-hadoop2.7/python/pyspark/sql/tests/test_pandas_udf_typehints.py\n",
            "spark-3.2.0-bin-hadoop2.7/python/pyspark/sql/tests/test_types.py\n",
            "spark-3.2.0-bin-hadoop2.7/python/pyspark/sql/tests/test_column.py\n",
            "spark-3.2.0-bin-hadoop2.7/python/pyspark/sql/tests/test_context.py\n",
            "spark-3.2.0-bin-hadoop2.7/python/pyspark/sql/tests/test_conf.py\n",
            "spark-3.2.0-bin-hadoop2.7/python/pyspark/sql/tests/test_arrow.py\n",
            "spark-3.2.0-bin-hadoop2.7/python/pyspark/sql/tests/test_session.py\n",
            "spark-3.2.0-bin-hadoop2.7/python/pyspark/sql/__init__.pyi\n",
            "spark-3.2.0-bin-hadoop2.7/python/pyspark/sql/pandas/\n",
            "spark-3.2.0-bin-hadoop2.7/python/pyspark/sql/pandas/map_ops.pyi\n",
            "spark-3.2.0-bin-hadoop2.7/python/pyspark/sql/pandas/functions.py\n",
            "spark-3.2.0-bin-hadoop2.7/python/pyspark/sql/pandas/serializers.py\n",
            "spark-3.2.0-bin-hadoop2.7/python/pyspark/sql/pandas/__init__.py\n",
            "spark-3.2.0-bin-hadoop2.7/python/pyspark/sql/pandas/typehints.py\n",
            "spark-3.2.0-bin-hadoop2.7/python/pyspark/sql/pandas/group_ops.pyi\n",
            "spark-3.2.0-bin-hadoop2.7/python/pyspark/sql/pandas/map_ops.py\n",
            "spark-3.2.0-bin-hadoop2.7/python/pyspark/sql/pandas/types.py\n",
            "spark-3.2.0-bin-hadoop2.7/python/pyspark/sql/pandas/conversion.pyi\n",
            "spark-3.2.0-bin-hadoop2.7/python/pyspark/sql/pandas/group_ops.py\n",
            "spark-3.2.0-bin-hadoop2.7/python/pyspark/sql/pandas/functions.pyi\n",
            "spark-3.2.0-bin-hadoop2.7/python/pyspark/sql/pandas/utils.py\n",
            "spark-3.2.0-bin-hadoop2.7/python/pyspark/sql/pandas/conversion.py\n",
            "spark-3.2.0-bin-hadoop2.7/python/pyspark/sql/pandas/_typing/\n",
            "spark-3.2.0-bin-hadoop2.7/python/pyspark/sql/pandas/_typing/__init__.pyi\n",
            "spark-3.2.0-bin-hadoop2.7/python/pyspark/sql/pandas/_typing/protocols/\n",
            "spark-3.2.0-bin-hadoop2.7/python/pyspark/sql/pandas/_typing/protocols/__init__.pyi\n",
            "spark-3.2.0-bin-hadoop2.7/python/pyspark/sql/pandas/_typing/protocols/series.pyi\n",
            "spark-3.2.0-bin-hadoop2.7/python/pyspark/sql/pandas/_typing/protocols/frame.pyi\n",
            "spark-3.2.0-bin-hadoop2.7/python/pyspark/sql/_typing.pyi\n",
            "spark-3.2.0-bin-hadoop2.7/python/pyspark/sql/functions.py\n",
            "spark-3.2.0-bin-hadoop2.7/python/pyspark/sql/readwriter.py\n",
            "spark-3.2.0-bin-hadoop2.7/python/pyspark/sql/streaming.pyi\n",
            "spark-3.2.0-bin-hadoop2.7/python/pyspark/sql/context.pyi\n",
            "spark-3.2.0-bin-hadoop2.7/python/pyspark/sql/column.pyi\n",
            "spark-3.2.0-bin-hadoop2.7/python/pyspark/sql/catalog.py\n",
            "spark-3.2.0-bin-hadoop2.7/python/pyspark/sql/types.pyi\n",
            "spark-3.2.0-bin-hadoop2.7/python/pyspark/sql/window.py\n",
            "spark-3.2.0-bin-hadoop2.7/python/pyspark/sql/udf.py\n",
            "spark-3.2.0-bin-hadoop2.7/python/pyspark/sql/conf.py\n",
            "spark-3.2.0-bin-hadoop2.7/python/pyspark/sql/__init__.py\n",
            "spark-3.2.0-bin-hadoop2.7/python/pyspark/sql/session.py\n",
            "spark-3.2.0-bin-hadoop2.7/python/pyspark/sql/column.py\n",
            "spark-3.2.0-bin-hadoop2.7/python/pyspark/sql/group.py\n",
            "spark-3.2.0-bin-hadoop2.7/python/pyspark/sql/catalog.pyi\n",
            "spark-3.2.0-bin-hadoop2.7/python/pyspark/sql/group.pyi\n",
            "spark-3.2.0-bin-hadoop2.7/python/pyspark/sql/context.py\n",
            "spark-3.2.0-bin-hadoop2.7/python/pyspark/sql/dataframe.pyi\n",
            "spark-3.2.0-bin-hadoop2.7/python/pyspark/sql/types.py\n",
            "spark-3.2.0-bin-hadoop2.7/python/pyspark/sql/functions.pyi\n",
            "spark-3.2.0-bin-hadoop2.7/python/pyspark/sql/conf.pyi\n",
            "spark-3.2.0-bin-hadoop2.7/python/pyspark/sql/udf.pyi\n",
            "spark-3.2.0-bin-hadoop2.7/python/pyspark/sql/dataframe.py\n",
            "spark-3.2.0-bin-hadoop2.7/python/pyspark/sql/avro/\n",
            "spark-3.2.0-bin-hadoop2.7/python/pyspark/sql/avro/functions.py\n",
            "spark-3.2.0-bin-hadoop2.7/python/pyspark/sql/avro/__init__.py\n",
            "spark-3.2.0-bin-hadoop2.7/python/pyspark/sql/avro/functions.pyi\n",
            "spark-3.2.0-bin-hadoop2.7/python/pyspark/sql/utils.py\n",
            "spark-3.2.0-bin-hadoop2.7/python/pyspark/sql/readwriter.pyi\n",
            "spark-3.2.0-bin-hadoop2.7/python/pyspark/sql/window.pyi\n",
            "spark-3.2.0-bin-hadoop2.7/python/pyspark/sql/session.pyi\n",
            "spark-3.2.0-bin-hadoop2.7/python/pyspark/sql/streaming.py\n",
            "spark-3.2.0-bin-hadoop2.7/python/pyspark/shuffle.py\n",
            "spark-3.2.0-bin-hadoop2.7/python/pyspark/rdd.pyi\n",
            "spark-3.2.0-bin-hadoop2.7/python/pyspark/taskcontext.pyi\n",
            "spark-3.2.0-bin-hadoop2.7/python/pyspark/taskcontext.py\n",
            "spark-3.2.0-bin-hadoop2.7/python/pyspark/_globals.py\n",
            "spark-3.2.0-bin-hadoop2.7/python/pyspark/broadcast.py\n",
            "spark-3.2.0-bin-hadoop2.7/python/pyspark/util.py\n",
            "spark-3.2.0-bin-hadoop2.7/python/pyspark/storagelevel.py\n",
            "spark-3.2.0-bin-hadoop2.7/python/.coveragerc\n",
            "spark-3.2.0-bin-hadoop2.7/python/docs/\n",
            "spark-3.2.0-bin-hadoop2.7/python/docs/make2.bat\n",
            "spark-3.2.0-bin-hadoop2.7/python/docs/source/\n",
            "spark-3.2.0-bin-hadoop2.7/python/docs/source/reference/\n",
            "spark-3.2.0-bin-hadoop2.7/python/docs/source/reference/pyspark.ss.rst\n",
            "spark-3.2.0-bin-hadoop2.7/python/docs/source/reference/index.rst\n",
            "spark-3.2.0-bin-hadoop2.7/python/docs/source/reference/pyspark.ml.rst\n",
            "spark-3.2.0-bin-hadoop2.7/python/docs/source/reference/pyspark.rst\n",
            "spark-3.2.0-bin-hadoop2.7/python/docs/source/reference/pyspark.pandas/\n",
            "spark-3.2.0-bin-hadoop2.7/python/docs/source/reference/pyspark.pandas/window.rst\n",
            "spark-3.2.0-bin-hadoop2.7/python/docs/source/reference/pyspark.pandas/index.rst\n",
            "spark-3.2.0-bin-hadoop2.7/python/docs/source/reference/pyspark.pandas/extensions.rst\n",
            "spark-3.2.0-bin-hadoop2.7/python/docs/source/reference/pyspark.pandas/ml.rst\n",
            "spark-3.2.0-bin-hadoop2.7/python/docs/source/reference/pyspark.pandas/frame.rst\n",
            "spark-3.2.0-bin-hadoop2.7/python/docs/source/reference/pyspark.pandas/io.rst\n",
            "spark-3.2.0-bin-hadoop2.7/python/docs/source/reference/pyspark.pandas/series.rst\n",
            "spark-3.2.0-bin-hadoop2.7/python/docs/source/reference/pyspark.pandas/indexing.rst\n",
            "spark-3.2.0-bin-hadoop2.7/python/docs/source/reference/pyspark.pandas/general_functions.rst\n",
            "spark-3.2.0-bin-hadoop2.7/python/docs/source/reference/pyspark.pandas/groupby.rst\n",
            "spark-3.2.0-bin-hadoop2.7/python/docs/source/reference/pyspark.mllib.rst\n",
            "spark-3.2.0-bin-hadoop2.7/python/docs/source/reference/pyspark.streaming.rst\n",
            "spark-3.2.0-bin-hadoop2.7/python/docs/source/reference/pyspark.sql.rst\n",
            "spark-3.2.0-bin-hadoop2.7/python/docs/source/reference/pyspark.resource.rst\n",
            "spark-3.2.0-bin-hadoop2.7/python/docs/source/index.rst\n",
            "spark-3.2.0-bin-hadoop2.7/python/docs/source/getting_started/\n",
            "spark-3.2.0-bin-hadoop2.7/python/docs/source/getting_started/index.rst\n",
            "spark-3.2.0-bin-hadoop2.7/python/docs/source/getting_started/quickstart_ps.ipynb\n",
            "spark-3.2.0-bin-hadoop2.7/python/docs/source/getting_started/quickstart_df.ipynb\n",
            "spark-3.2.0-bin-hadoop2.7/python/docs/source/getting_started/install.rst\n",
            "spark-3.2.0-bin-hadoop2.7/python/docs/source/conf.py\n",
            "spark-3.2.0-bin-hadoop2.7/python/docs/source/_templates/\n",
            "spark-3.2.0-bin-hadoop2.7/python/docs/source/_templates/autosummary/\n",
            "spark-3.2.0-bin-hadoop2.7/python/docs/source/_templates/autosummary/class.rst\n",
            "spark-3.2.0-bin-hadoop2.7/python/docs/source/_templates/autosummary/class_with_docs.rst\n",
            "spark-3.2.0-bin-hadoop2.7/python/docs/source/_static/\n",
            "spark-3.2.0-bin-hadoop2.7/python/docs/source/_static/copybutton.js\n",
            "spark-3.2.0-bin-hadoop2.7/python/docs/source/_static/css/\n",
            "spark-3.2.0-bin-hadoop2.7/python/docs/source/_static/css/pyspark.css\n",
            "spark-3.2.0-bin-hadoop2.7/python/docs/source/development/\n",
            "spark-3.2.0-bin-hadoop2.7/python/docs/source/development/setting_ide.rst\n",
            "spark-3.2.0-bin-hadoop2.7/python/docs/source/development/index.rst\n",
            "spark-3.2.0-bin-hadoop2.7/python/docs/source/development/debugging.rst\n",
            "spark-3.2.0-bin-hadoop2.7/python/docs/source/development/testing.rst\n",
            "spark-3.2.0-bin-hadoop2.7/python/docs/source/development/contributing.rst\n",
            "spark-3.2.0-bin-hadoop2.7/python/docs/source/user_guide/\n",
            "spark-3.2.0-bin-hadoop2.7/python/docs/source/user_guide/arrow_pandas.rst\n",
            "spark-3.2.0-bin-hadoop2.7/python/docs/source/user_guide/index.rst\n",
            "spark-3.2.0-bin-hadoop2.7/python/docs/source/user_guide/pandas_on_spark/\n",
            "spark-3.2.0-bin-hadoop2.7/python/docs/source/user_guide/pandas_on_spark/types.rst\n",
            "spark-3.2.0-bin-hadoop2.7/python/docs/source/user_guide/pandas_on_spark/best_practices.rst\n",
            "spark-3.2.0-bin-hadoop2.7/python/docs/source/user_guide/pandas_on_spark/options.rst\n",
            "spark-3.2.0-bin-hadoop2.7/python/docs/source/user_guide/pandas_on_spark/pandas_pyspark.rst\n",
            "spark-3.2.0-bin-hadoop2.7/python/docs/source/user_guide/pandas_on_spark/index.rst\n",
            "spark-3.2.0-bin-hadoop2.7/python/docs/source/user_guide/pandas_on_spark/typehints.rst\n",
            "spark-3.2.0-bin-hadoop2.7/python/docs/source/user_guide/pandas_on_spark/transform_apply.rst\n",
            "spark-3.2.0-bin-hadoop2.7/python/docs/source/user_guide/pandas_on_spark/from_to_dbms.rst\n",
            "spark-3.2.0-bin-hadoop2.7/python/docs/source/user_guide/pandas_on_spark/faq.rst\n",
            "spark-3.2.0-bin-hadoop2.7/python/docs/source/user_guide/python_packaging.rst\n",
            "spark-3.2.0-bin-hadoop2.7/python/docs/source/user_guide/sql/\n",
            "spark-3.2.0-bin-hadoop2.7/python/docs/source/user_guide/sql/arrow_pandas.rst\n",
            "spark-3.2.0-bin-hadoop2.7/python/docs/source/user_guide/sql/index.rst\n",
            "spark-3.2.0-bin-hadoop2.7/python/docs/source/migration_guide/\n",
            "spark-3.2.0-bin-hadoop2.7/python/docs/source/migration_guide/pyspark_2.3.0_to_2.3.1_above.rst\n",
            "spark-3.2.0-bin-hadoop2.7/python/docs/source/migration_guide/index.rst\n",
            "spark-3.2.0-bin-hadoop2.7/python/docs/source/migration_guide/pyspark_2.4_to_3.0.rst\n",
            "spark-3.2.0-bin-hadoop2.7/python/docs/source/migration_guide/pyspark_1.0_1.2_to_1.3.rst\n",
            "spark-3.2.0-bin-hadoop2.7/python/docs/source/migration_guide/pyspark_2.3_to_2.4.rst\n",
            "spark-3.2.0-bin-hadoop2.7/python/docs/source/migration_guide/koalas_to_pyspark.rst\n",
            "spark-3.2.0-bin-hadoop2.7/python/docs/source/migration_guide/pyspark_1.4_to_1.5.rst\n",
            "spark-3.2.0-bin-hadoop2.7/python/docs/source/migration_guide/pyspark_2.2_to_2.3.rst\n",
            "spark-3.2.0-bin-hadoop2.7/python/docs/source/migration_guide/pyspark_3.1_to_3.2.rst\n",
            "spark-3.2.0-bin-hadoop2.7/python/docs/make.bat\n",
            "spark-3.2.0-bin-hadoop2.7/python/docs/Makefile\n",
            "spark-3.2.0-bin-hadoop2.7/python/lib/\n",
            "spark-3.2.0-bin-hadoop2.7/python/lib/PY4J_LICENSE.txt\n",
            "spark-3.2.0-bin-hadoop2.7/python/lib/py4j-0.10.9.2-src.zip\n",
            "spark-3.2.0-bin-hadoop2.7/python/lib/pyspark.zip\n",
            "spark-3.2.0-bin-hadoop2.7/python/run-tests\n",
            "spark-3.2.0-bin-hadoop2.7/python/setup.cfg\n",
            "spark-3.2.0-bin-hadoop2.7/licenses/\n",
            "spark-3.2.0-bin-hadoop2.7/licenses/LICENSE-respond.txt\n",
            "spark-3.2.0-bin-hadoop2.7/licenses/LICENSE-sbt-launch-lib.txt\n",
            "spark-3.2.0-bin-hadoop2.7/licenses/LICENSE-antlr.txt\n",
            "spark-3.2.0-bin-hadoop2.7/licenses/LICENSE-dagre-d3.txt\n",
            "spark-3.2.0-bin-hadoop2.7/licenses/LICENSE-pyrolite.txt\n",
            "spark-3.2.0-bin-hadoop2.7/licenses/LICENSE-sorttable.js.txt\n",
            "spark-3.2.0-bin-hadoop2.7/licenses/LICENSE-janino.txt\n",
            "spark-3.2.0-bin-hadoop2.7/licenses/LICENSE-protobuf.txt\n",
            "spark-3.2.0-bin-hadoop2.7/licenses/LICENSE-jquery.txt\n",
            "spark-3.2.0-bin-hadoop2.7/licenses/LICENSE-scopt.txt\n",
            "spark-3.2.0-bin-hadoop2.7/licenses/LICENSE-netlib.txt\n",
            "spark-3.2.0-bin-hadoop2.7/licenses/LICENSE-d3.min.js.txt\n",
            "spark-3.2.0-bin-hadoop2.7/licenses/LICENSE-graphlib-dot.txt\n",
            "spark-3.2.0-bin-hadoop2.7/licenses/LICENSE-AnchorJS.txt\n",
            "spark-3.2.0-bin-hadoop2.7/licenses/LICENSE-datatables.txt\n",
            "spark-3.2.0-bin-hadoop2.7/licenses/LICENSE-pmml-model.txt\n",
            "spark-3.2.0-bin-hadoop2.7/licenses/LICENSE-paranamer.txt\n",
            "spark-3.2.0-bin-hadoop2.7/licenses/LICENSE-jakarta-ws-rs-api\n",
            "spark-3.2.0-bin-hadoop2.7/licenses/LICENSE-dnsjava.txt\n",
            "spark-3.2.0-bin-hadoop2.7/licenses/LICENSE-jakarta.xml.bind-api.txt\n",
            "spark-3.2.0-bin-hadoop2.7/licenses/LICENSE-jakarta-annotation-api\n",
            "spark-3.2.0-bin-hadoop2.7/licenses/LICENSE-CC0.txt\n",
            "spark-3.2.0-bin-hadoop2.7/licenses/LICENSE-jodd.txt\n",
            "spark-3.2.0-bin-hadoop2.7/licenses/LICENSE-f2j.txt\n",
            "spark-3.2.0-bin-hadoop2.7/licenses/LICENSE-machinist.txt\n",
            "spark-3.2.0-bin-hadoop2.7/licenses/LICENSE-javolution.txt\n",
            "spark-3.2.0-bin-hadoop2.7/licenses/LICENSE-modernizr.txt\n",
            "spark-3.2.0-bin-hadoop2.7/licenses/LICENSE-spire.txt\n",
            "spark-3.2.0-bin-hadoop2.7/licenses/LICENSE-leveldbjni.txt\n",
            "spark-3.2.0-bin-hadoop2.7/licenses/LICENSE-join.txt\n",
            "spark-3.2.0-bin-hadoop2.7/licenses/LICENSE-zstd-jni.txt\n",
            "spark-3.2.0-bin-hadoop2.7/licenses/LICENSE-slf4j.txt\n",
            "spark-3.2.0-bin-hadoop2.7/licenses/LICENSE-arpack.txt\n",
            "spark-3.2.0-bin-hadoop2.7/licenses/LICENSE-jsp-api.txt\n",
            "spark-3.2.0-bin-hadoop2.7/licenses/LICENSE-JTransforms.txt\n",
            "spark-3.2.0-bin-hadoop2.7/licenses/LICENSE-JLargeArrays.txt\n",
            "spark-3.2.0-bin-hadoop2.7/licenses/LICENSE-bootstrap.txt\n",
            "spark-3.2.0-bin-hadoop2.7/licenses/LICENSE-reflectasm.txt\n",
            "spark-3.2.0-bin-hadoop2.7/licenses/LICENSE-javassist.html\n",
            "spark-3.2.0-bin-hadoop2.7/licenses/LICENSE-zstd.txt\n",
            "spark-3.2.0-bin-hadoop2.7/licenses/LICENSE-json-formatter.txt\n",
            "spark-3.2.0-bin-hadoop2.7/licenses/LICENSE-matchMedia-polyfill.txt\n",
            "spark-3.2.0-bin-hadoop2.7/licenses/LICENSE-scala.txt\n",
            "spark-3.2.0-bin-hadoop2.7/licenses/LICENSE-jakarta.activation-api.txt\n",
            "spark-3.2.0-bin-hadoop2.7/licenses/LICENSE-automaton.txt\n",
            "spark-3.2.0-bin-hadoop2.7/licenses/LICENSE-javax-transaction-transaction-api.txt\n",
            "spark-3.2.0-bin-hadoop2.7/licenses/LICENSE-jaxb-runtime.txt\n",
            "spark-3.2.0-bin-hadoop2.7/licenses/LICENSE-minlog.txt\n",
            "spark-3.2.0-bin-hadoop2.7/licenses/LICENSE-mustache.txt\n",
            "spark-3.2.0-bin-hadoop2.7/licenses/LICENSE-xmlenc.txt\n",
            "spark-3.2.0-bin-hadoop2.7/licenses/LICENSE-jline.txt\n",
            "spark-3.2.0-bin-hadoop2.7/licenses/LICENSE-istack-commons-runtime.txt\n",
            "spark-3.2.0-bin-hadoop2.7/licenses/LICENSE-py4j.txt\n",
            "spark-3.2.0-bin-hadoop2.7/licenses/LICENSE-vis-timeline.txt\n",
            "spark-3.2.0-bin-hadoop2.7/licenses/LICENSE-blas.txt\n",
            "spark-3.2.0-bin-hadoop2.7/licenses/LICENSE-re2j.txt\n",
            "spark-3.2.0-bin-hadoop2.7/licenses/LICENSE-kryo.txt\n",
            "spark-3.2.0-bin-hadoop2.7/licenses/LICENSE-cloudpickle.txt\n",
            "Collecting pyspark\n",
            "  Downloading pyspark-3.2.0.tar.gz (281.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 281.3 MB 34 kB/s \n",
            "\u001b[?25hCollecting py4j==0.10.9.2\n",
            "  Downloading py4j-0.10.9.2-py2.py3-none-any.whl (198 kB)\n",
            "\u001b[K     |████████████████████████████████| 198 kB 54.8 MB/s \n",
            "\u001b[?25hBuilding wheels for collected packages: pyspark\n",
            "  Building wheel for pyspark (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyspark: filename=pyspark-3.2.0-py2.py3-none-any.whl size=281805912 sha256=55971b4d8442684a65ebe5fdc36253271f3100694f0818e197e6e23723b6167f\n",
            "  Stored in directory: /root/.cache/pip/wheels/0b/de/d2/9be5d59d7331c6c2a7c1b6d1a4f463ce107332b1ecd4e80718\n",
            "Successfully built pyspark\n",
            "Installing collected packages: py4j, pyspark\n",
            "Successfully installed py4j-0.10.9.2 pyspark-3.2.0\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# ----- Download and install pyspark and all requirements -----\n",
        "\n",
        "# Download and install Java 8\n",
        "!apt-get update\n",
        "!apt-get install openjdk-8-jdk-headless -qq > /dev/null\n",
        "\n",
        "# Download Apache Spark binary: This link can change based on the version. Update this link with the latest version before using\n",
        "!wget -q https://downloads.apache.org/spark/spark-3.2.0/spark-3.2.0-bin-hadoop2.7.tgz\n",
        "\n",
        "# Unzip file\n",
        "!tar -xvzf spark-3.2.0-bin-hadoop2.7.tgz\n",
        "\n",
        "# Install findspark: Adds Pyspark to sys.path at runtime\n",
        "!pip install -q findspark\n",
        "\n",
        "# Install pyspark\n",
        "!pip install pyspark\n",
        "\n",
        "# Add environmental variables\n",
        "import os\n",
        "os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-8-openjdk-amd64\"\n",
        "os.environ[\"SPARK_HOME\"] = \"/content/spark-3.2.0-bin-hadoop2.7\"\n",
        "\n",
        "# findspark will locate spark in the system\n",
        "import findspark\n",
        "findspark.init()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Iniciamos Spark"
      ],
      "metadata": {
        "id": "EnZD01VPUzZs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql import SparkSession\n",
        "\n",
        "spark = SparkSession.builder \\\n",
        "        .master(\"local\") \\\n",
        "        .appName(\"Hands-on PySpark on Google Colab\") \\\n",
        "        .getOrCreate()\n",
        "\n",
        "spark"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 219
        },
        "id": "719YJxJWUTan",
        "outputId": "d4f319a6-54f4-4918-980f-c8576c8e39de"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "            <div>\n",
              "                <p><b>SparkSession - in-memory</b></p>\n",
              "                \n",
              "        <div>\n",
              "            <p><b>SparkContext</b></p>\n",
              "\n",
              "            <p><a href=\"http://d21edd5d4791:4040\">Spark UI</a></p>\n",
              "\n",
              "            <dl>\n",
              "              <dt>Version</dt>\n",
              "                <dd><code>v3.2.0</code></dd>\n",
              "              <dt>Master</dt>\n",
              "                <dd><code>local</code></dd>\n",
              "              <dt>AppName</dt>\n",
              "                <dd><code>Hands-on PySpark on Google Colab</code></dd>\n",
              "            </dl>\n",
              "        </div>\n",
              "        \n",
              "            </div>\n",
              "        "
            ],
            "text/plain": [
              "<pyspark.sql.session.SparkSession at 0x7fd4f07d6b50>"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Algoritmo 1: Term Frecuency (TF)"
      ],
      "metadata": {
        "id": "lqVFjpNoVdX9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Estructuramos la data y la mostramos"
      ],
      "metadata": {
        "id": "oyUs3NXvqlDo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql.types import *\n",
        "from pyspark import SparkConf, SparkContext\n",
        "\n",
        "# creamos el spark context\n",
        "sc =SparkContext.getOrCreate()\n",
        "\n",
        "# cargamos el archivo\n",
        "file_name = \"twitts.txt\"\n",
        "f = open(file_name)\n",
        "\n",
        "# estructuramos la data\n",
        "data = []\n",
        "count = 1\n",
        "for row in f:\n",
        "    if row != \"\\n\":\n",
        "        row = row.replace(\"\\n\",\"\")\n",
        "        data.append((count,row))\n",
        "        count += 1\n",
        "\n",
        "rows = sc.parallelize(data)\n",
        "rows.collect()\n"
      ],
      "metadata": {
        "id": "qvYpTBbKVWMn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cf586496-343f-4e15-e1aa-5d6ae40557c4"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[(1, 'protester stage diein protest store nyc anger misplace retweet agree'),\n",
              " (2,\n",
              "  'apple intraday comment update range premium user aapl stockaction trading stock mkt'),\n",
              " (3, 'ios app 2014 name elevate brain training iphone app'),\n",
              " (4, 'shit'),\n",
              " (5, 'founder attack boss ridiculous comment ad'),\n",
              " (6, 'evidence factcheckthis'),\n",
              " (7, 'educate'),\n",
              " (8, 'hard reach buy suicide squad comic_strip apple store turkey'),\n",
              " (9, 'delete music customer ipod'),\n",
              " (10,\n",
              "  'apple intraday comment update range premium user aapl stockaction trading stock mkt'),\n",
              " (11, 'studio 45,000 outlet computer need battery future'),\n",
              " (12, 'apple great business aapl investwall aapl'),\n",
              " (13, 'dear love iphone plus lot great achievement iphone reboot day fail'),\n",
              " (14,\n",
              "  'survey feedback iwatch positioning fashion accessory geek centric gadget'),\n",
              " (15, 'similar cloud backup picture onlinefootprint modicumofprudence'),\n",
              " (16, 'protester stage diein protest store nyc anger misplace retweet agree'),\n",
              " (17, 'fuck make shit product'),\n",
              " (18, 'try turn problem'),\n",
              " (19,\n",
              "  'macbook pro annoying asus window computer freezing laggy etc excellence'),\n",
              " (20,\n",
              "  'speak wearable new chargehr amp iphone want eat latke run place tl_chat'),\n",
              " (21,\n",
              "  'forbe whoop plaintiff apple tell court ipod owner class represent aapl'),\n",
              " (22, 'thanks 3-way call facetime call ability device seamlessly'),\n",
              " (23, 'mkt final aapl putcallratio monday december 2014'),\n",
              " (24, 'julian robertson bullish apple inc aapl'),\n",
              " (25,\n",
              "  'apple intraday comment update range premium user aapl stockaction trading stock mkt'),\n",
              " (26,\n",
              "  'new problem airport board pass phone hold scanner security applepay credit card take screen'),\n",
              " (27, 'help mac memory clear ask password old'),\n",
              " (28, 'ask use voice attribute dude ace vocal clone'),\n",
              " (29, 'fuck fuck hate'),\n",
              " (30, 'apple want commute easy accord new patent aapl'),\n",
              " (31, 'studio 45,000 outlet computer need battery future'),\n",
              " (32, 'need help apple iphone6 amp iphone6plus checkitout'),\n",
              " (33, 'invest terabyte storage'),\n",
              " (34, 'ceo warn wearable maker tech need productivity novelty like siri '),\n",
              " (35, 'gva lounge sight mac pc undetermined number ipxs aapl'),\n",
              " (36, 'afp request apple reveal warrant pushback tax evader rip aussie'),\n",
              " (37, 'protester stage diein protest store nyc anger misplace retweet agree'),\n",
              " (38, 'yeah monarchywpb sticker ride boommovement'),\n",
              " (39, 'afternoon tea ipadair2 touchpoint reward visit info'),\n",
              " (40, 'drain battery fix'),\n",
              " (41, '.@apple ceo visit'),\n",
              " (42,\n",
              "  'promoproduct supplier carry brandable compliant adapter headsaregoingtoroll'),\n",
              " (43, 'new sony'),\n",
              " (44, 'apple pay service lead price target upgrade apple inc aapl aapl'),\n",
              " (45, 'studio 45,000 outlet computer need battery future'),\n",
              " (46, 'go canal street knockoff cmonman pay lightning cord'),\n",
              " (47, 'excited name app store best 2014 list year apple'),\n",
              " (48, 'gold macbook'),\n",
              " (49, 'studio 45,000 outlet computer need battery future'),\n",
              " (50, 'hey teach people use pay'),\n",
              " (51, 'protester stage diein protest store nyc anger misplace retweet agree'),\n",
              " (52, 'well iphone app year accord apple monday december'),\n",
              " (53, 'protester stage diein protest store nyc anger misplace retweet agree'),\n",
              " (54, 'make smart elevate app year congratulation team'),\n",
              " (55, 'final aapl putcallratio monday december 2014 hamzei'),\n",
              " (56,\n",
              "  'game trader play market liquidity hft darkpool stock trading algorithm aapl'),\n",
              " (57, 'studio 45,000 outlet computer need battery future'),\n",
              " (58, 'cool cool bait switch pay upgrade server free upgd 10.10.1'),\n",
              " (59,\n",
              "  '.@apple macmail yosemite give hard time alternative email program yosemiteproblem'),\n",
              " (60,\n",
              "  '.@apple make hard spend money app functionality soon disappear today menu stop'),\n",
              " (61, 'congrat mary sotos green power leadership award'),\n",
              " (62, 'need battery game get time charge phone furstrate annoy charge'),\n",
              " (63, 'hoe'),\n",
              " (64,\n",
              "  'music library sync new music etc itunes tell sync complete new uploaded fix frustrating'),\n",
              " (65,\n",
              "  'apple make bad charger genius say wrap electrical tape wonder jony think'),\n",
              " (66, 'amp delete music customer ipod tell'),\n",
              " (67, 'studio 45,000 outlet computer need battery future'),\n",
              " (68, 'apple inc aapl price target eps estimate raise bmo'),\n",
              " (69, 'want android apple torrent?@apple'),\n",
              " (70,\n",
              "  'iphone ipad game 2014 apple name monument valley amp three tuesday december'),\n",
              " (71,\n",
              "  'apple intraday comment pre opening premium user aapl stockaction trading stock mkt'),\n",
              " (72, 'apple great business aapl'),\n",
              " (73,\n",
              "  'amazing customer service today utc store work form store hour tbjapodcast'),\n",
              " (74, 'aww look tht lot work guy good luck'),\n",
              " (75,\n",
              "  'kantar apple track record quarter iphone6 sale bump wednesday december'),\n",
              " (76, 'iphone battery life take piss sort iphone iphone apple'),\n",
              " (77, 'spy pair m50 good work'),\n",
              " (78, 'product line compete iphone6 vs. ipad need ipad long'),\n",
              " (79, 'dominate commerce device grab market share'),\n",
              " (80, 'try turn problem'),\n",
              " (81,\n",
              "  'apple iphone iphone4s iphone4problem fucking help work apple fucking help job cunt'),\n",
              " (82, 'idk happend'),\n",
              " (83, 'computer slow right make want shoot god dam mac hav deal'),\n",
              " (84, 'good iphone app year accord'),\n",
              " (85, 'computer science education week come check code opportunity help'),\n",
              " (86, 'protester stage diein protest store nyc anger misplace retweet agree'),\n",
              " (87, 'apple recent pullback buy opportunity aapl'),\n",
              " (88, 'know fix xcode simulator try complete reinstall ios'),\n",
              " (89, 'real tired charger break month'),\n",
              " (90, 'protester stage diein protest store nyc anger misplace retweet agree'),\n",
              " (91, 'twitter'),\n",
              " (92, 'fuck charger like shit'),\n",
              " (93,\n",
              "  'apple warm social medium apple hire social medium guru l.a finally tweet?her'),\n",
              " (94, 'thank good coverage nofear'),\n",
              " (95, 'apple hedge bet small iphone aapl'),\n",
              " (96, 'aapl ios8 browser share'),\n",
              " (97, 'bad idea bring tap tweet function guy'),\n",
              " (98,\n",
              "  '.@apple ban school yik yak app itunes app store app anonymous bullying amp threat'),\n",
              " (99,\n",
              "  'enjoy introduction connect launch event amazing edtech leader room txe'),\n",
              " (100, 'apple important stock earth aapl'),\n",
              " (101, 'go come'),\n",
              " (102, 'studio 45,000 outlet computer need battery future'),\n",
              " (103, 'blackberry want iphone pay '),\n",
              " (104, '  bbry bbry blackberry iphone aapl aapl'),\n",
              " (105, 'iupdate new need dun year ago web form phone ironic req support ie8'),\n",
              " (106, 'asshole shit'),\n",
              " (107, 'report apple hire fashionista help flog watch aapl aapl'),\n",
              " (108,\n",
              "  'apple build major new r&amp;d facility japan prime minister reveal aapl aapl'),\n",
              " (109,\n",
              "  'tim cook show apple watch chinese internet official discuss security issue aapl'),\n",
              " (110, 'translate app success story taus member global'),\n",
              " (111, 'lol quicktime movs'),\n",
              " (112, 'apple inc google inc battle tech giant aapl'),\n",
              " (113, 'big difference mac yep stick mac apple'),\n",
              " (114, 'studio 45,000 outlet computer need battery future'),\n",
              " (115, 'new 4-inch iphone report reason apple aapl aapl'),\n",
              " (116, 'office today remotesupport techlife'),\n",
              " (117, 'studio 45,000 outlet computer need battery future'),\n",
              " (118,\n",
              "  'jmp raise apple price target 130 150 reason jmp aapl stock wallstreet'),\n",
              " (119, 'protester stage diein protest store nyc anger misplace retweet agree'),\n",
              " (120, 'studio 45,000 outlet computer need battery future'),\n",
              " (121,\n",
              "  'aapl alabama anti discrimination bill name apple ceo tim cook...http://t.co/j6hgjmjbzd'),\n",
              " (122,\n",
              "  'apple intraday comment pre opening premium user aapl stockaction trading stock mkt'),\n",
              " (123, 'result mobility pilothouse program loyal customer'),\n",
              " (124, 'aapl apple donate portion profit fight aids...http://t.co/br05n1u3qr'),\n",
              " (125, 'bloombergtv stevejobs testimony play key role ipod trial aapl'),\n",
              " (126, 'apple macbook 949.86 tech'),\n",
              " (127, 'app ipodtouch5thgen'),\n",
              " (128, 'offensive thing lack trashcan emoji stop discrimination'),\n",
              " (129,\n",
              "  'major crisis avoid guy able restore daughter iphone great service thank 5starservice'),\n",
              " (130, 'tell feel'),\n",
              " (131, 'stop replace iphone unit defect scratch phone mean drop'),\n",
              " (132, 'live streaming blow'),\n",
              " (133,\n",
              "  'jmp raise apple inc price target 150 exceptionally strong demand aapl'),\n",
              " (134, 'phone keep fuck freezing'),\n",
              " (135, 'apple iphone lead time long previous model aapl aapl'),\n",
              " (136, 'sit home friday night wait invitation join dev team look phone day'),\n",
              " (137, 'apple raise barclay 140.00 overweight rating aapl aapl'),\n",
              " (138, 'iphone come rareearth'),\n",
              " (139, 'thisn#yosemite update stress macbookpro'),\n",
              " (140, 'aapl expect user like small screen iphone mini reportedly way aapl'),\n",
              " (141, '118 tomorrow aapl'),\n",
              " (142,\n",
              "  'frustrated unsuccessfully try fix outgoing smtp configuration lt;3 unacceptable yosemiteproblem apple help'),\n",
              " (143,\n",
              "  'apple intraday comment update premium user aapl stockaction trading stock mkt'),\n",
              " (144, 'official williamsburg long hip anymore'),\n",
              " (145, 'thing happen'),\n",
              " (146, 'definition easy warped thank useless corporate speak'),\n",
              " (147, 'dare fireball transmit ios icloud drive'),\n",
              " (148, 'protester stage diein protest store nyc anger misplace retweet agree'),\n",
              " (149,\n",
              "  'sign utterly break wifi driver air sit lap desperate read email android phone'),\n",
              " (150, 'gtat creditor want question apple jeff williams aapl aapl'),\n",
              " (151,\n",
              "  'aapl ipad mini sony xperia tablet compact step aside sony apple s...http://t.co/85qgeih7lo'),\n",
              " (152, 'fuck phone search service complete day'),\n",
              " (153, 'mkt final aapl putcallratio tuesday december 2014'),\n",
              " (154, 'damn wish iphone imessage money damn damm damn'),\n",
              " (155, 'thank disturb feature'),\n",
              " (156, '.@apple ceo visit'),\n",
              " (157, 'dear bad idea fix'),\n",
              " (158, 'power cord problem- warranty say fine replace'),\n",
              " (159, 'sooooo annoy restore lose voice mails need thank lot'),\n",
              " (160, 'ischool education'),\n",
              " (161, 'rumor roundup crescentgate gate aapl aapl'),\n",
              " (162, 'store nyc honor travel'),\n",
              " (163, 'tech stock soar 2015 motley fool goog aapl'),\n",
              " (164, 'apple raise canaccord genuity 135.00 buy rating aapl aapl'),\n",
              " (165, 'aapl apple stock price plummeting time sell bit'),\n",
              " (166, 'aapl fantastic investment future aapl beat aapl'),\n",
              " (167, 'consider ad feed facebook privacy change think tim cook spot'),\n",
              " (168, 'barclays raise aapl price target 140 aapl aapl'),\n",
              " (169, 'footage apple-1 computer run computerhistory'),\n",
              " (170, 'total nightmare big slice cake'),\n",
              " (171, 'apple launch 4-inch iphone year report aapl aapl'),\n",
              " (172, 'watch sdk monetizaton download watchkit soon possible'),\n",
              " (173,\n",
              "  'downgrade iphone obviously understand extra battery life morning dead'),\n",
              " (174, 'year goal apple free tired'),\n",
              " (175, 'hey nvm restart phone work'),\n",
              " (176, 'need eye roll emoji pronto'),\n",
              " (177, 'reason iphone imessage bruh well battery'),\n",
              " (178, 'studio 45,000 outlet computer need battery future'),\n",
              " (179, 'know smartwatch old fashioned clock face grandma need watch'),\n",
              " (180, 'good think go compete dropbox etc bad sign like macpro std 250'),\n",
              " (181, 'face'),\n",
              " (182, 'notice app instead free change alleged misleading labeling'),\n",
              " (183, 'studio 45,000 outlet computer need battery future'),\n",
              " (184, 'degree nice weather'),\n",
              " (185, 'aapl carl icahn cause new private equity bubble?'),\n",
              " (186, 'touch screen macbook'),\n",
              " (187, 'mkt final aapl putcallratio wednesday december 2014'),\n",
              " (188, 'delete unwanted photo time want recently delete folder'),\n",
              " (189, 'studio 45,000 outlet computer need battery future'),\n",
              " (190,\n",
              "  'apple patent iphone drop protection mechanism change device tuesday december'),\n",
              " (191, 'sketchy rumor claim apple plan new 4-inch iphone 2015 aapl'),\n",
              " (192,\n",
              "  'patent active fall protection system shift iphone midair technology fyi'),\n",
              " (193, 'studio 45,000 outlet computer need battery future'),\n",
              " (194, 'big spending consumer cyber monday '),\n",
              " (195, ' cybermonday paypal apple aapl ebay walmart wmt sale'),\n",
              " (196, 'cnbctv cramer apple real competition aapl'),\n",
              " (197, 'love phone thank base god'),\n",
              " (198, 'apple antitrust case hang balance antitrust wow ipod'),\n",
              " (199, 'bad thing update software computer update trash'),\n",
              " (200, 'come charger case hurr'),\n",
              " (201, 'day access passwd apple work new app calendar ecosystem achille'),\n",
              " (202, 'thing know today include hoard iphone6'),\n",
              " (203,\n",
              "  'hey love applecare low hold music awful prefer hear tip apple gear well use hold time'),\n",
              " (204, 'def get like watch'),\n",
              " (205,\n",
              "  '4-star analyst alex gauna jmp securities rate aapl buy alex success rate nasdaq stock aapl'),\n",
              " (206,\n",
              "  'confirm bose speaker return apple store removal early year aapl beatselectronic'),\n",
              " (207, 'app ipodtouch5thgen'),\n",
              " (208, 'hah defend understand internet'),\n",
              " (209,\n",
              "  'apple tentatively approve plan expand reseller network india 500 new store mac blog aapl'),\n",
              " (210, 'aapl android phone dominate 2018 ios phone revenue'),\n",
              " (211, 'aapl apple court billion line...http://t.co/mduqi14xqk'),\n",
              " (212, 'ayyy fourth phone charger week break today fuck'),\n",
              " (213, 'studio 45,000 outlet computer need battery future'),\n",
              " (214, '.@mcdonalds share slice iphone6 lover'),\n",
              " (215, 'nofear'),\n",
              " (216, 'shipping estimate 27-inch retina imac improve week mac blog aapl'),\n",
              " (217, 'security firm issue cheery 2015 prediction pay attract attack'),\n",
              " (218, 'pay taxis country'),\n",
              " (219,\n",
              "  'twdancecenter urbannutcracker store boylston 6.30pm enjoy krumpe meet director amp'),\n",
              " (220, '.@google unseats u.s classroom chromebook beat ipad'),\n",
              " (221,\n",
              "  'average mac user face malware threat year remain minor target mac blog aapl'),\n",
              " (222, 'ipod change order song playlist listen fly fuck okay'),\n",
              " (223, 'autocorrect change muslim awesome okay'),\n",
              " (224, 'protester stage diein protest store nyc anger misplace retweet agree'),\n",
              " (225, 'think want watch'),\n",
              " (226, 'evidence apple inc need refresh apple aapl'),\n",
              " (227, 'flip great apple iphone smash detect saturday'),\n",
              " (228, 'windows lappy work half price alternative'),\n",
              " (229, 'hey guy charger last fucking week'),\n",
              " (230, 'get iphone iphone6 iphone'),\n",
              " (231, 'studio 45,000 outlet computer need battery future'),\n",
              " (232, 'computer turn help'),\n",
              " (233, 'take month iphone6 plus king phablet aapl'),\n",
              " (234, 'studio 45,000 outlet computer need battery future'),\n",
              " (235, 'remove photo upload cover refund purchase base feature'),\n",
              " (236, 'autocorrect change muslim awesome okay'),\n",
              " (237, 'battery minute usage fix'),\n",
              " (238, 'mfn international trade key issue ebook appellate case say'),\n",
              " (239,\n",
              "  'apple watch top search engine list good wearable tech aapl iwatch applewatch'),\n",
              " (240, 'studio 45,000 outlet computer need battery future'),\n",
              " (241, 'apple inc sell million apple watch 2015 aapl'),\n",
              " (242, 'snapchat'),\n",
              " (243, 'hey look weird'),\n",
              " (244, 'wrap charger begin smoke well apple'),\n",
              " (245,\n",
              "  '.@panic inconsistency overall weirdness control appstore archive previous version easy downgrade'),\n",
              " (246, 'iphone release date need feature aapl aapl'),\n",
              " (247, 'dinner night leave computer charge fire happen house applecordfire'),\n",
              " (248, 'god dammit fuck'),\n",
              " (249, 'head store today yikes yay dayoffdutie'),\n",
              " (250, 'apple fade away stream video player market vod streaming'),\n",
              " (251, 'studio 45,000 outlet computer need battery future'),\n",
              " (252,\n",
              "  'try launch info ahead time telco marketing team nightmare thank ecomchat'),\n",
              " (253, 'good buy cut apple inc ipad price boost sale aapl ipad'),\n",
              " (254,\n",
              "  'take marketing convert shopper buyer amp create total sense experience'),\n",
              " (255, 'apple dilemma apple aapl aapl'),\n",
              " (256, 'chromebook overtake apple ipad u.s education market chromebook ipad'),\n",
              " (257,\n",
              "  'smartphone tablet home automation hub wireless protocol beat wifi bluetooth homekit flic'),\n",
              " (258,\n",
              "  'get love autocorrect iphone make person illiterate fuck quit guess let correct'),\n",
              " (259, 'yahootech admit year remove non itunes music ipod'),\n",
              " (260, 'apple bear fat payout stock swoon 60-second plunge aapl aapl'),\n",
              " (261, 'expect spanish inquisition aapl'),\n",
              " (262, 'news raise bill pre 164.5 bill cash good time valley wait'),\n",
              " (263, 'apple dominate mobile online shopping percent aapl'),\n",
              " (264, 'tim cook 100 billion mistake aapl'),\n",
              " (265, 'osx build keylogger provide'),\n",
              " (266, 'game bitch try tonight gams night gawd'),\n",
              " (267, 'learn apple ipad air 128 gold'),\n",
              " (268, 'block trade detect aapl'),\n",
              " (269, \"split valley user datum say totally amp say,'like titianfight\"),\n",
              " (270, 'rumor surface apple iphone6s iphone7 2015 wednesday december'),\n",
              " (271, 'dear '),\n",
              " (272,\n",
              "  ' fault pos macbook airquote pro fast port drop pro future toycomputer'),\n",
              " (273, 'note mail trouble send update fix mail send useful'),\n",
              " (274, 'protester stage diein protest store nyc anger misplace retweet agree'),\n",
              " (275, 'apple plan launch iphone mini version 2015 aapl aapl'),\n",
              " (276, 'tell update stop capitalize'),\n",
              " (277, 'protester stage diein protest store nyc anger misplace retweet agree'),\n",
              " (278, 'harry potter emojis work'),\n",
              " (279, 'protester stage diein protest store nyc anger misplace retweet agree'),\n",
              " (280,\n",
              "  'news apple patent prevent cracked iphone apple award patent gravity defy'),\n",
              " (281, 'ios app 2014 name elevate brain training iphone app'),\n",
              " (282, 'excited name app store best 2014 list year apple'),\n",
              " (283, 'apple plan launch iphone mini version 2015 aapl aapl'),\n",
              " (284, 'iphone plus availability wait time update aapl aapl'),\n",
              " (285, 'obviously left multi talented super successful gay business agenda'),\n",
              " (286,\n",
              "  'sunrise northamptonshire northampton wow sunrise morning iphone6 apple sun'),\n",
              " (287, 'talk town crescentgate'),\n",
              " (288, 'lose factor recovery key permanently lock apple aapl'),\n",
              " (289, 'get nigga turban sista headscarf'),\n",
              " (290,\n",
              "  'apple inc samsung group continue fight sub-$1 billion award loom aapl aapl'),\n",
              " (291, 'week iphone push currently'),\n",
              " (292, 'apple fibonacci technical level intraday update aapl aapl'),\n",
              " (293, 'studio 45,000 outlet computer need battery future'),\n",
              " (294, 'hey keyboard phone sort drunk morning send help pls thx'),\n",
              " (295, 'nice iphone get pity happen'),\n",
              " (296, 'protester stage diein protest store nyc anger misplace retweet agree'),\n",
              " (297,\n",
              "  'sunrise northamptonshire northampton wow sunrise morning iphone6 apple sun'),\n",
              " (298, 'aapl market cap pass 700 billion tablet sale slump'),\n",
              " (299, 'programming language code analysis web tech nerdup'),\n",
              " (300, 'apple price target rise 140 apple aapl'),\n",
              " (301, 'apple fibonacci technical level intraday update aapl aapl'),\n",
              " (302, 'harry potter emojis work'),\n",
              " (303, 'hey fuck phone speaker long work'),\n",
              " (304, 'win digital makeover giveaway 1000 gc,#ipad macbook pin'),\n",
              " (305, 'annoying stuff right time'),\n",
              " (306, 'iflipphone'),\n",
              " (307,\n",
              "  'apple 115 fit 8.4 increase earning use 2014q3 eps=$1.42 free ios app donkey stock aapl'),\n",
              " (308, 'stevejobs email want smear competitor hackers aapl'),\n",
              " (309, 'apple delete rival music ipod court hears apple itune ipod'),\n",
              " (310, 'innovation die steve job apple macintosh aapl'),\n",
              " (311, 'love iphone6 mobilephone'),\n",
              " (312, 'update yosemite machine painfully slow thank'),\n",
              " (313, 'poor try ipad macbook look useful commercial close power pro'),\n",
              " (314,\n",
              "  'foxconn robots prove unsuitable iphone assembly update version work aapl'),\n",
              " (315, 'bbc news evidence late steve job music trial aapl '),\n",
              " (316,\n",
              "  'photo love ios love ios8 nocrop iphone young phone screen capturescream boy'),\n",
              " (317, 'yosemite ruin wifi'),\n",
              " (318,\n",
              "  'innovation sector large multipli effect come job employ 13,000 create 70,000 indirect job'),\n",
              " (319, 'roll webgl ios8 month ago overtook webgl support level'),\n",
              " (320,\n",
              "  'hey battery iphone drop like cock gay porn xvideos main page fix shit'),\n",
              " (321, 'announce app 2014 favourite app list appstore2014'),\n",
              " (322, 'watch steve wozniak use iphone6 magically unlock hotel room woz'),\n",
              " (323, 'charger suck'),\n",
              " (324, 'ios8 delete contact actually delete fml fuck'),\n",
              " (325, 'studio 45,000 outlet computer need battery future'),\n",
              " (326, 'macbook pro non retina startup macbook macbookpro startup hipster'),\n",
              " (327, 'apple need china love apple watch aapl aapl'),\n",
              " (328,\n",
              "  'check macbook pro 15.4 retina 2.6 ghz 500 ssd mid 2012 650 2magsafe apple'),\n",
              " (329,\n",
              "  'apple pay add issuer l&amp;n federal credit union credit union m&amp;t bank aapl aapl'),\n",
              " (330, 'studio 45,000 outlet computer need battery future'),\n",
              " (331,\n",
              "  'apple warm social medium apple hire social medium guru l.a fin startup nyc'),\n",
              " (332, 'hines staff newly issue connect macbook ipad mini txe txe'),\n",
              " (333, 'happy'),\n",
              " (334, 'time buy dip apple inc stock aapl aapl'),\n",
              " (335, 'twitter problem'),\n",
              " (336, 'protester stage diein protest store nyc anger misplace retweet agree'),\n",
              " (337, 'studio 45,000 outlet computer need battery future'),\n",
              " (338, 'protester stage diein protest store nyc anger misplace retweet agree'),\n",
              " (339, 'hey catch fucking maverick wave iphone think surfsupsamsung'),\n",
              " (340,\n",
              "  'lack equal access technology place student minority disadvantage education great equalizer txe'),\n",
              " (341, 'studio 45,000 outlet computer need battery future'),\n",
              " (342,\n",
              "  'aapl steve jobs defend apple tape deposition...http://t.co/7oxigddequ'),\n",
              " (343, 'get powerbeats2 repair shoutout'),\n",
              " (344, 'block trade detect aapl'),\n",
              " (345, 'fuck recently delete photo album'),\n",
              " (346, 'legendary designer give young designer simple rule follow'),\n",
              " (347, 'robot fabricando iphone ipad pro apple watch apple sunday december'),\n",
              " (348, 'displeased lack bdsm themed emojis'),\n",
              " (349, 'harry potter emojis work'),\n",
              " (350, 'apple enter era security fear mongering security vendor aapl aapl'),\n",
              " (351, 'apple inc seo walk mystery aapl'),\n",
              " (352, 'studio 45,000 outlet computer need battery future'),\n",
              " (353,\n",
              "  'steve wozniak star upcoming reality focus futuristic tech mac blog aapl'),\n",
              " (354, 'elgato launches thunderbolt dock resolution support mac blog aapl'),\n",
              " (355,\n",
              "  'force people use vpn build ios8 button work ff like want apple nsa data collection service'),\n",
              " (356, 'new item come product start tweaking'),\n",
              " (357,\n",
              "  'overheard employee tell some1 use capital letter password cause easy remember applefail'),\n",
              " (358, 'dear lovin heck navigation arrow itunes store use software'),\n",
              " (359,\n",
              "  'aapl stock mini flash crash today money morning analyst suggest widel'),\n",
              " (360, 'apple green company america energy efficiency'),\n",
              " (361, 'cnbctv day apple antitrust trial aapl'),\n",
              " (362, 'apple important stock earth apple inc aapl seek alpha'),\n",
              " (363,\n",
              "  'important apple developer world need people invent stuff tim cook ceo'),\n",
              " (364, 'logjn amp reorder tweet 2step auth share password amp say malware'),\n",
              " (365, 'final aapl putcallratio monday december 2014'),\n",
              " (366, 'apple fibonacci technical level intraday update aapl aapl'),\n",
              " (367, 'iphone alarm fail work miss bonus point class sooooo annoy'),\n",
              " (368, '2015 year biometric wearable cryptocurrency stream aapl aapl'),\n",
              " (369, 'protester stage diein protest store nyc anger misplace retweet agree'),\n",
              " (370, 'thestreet google major headache go 2015 apple facebook aapl goog'),\n",
              " (371, 'come aapl shit'),\n",
              " (372, '45,000 foot keeeppppp flyinggggg'),\n",
              " (373, 'fuck'),\n",
              " (374, 'fuck goddamn stupid fuck justsayin itune'),\n",
              " (375, 'learn apple ipad mini smart cover green'),\n",
              " (376,\n",
              "  '.@apple market share smartphone market drive iphone great sale apple store'),\n",
              " (377,\n",
              "  'apple intraday comment update range premium user aapl stockaction trading stock mkt'),\n",
              " (378, 'apple release ios 8.1.2 fix disappear ringtone issue aapl'),\n",
              " (379, 'aapl apple share repurchase benefit shareholder billion'),\n",
              " (380, 'go sell stuff provide visibility order system'),\n",
              " (381,\n",
              "  'apple intraday comment update premium user aapl stockaction trading stock mkt'),\n",
              " (382,\n",
              "  'mark word wild away iphone bring iphone ultimate form factor welcome iphone mini'),\n",
              " (383, 'happen'),\n",
              " (384, 'justice department cite 18th century federal law unlock iphone'),\n",
              " (385, 'immune bug like like people spend time choosewisely'),\n",
              " (386, 'apple fibonacci technical level intraday update aapl aapl'),\n",
              " (387, 'apple inc catch iphone supply lag demand aapl'),\n",
              " (388,\n",
              "  'aapl apple inc aapl fall week monday morning drop...http://t.co/ut65kwzukc'),\n",
              " (389, 'studio 45,000 outlet computer need battery future'),\n",
              " (390, 'explore apple rumour 2015 apple2015 techireland'),\n",
              " (391,\n",
              "  'aapl buy reiterate target raise 135 canaccord genuity aapl brief explanation aapl'),\n",
              " (392, 'apple inc explosive quarter jmp analyst aapl'),\n",
              " (393, 'harry potter emojis work'),\n",
              " (394, 'thank think upgrading'),\n",
              " (395, 'big thing wireless earbuds aka earplug sound soundplug'),\n",
              " (396, 'ipod lawsuit reveal unseen steve job video'),\n",
              " (397, 'sound like need upgrade iphone spacious purse hold item tl_chat'),\n",
              " (398,\n",
              "  \"aapl:'fast money recap energy company ebb flow oil prices...http://t.co/qrwllgclk6\"),\n",
              " (399, 'belong employeediscount'),\n",
              " (400,\n",
              "  'thank push yosemite bad slow clunky cantgoback misssnowleopard whathappene'),\n",
              " (401, 'holiday giveaway ensure stay touch brand like'),\n",
              " (402, 'watcha soldering iron woz computer swap cap'),\n",
              " (403, 'alarm set ringer refuse work fuck'),\n",
              " (404, 'follow pls'),\n",
              " (405,\n",
              "  'nasdaq100 recent market exit sell aapl long 10.49 gain day aapl forex trade stock'),\n",
              " (406, 'tre'),\n",
              " (407,\n",
              "  'try buy charger protest nyc wecantbreathe 5thave apple store fifth avenue'),\n",
              " (408, 'gorgeous iphone app surprising design amazing visual bgr aapl'),\n",
              " (409, 'studio 45,000 outlet computer need battery future'),\n",
              " (410,\n",
              "  'aapl horseman nasdaq 100 apple microsoft gilead scie...http://t.co/cdvozfgsbx'),\n",
              " (411, 'shit'),\n",
              " (412, 'good get new shiny mac handy'),\n",
              " (413, 'save ton money buy iphone aapl'),\n",
              " (414, 'merge multiple apple fail'),\n",
              " (415,\n",
              "  'promoproduct supplier carry brandable compliant adapter headsaregoingtoroll'),\n",
              " (416, 'studio 45,000 outlet computer need battery future'),\n",
              " (417, 'love support hourofcode workshop'),\n",
              " (418,\n",
              "  'iscuba 360 degree camera rig cloud mobile game surface imask underwaterwearable cardboard pivot'),\n",
              " (419, 'protester stage diein protest store nyc anger misplace retweet agree'),\n",
              " (420, 'twitter'),\n",
              " (421, 'try turn problem'),\n",
              " (422, 'recent apple inc lawsuit hurt share price aapl'),\n",
              " (423, 'problem blame anybody like join roster'),\n",
              " (424, 'ditch tomtom license map datum'),\n",
              " (425, 'protester stage diein protest store nyc anger misplace retweet agree'),\n",
              " (426,\n",
              "  'aapl apple iphone lead time long previous models...http://t.co/2bgo33v309'),\n",
              " (427, 'final aapl putcallratio wednesday december 2014'),\n",
              " (428,\n",
              "  'apple nasdaq aapl participate world aids day campaign apple aapl campaign'),\n",
              " (429, 'bloombergtv apple exec sentence year prison fraud aapl'),\n",
              " (430,\n",
              "  'mistake it´s time replace fix 2011 macbook pro graphic failure mbp2011'),\n",
              " (431, 'get patent 2prevent crack screen rotate fall iphone bigdocc'),\n",
              " (432, 'studio 45,000 outlet computer need battery future'),\n",
              " (433, 'fuck'),\n",
              " (434, 'studio 45,000 outlet computer need battery future'),\n",
              " (435, 'play game'),\n",
              " (436, 'aapl unsubsidized smartphone 25...http://t.co/frqhiwnfp5'),\n",
              " (437, 'hey software update ipad open webpage idea'),\n",
              " (438, 'hopefully bday believe second dear'),\n",
              " (439, 'month store visit call iphone receive text non customer fail'),\n",
              " (440, 'great crack screen amp die battery think trade new'),\n",
              " (441, 'apple raise citigroup inc 135.00 aapl aapl'),\n",
              " (442, 'yes love stuff work thank'),\n",
              " (443, 'block trade detect aapl'),\n",
              " (444, 'ask friend'),\n",
              " (445, 'mark zuckerberg take shoot apple aapl'),\n",
              " (446, 'well charger fam cheap cuz get job'),\n",
              " (447, 'shopping pay receive good flight far well custserv'),\n",
              " (448, 'iphone autocorrecte believe beiber hard guy need'),\n",
              " (449, 'charger weak needa iphone charger otterboxe cord'),\n",
              " (450, 'laptop battery go straight'),\n",
              " (451, 'hide gray controller dvd player heck'),\n",
              " (452, 'reply livingthedream ~ari'),\n",
              " (453, 'thank'),\n",
              " (454, 'studio 45,000 outlet computer need battery future'),\n",
              " (455,\n",
              "  'apple hiring map engineer work improve community crowdsourcing siri passbook integration aapl'),\n",
              " (456, 'morph action police praetorian guard work unaware rich'),\n",
              " (457, 'dear write give mean want word give word typo'),\n",
              " (458, '2014 canadian flag emoji keyboard'),\n",
              " (459, 'steal apple'),\n",
              " (460,\n",
              "  'help store rep tell itunes backup save multiple backup back phone old backup go'),\n",
              " (461, 'studio 45,000 outlet computer need battery future'),\n",
              " (462, 'world murder facetime thank innovation'),\n",
              " (463, 'obsession'),\n",
              " (464, 'dear replace phone battery suck'),\n",
              " (465, 'studio 45,000 outlet computer need battery future'),\n",
              " (466, 'cnbctv drive apple aapl'),\n",
              " (467,\n",
              "  'tweet nandos phone put cap like iphone know favourite restaurant good phone'),\n",
              " (468, 'thank little troll put option close right save tab legends'),\n",
              " (469, 'apple inc catch iphone supply lag demand aapl'),\n",
              " (470, 'fact itune update make anal reset play count mosttttt'),\n",
              " (471, 'horrible packaging shipping shame'),\n",
              " (472, 'walk anna pick iphone 128 address'),\n",
              " (473, \"remind tomorrow f'e tell update want install actually\"),\n",
              " (474,\n",
              "  'apple corporate raider sell weak product stop work weeks&amp;apple get warranty claim dampness'),\n",
              " (475, 'studio 45,000 outlet computer need battery future'),\n",
              " (476, 'protester stage diein protest store nyc anger misplace retweet agree'),\n",
              " (477, 'studio 45,000 outlet computer need battery future'),\n",
              " (478, 'apple name 10th disruptive idea past year businessweek aapl aapl'),\n",
              " (479, 'studio 45,000 outlet computer need battery future'),\n",
              " (480,\n",
              "  'apple dec trade daily profit 1.57 weekly profit 18.36 aapl stockaction trading stock mkt  '),\n",
              " (481,\n",
              "  'apple iphone gain significant share japan germany great britain aapl aapl'),\n",
              " (482, 'protester stage diein protest store nyc anger misplace retweet agree'),\n",
              " (483, 'otter emoji'),\n",
              " (484, 'aapl samsung ask appeal court throw 930 million damage apple'),\n",
              " (485,\n",
              "  'condosenior say need supply condo dedicated tech issue iphone imac ipad warrant tech eat'),\n",
              " (486, 'wait okay yeah actually burn'),\n",
              " (487, 'thank fix swift sourcekit crash xcode life well'),\n",
              " (488, 'aapl apple inc facebook clash wrong...http://t.co/uuvn8tkrrs'),\n",
              " (489, 'foreign currency exchange headwind apple aapl aapl'),\n",
              " (490, 'studio 45,000 outlet computer need battery future'),\n",
              " (491, 'protester stage diein protest store nyc anger misplace retweet agree'),\n",
              " (492, 'stevejob predict future ecommerce 1996 get exactly right aapl'),\n",
              " (493, 'detail apple inc ipad mini reveal aapl'),\n",
              " (494, 'studio 45,000 outlet computer need battery future'),\n",
              " (495,\n",
              "  'strategic step time trading stock future forex trader baba aapl gpro eem esignal'),\n",
              " (496, 'hope use glass new store williamsburg '),\n",
              " (497, ' afraid sikrikim tzimerman break'),\n",
              " (498, 'studio 45,000 outlet computer need battery future'),\n",
              " (499, 'logic board completely replace warranty free sure'),\n",
              " (500, 'osx build keylogger provide'),\n",
              " (501, 'phone automatically reason kinda dumb thank'),\n",
              " (502, 'yay customer support super nice helpful imessage verify'),\n",
              " (503, 'special education staff work hard behalf student disability ed1426'),\n",
              " (504, 'guru fund manager hold apple aapl'),\n",
              " (505, 'harry potter emojis work'),\n",
              " (506, 'fix phone'),\n",
              " (507, 'apple important stock earth aapl'),\n",
              " (508, 'calls wit amanda end fix urself'),\n",
              " (509, 'fight fight fight'),\n",
              " (510, 'bring classicipod cantbelieveitsgone'),\n",
              " (511,\n",
              "  'strike somewhat stupid send brand new iphone late software restore old stuff'),\n",
              " (512, 'year loss apple finally claw market share android aapl aapl'),\n",
              " (513, 'gosh darnit know cloud'),\n",
              " (514, 'setting use app location app instead'),\n",
              " (515, 'love support hourofcode workshop'),\n",
              " (516, 'studio 45,000 outlet computer need battery future'),\n",
              " (517, 'protester stage diein protest store nyc anger misplace retweet agree'),\n",
              " (518, 'archetype figure product intuitive'),\n",
              " (519, 'iphone fucked thank great help new iphone'),\n",
              " (520, 'mother'),\n",
              " (521, 'protester stage diein protest store nyc anger misplace retweet agree'),\n",
              " (522, 'think upgrade yosemite think twice asmsg'),\n",
              " (523, 'need eye roll emoji pronto'),\n",
              " (524, 'ahhhh store course'),\n",
              " (525, 'protester stage diein protest store nyc anger misplace retweet agree'),\n",
              " (526, 'great piece amp new red app store profit exclusive content'),\n",
              " (527,\n",
              "  'ipad mini time startup ipadmini ipad macbook macbookpro startup hipster unbox'),\n",
              " (528, 'studio 45,000 outlet computer need battery future'),\n",
              " (529, 'apple fibonacci technical level intraday update aapl aapl'),\n",
              " (530, 'thank preview smartwatch fitnesstracker quantifiedself iot'),\n",
              " (531, 'iphone plus apple sprint give bread trash ass phone fuck up'),\n",
              " (532, 'fuck'),\n",
              " (533, 'apple inc weekly roundup facebook ads amp ipad aapl'),\n",
              " (534, 'kantar worldpanel iphone sale october huge aapl aapl'),\n",
              " (535, 'meet elevate apple pick good iphone app year monday december'),\n",
              " (536, 'protester stage diein protest store nyc anger misplace retweet agree'),\n",
              " (537, 'apple open new research site japan aapl aapl'),\n",
              " (538, 'protester stage diein protest store nyc anger misplace retweet agree'),\n",
              " (539, 'massive mobile tech company like excite wearable invest million '),\n",
              " (540, 'man chromecast pretty sweet'),\n",
              " (541, 'cnbctv buy apple pullback aapl'),\n",
              " (542, 'sorry go hope fix real pain apple care cover free'),\n",
              " (543, 'wow family guy simpson dowmload old update need update wait'),\n",
              " (544, 'big fan watch'),\n",
              " (545, 'studio 45,000 outlet computer need battery future'),\n",
              " (546, 'protester stage diein protest store nyc anger misplace retweet agree'),\n",
              " (547, '.@apple kill genius bar reservation online mac apple store'),\n",
              " (548, 'wish prosecute admin violation privacy criminal search seizure'),\n",
              " (549, 'patent number patent 8,903,519'),\n",
              " (550,\n",
              "  'bose product reportedly set return apple store shelf early week aapl jimmyiovine'),\n",
              " (551, 'kid parent need monitor power cord daily sure safe applecordfire'),\n",
              " (552, 'studio 45,000 outlet computer need battery future'),\n",
              " (553,\n",
              "  'youtube apple app update streamline interface video advertisement aapl'),\n",
              " (554, 'fix'),\n",
              " (555, 'studio 45,000 outlet computer need battery future'),\n",
              " (556, 'charger suck ass love break'),\n",
              " (557, 'thing buy iphone come replace battery month'),\n",
              " (558, 'new phone christmas spreadsomejoy'),\n",
              " (559, 'tree know maybe cop cig deal senseless'),\n",
              " (560, 'ciosynergy ciolosangele give away tv visit'),\n",
              " (561, 'apple ceo tim cook come gay'),\n",
              " (562, 'enjoy garageband garageband'),\n",
              " (563, 'watch'),\n",
              " (564, 'studio 45,000 outlet computer need battery future'),\n",
              " (565, 'hang loose'),\n",
              " (566, 'final aapl putcallratio monday december 2014'),\n",
              " (567, 'apple aapl plan launch iphone6 mini version 2015 monday december'),\n",
              " (568, 'awesome invent peanut butter sandwich technology phone'),\n",
              " (569, 'yeah thing inspire apple course apple++ 2002 tvad'),\n",
              " (570,\n",
              "  'interesting job wth crowdsourcing tip map community client software engineer'),\n",
              " (571, 'phone die let happen'),\n",
              " (572, 'harry potter emojis work'),\n",
              " (573, 'ubs see apple inc aapl iphone sale aapl'),\n",
              " (574, 'conclusion good client service'),\n",
              " (575,\n",
              "  'dashlane introduces password changer allow user change multiple password click mac blog aapl'),\n",
              " (576,\n",
              "  'estimate trillion market cap apple far fetched fundamental algorithmic analysis aapl'),\n",
              " (577, 'fuck'),\n",
              " (578, 'similar exist app call cardio guru interestingly maybe apple notice'),\n",
              " (579, 'hour hold customer service try figure messup'),\n",
              " (580, 'product write paper '),\n",
              " (581, ' photo credit iphone'),\n",
              " (582, 'robot fabricando iphone ipad pro apple watch apple sunday december'),\n",
              " (583, 'literally go iphone cord little year fix suck'),\n",
              " (584, 'know iphone die like'),\n",
              " (585, 'apple ceo tim cook come gay'),\n",
              " (586, 'genius bar@apple store helpful aapl staff help genius comp wke'),\n",
              " (587, 'love support hourofcode workshop'),\n",
              " (588, 'go fix map app navigation suck face switch google map'),\n",
              " (589,\n",
              "  'apple continue beef digital audio expertise hire dana massie audience aapl aapl'),\n",
              " (590, 'apple sale top chromecast aapl push apple inc aapl fuss'),\n",
              " (591, 'iwatch change face watch applenew iwatch gadget'),\n",
              " (592, 'well design iphone app world accord'),\n",
              " (593, 'studio 45,000 outlet computer need battery future'),\n",
              " (594, 'week replace harddrive ridiculous homework'),\n",
              " (595, 'apple bear pay contract double amid drop aapl'),\n",
              " (596, 'enterprise developer agreement wait 719 seven nineteen page'),\n",
              " (597, 'learn apple ipad mini smart cover pink md968ll'),\n",
              " (598,\n",
              "  'apple dec total trading daily profit 2.78 aapl stockaction trading stock mkt'),\n",
              " (599, 'wrong'),\n",
              " (600, 'tablet damn right'),\n",
              " (601,\n",
              "  'aapl invest tsla increase r&amp;d plus increase production multi fold car suv 2015 amp china supercharge'),\n",
              " (602, 'disrespectful'),\n",
              " (603, 'dear'),\n",
              " (604, 'studio 45,000 outlet computer need battery future'),\n",
              " (605, 'need texas flag emoji'),\n",
              " (606, 'protester stage diein protest store nyc anger misplace retweet agree'),\n",
              " (607,\n",
              "  'apple warm social medium apple hire social medium guru l.a finally tweet?her'),\n",
              " (608, 'update apple healthkit see early adoption aapl'),\n",
              " (609,\n",
              "  'apple loop iphone6s rumor steve job garage myth iphone speculation saturday december'),\n",
              " (610,\n",
              "  '.@apple reportedly hire fashion focus staff physical store ftdaily fashiontech'),\n",
              " (611, 'brass band store broadway winterseve nyc'),\n",
              " (612, 'proof use product freak mail show search file finder '),\n",
              " (613, ' nut kicks'),\n",
              " (614,\n",
              "  'aapl google tops apple //feeds.foxbusiness.com/~r foxbusiness video/~3/-dbuio5m0_m/'),\n",
              " (615, 'hey album phone'),\n",
              " (616, 'need china love applewatch aapl wearable wearabletech apple'),\n",
              " (617, 'cnbctv apple exec stand aapl'),\n",
              " (618, 'studio 45,000 outlet computer need battery future'),\n",
              " (619, 'protester stage diein protest store nyc anger misplace retweet agree'),\n",
              " (620, 'apple inc go trial anti trust charge today aapl'),\n",
              " (621,\n",
              "  'completely love iphone6 right play newphone amp dig day complete pizza'),\n",
              " (622, 'excited name app store best 2014 list year apple'),\n",
              " (623, 'bad idea bring tap tweet function guy'),\n",
              " (624, 'product shit break 24/7 ruin life'),\n",
              " (625,\n",
              "  'slow food movement metaphor platform strategy apple iphone ipad apple watch aapl'),\n",
              " (626, 'studio 45,000 outlet computer need battery future'),\n",
              " (627, 'good product boycott forever'),\n",
              " (628, 'date clone come'),\n",
              " (629, 'reason hate'),\n",
              " (630,\n",
              "  'seriously ing hate new version itunes spend hour try figure synch without delete'),\n",
              " (631, 'case accident download free app winnipeg'),\n",
              " (632, 'jmp securities think apple inc go 150 time sell aapl'),\n",
              " (633, 'sync folder'),\n",
              " (634, 'computer sux fix'),\n",
              " (635, 'difficult help product waste minute life online'),\n",
              " (636,\n",
              "  'alabama state representative anti discrimination bill tim cook aapl apple timcook'),\n",
              " (637, 'studio 45,000 outlet computer need battery future'),\n",
              " (638, 'life soon'),\n",
              " (639, 'god play forreal'),\n",
              " (640, 'order osx like network clone copy ideas?@appieofflciai'),\n",
              " (641, 'maybe stop whore sleep'),\n",
              " (642, 'studio 45,000 outlet computer need battery future'),\n",
              " (643,\n",
              "  'apple iphone plus retina imac ship time improve time holiday aapl aapl'),\n",
              " (644, 'aapl time start buy apple?'),\n",
              " (645, 'worry crash stop'),\n",
              " (646, 'plane amazing look cool yes need battery write list'),\n",
              " (647, 'job say apple take pain protect record contract stevejobs aapl'),\n",
              " (648, 'want delete email turn'),\n",
              " (649,\n",
              "  'iphone6 plus availability wait time update apple store verizon sunday december'),\n",
              " (650, 'apple plan support 500 apple reseller india focus ios aapl'),\n",
              " (651,\n",
              "  'aapl pale hoarse steve job defend apple videotape deposition ipod...http://t.co/snmpsx4tdo'),\n",
              " (652, 'howto import objective code bridge header file sdk swift'),\n",
              " (653, 'studio 45,000 outlet computer need battery future'),\n",
              " (654, 'fix problem good change logic board check apple genius'),\n",
              " (655,\n",
              "  'refusal application app store uphold australian federal court apple appeal'),\n",
              " (656, 'new iphone free apple share invest stock aapl'),\n",
              " (657, 'apple inc ceo donate 291k pennsylvania school district aapl'),\n",
              " (658, 'apple inc price close december 2014 114.9801 apple aapl'),\n",
              " (659, 'steve wozniak call legendary garage bit myth'),\n",
              " (660, 'thing know today include hoard iphone6'),\n",
              " (661, 'know suck store lock week preordere smh'),\n",
              " (662, 'alabama anti discrimination bill name'),\n",
              " (663, 'battery die long live apple sell new battery new iphone 500'),\n",
              " (664, 'studio 45,000 outlet computer need battery future'),\n",
              " (665, 'hey guy charger last fucking week'),\n",
              " (666, 'think happen hate day'),\n",
              " (667,\n",
              "  'want drop word book product employee start treat machine care aka stop drop'),\n",
              " (668, 'everybody track stuff usps great small package tracking'),\n",
              " (669,\n",
              "  '.@dell order laptop today try instead maybe rep kind instead behavior'),\n",
              " (670,\n",
              "  'realworld etnui magicleap spin collection dream thought discussion share'),\n",
              " (671,\n",
              "  'myth vs. reality time trading stock future forex trader aapl gpro esignal'),\n",
              " (672, 'studio 45,000 outlet computer need battery future'),\n",
              " (673, 'apple watch hackathon app challenge emerge aapl aapl'),\n",
              " (674, 'aapl apple store host free code workshop second annual hour code'),\n",
              " (675, 'love samsung kristen bell watch weekend new ad'),\n",
              " (676, 'caller able block product apple iphone6 iphone6plus'),\n",
              " (677, 'profit apple aapl option trade trading finance short bet hedge'),\n",
              " (678, 'studio 45,000 outlet computer need battery future'),\n",
              " (679, 'bore huh'),\n",
              " (680, 'turkey tday care appleemojissuck'),\n",
              " (681, 'new role require new hardware thankful'),\n",
              " (682, 'rich quick criminal capitalist steal client product apple technology'),\n",
              " (683, 'enjoy studio wireless beat'),\n",
              " (684, 'clear support rand paul 2016 case pigeonhole red blue like'),\n",
              " (685, 'haha switch'),\n",
              " (686, 'phone suck'),\n",
              " (687, 'final aapl putcallratio tuesday december 2014 hamzei'),\n",
              " (688, 'need ride drive mall today schedule appt mac daddy'),\n",
              " (689, 'studio 45,000 outlet computer need battery future'),\n",
              " (690, 'studio 45,000 outlet computer need battery future'),\n",
              " (691, '.@apple want stop take vertical photo'),\n",
              " (692, 'honest great fanaticism turn equally great dislike'),\n",
              " (693, 'figure iphone randomly lose contact hour reason wth'),\n",
              " (694, 'wait ipod bubblew apple'),\n",
              " (695, 'phone suck'),\n",
              " (696, 'agree robust chocolate fire guard'),\n",
              " (697, 'computer slow'),\n",
              " (698, 'apple important stock earth aapl'),\n",
              " (699,\n",
              "  'need product like .@aviate company like .@blackberry amp .@apple need embrace customization quality theme'),\n",
              " (700, 'cash aapl cfd 110 113 inside hour brave'),\n",
              " (701, '128 version'),\n",
              " (702, 'good iphone app 2014'),\n",
              " (703, 'studio 45,000 outlet computer need battery future'),\n",
              " (704, 'oops sorry applebees mean'),\n",
              " (705, 'buy phone use'),\n",
              " (706, 'got kid'),\n",
              " (707, 'thank amp postman work overtime'),\n",
              " (708,\n",
              "  'thx .@apple 2600 digital language new internet leader,10 cost diy .@googlenexus'),\n",
              " (709, 'ipad change way child learn classroom education tech'),\n",
              " (710, 'iphone6plus vs. galaxy note apple snatch away phablet thursday decem'),\n",
              " (711, 'studio 45,000 outlet computer need battery future'),\n",
              " (712,\n",
              "  'surprised talk look like flash crash aapl yesterday big range year largely ignore'),\n",
              " (713, 'homekit soon control home iphone aapl aapl'),\n",
              " (714,\n",
              "  'apple price target raise bmo capital see unfulfilled iphone demand push march quarter aapl aapl'),\n",
              " (715, 'protester stage diein protest store nyc anger misplace retweet agree'),\n",
              " (716, 'patent iphone drop protection mechanism end crackedscreen'),\n",
              " (717, 'fucking phone screen break want phone naked free'),\n",
              " (718, 'block trade detect aapl'),\n",
              " (719, 'charge ringtone let use thanksobama'),\n",
              " (720, 'forget apple iphone samsung galaxy humble flip phone frid'),\n",
              " (721,\n",
              "  'hope store arndale pass staff member staff visually impair inspiration great work inawe welldone'),\n",
              " (722, 'steve wozniak call legendary garage bit myth'),\n",
              " (723,\n",
              "  'encourage marxist isis give order arrest marxist dupe trespass pantsupdontloot'),\n",
              " (724, 'protester stage diein protest store nyc anger misplace retweet agree'),\n",
              " (725, 'tell tester gmail ios app work tell tester'),\n",
              " (726, 'figure memory issue ipad bug new hidden folder store image'),\n",
              " (727, 'battery die'),\n",
              " (728, 'hell'),\n",
              " (729, 'studio 45,000 outlet computer need battery future'),\n",
              " (730, 'dear create middle finger emoji asap sincerely iphone user'),\n",
              " (731,\n",
              "  'dawned probably spend replace frayed non function iphone cable spend iphone'),\n",
              " (732, 'apple raise jmp security 150.00 outperform rating aapl aapl'),\n",
              " (733, 'try thousand foot fly'),\n",
              " (734, 'way'),\n",
              " (735, 'like emojis look like'),\n",
              " (736, 'hey let facetime claire stop rude'),\n",
              " (737, 'prove'),\n",
              " (738,\n",
              "  'hey come saturday movie night fail appletv chuck guy wifegoingtosleep'),\n",
              " (739, 'apple patent idea stevejobs hate aapl'),\n",
              " (740, 'apple aapl plan launch iphone6 mini version 2015 monday december'),\n",
              " (741,\n",
              "  'ayo think create video message option answer facetime leave video mail'),\n",
              " (742, 'fda clear smartphone connect thermometer store holiday'),\n",
              " (743, 'protester stage diein protest store nyc anger misplace retweet agree'),\n",
              " (744,\n",
              "  'unfollow unlike tuesday unlike unfollow socialcleanuptuesday maybe antidrama'),\n",
              " (745, 'studio 45,000 outlet computer need battery future'),\n",
              " (746, 'need new emojis preferably brown people shxt like'),\n",
              " (747, 'ubs increase apple iphone6 sale revenue eps friday december'),\n",
              " (748, 'iphone5s good mobile easy work wonderfull thank'),\n",
              " (749, 'apple inc profit margin continue upward aapl aapl'),\n",
              " (750, 'photo café mac check shady groove check techie frequent'),\n",
              " (751, 'walk work see trade bent ass iphone needa fix shit'),\n",
              " (752, 'big storage'),\n",
              " (753, 'playlist ipod add auto download album playlist shuffle hear'),\n",
              " (754, 'protester stage diein protest store nyc anger misplace retweet agree'),\n",
              " (755, 'fan scramble ipod classic music player apple kill aapl '),\n",
              " (756,\n",
              "  'apple patent iphone drop protection mechanism change device tuesday december'),\n",
              " (757, 'ipod photo possible come end 10yrs battery charge'),\n",
              " (758,\n",
              "  'aapl:5 rocket stock buy december gain apple more...http://t.co/eg5xhxdlls'),\n",
              " (759,\n",
              "  'hey battery iphone drop like cock gay porn xvideos main page fix shit'),\n",
              " (760,\n",
              "  'principled truth eddy cue talk fortune apple appeal book price fix judgment aapl'),\n",
              " (761, 'read apple iphone china unicom lead time aapl aapl'),\n",
              " (762, 'u.s government accept donation reduce national debt fact'),\n",
              " (763, 'store host free code workshop hourofcode 12/11/14 computerscience'),\n",
              " (764,\n",
              "  'hope amp ios allow compact view 3rd party keyboard like swiftkey swype android'),\n",
              " (765, 'dream night downgrade iphone spend rest dream try figure shame'),\n",
              " (766, 'protester stage diein protest store nyc anger misplace retweet agree'),\n",
              " (767, 'apple fibonacci technical level intraday update aapl aapl'),\n",
              " (768, 'make smart elevate app year congratulation team'),\n",
              " (769,\n",
              "  'look especially decline sale look like aapl decide want samsung piece pie'),\n",
              " (770, 'fail poli sci fucking laptop sue'),\n",
              " (771,\n",
              "  'apple warm social medium apple hire social medium guru l.a finally tweet?her'),\n",
              " (772, 'real cute sync music phone'),\n",
              " (773, 'protester stage diein protest store nyc anger misplace retweet agree'),\n",
              " (774, 'wwa movie itune'),\n",
              " (775, 'studio 45,000 outlet computer need battery future'),\n",
              " (776, 'apple fibonacci technical level intraday update aapl aapl'),\n",
              " (777, 'surprise explanation bend iphone'),\n",
              " (778,\n",
              "  'aapl abe say apple build technical center japan...http://t.co/deavv9aymk'),\n",
              " (779, 'host free code workshop store'),\n",
              " (780, 'studio 45,000 outlet computer need battery future'),\n",
              " (781, '19-year old wizkid turn nab back hollywood star'),\n",
              " (782, 'apple inc price close december 2014 115.95 apple aapl'),\n",
              " (783, 'harry potter emojis work'),\n",
              " (784, 'studio 45,000 outlet computer need battery future'),\n",
              " (785,\n",
              "  'iphone6 fall screen shatter like blow want additional 109 fix maybe product last'),\n",
              " (786, 'mark zuckerberg slam tim cook care customer aapl'),\n",
              " (787, 'sale iphone plus settle long run argument apple smartphone aapl aapl'),\n",
              " (788, 'apple inc iphone infringe chinese company patent aapl'),\n",
              " (789, 'cnbc fat finger aapl look day later'),\n",
              " (790, 'happen music delete music customer ipod'),\n",
              " (791, 'touch screen macbook'),\n",
              " (792, 'aapl apple delete music customer ipods...http://t.co/ieyvcmygav'),\n",
              " (793, 'company admire rock work mainly boss culture'),\n",
              " (794,\n",
              "  'iphone plus make large phone sale iphone lead ios device ios blog aapl'),\n",
              " (795, 'patent system change position iphone mid air yay'),\n",
              " (796, 'cite constitution judge pass law violation separation power'),\n",
              " (797,\n",
              "  'get new iphone6 grow love bit bulky come iphone5 nice feel thank wait applewatch'),\n",
              " (798, 'award patent augment reality device transparent display'),\n",
              " (799, 'movie itunes match icloud remove actually trailer annoying'),\n",
              " (800, 'train employee deal issue hang customer fuck minute wait hold'),\n",
              " (801, 'protester stage diein protest store nyc anger misplace retweet agree'),\n",
              " (802, 'apple lose ground google education tablet sale aapl aapl'),\n",
              " (803, 'need portfolio defend big company look court battle'),\n",
              " (804, 'try turn problem'),\n",
              " (805, 'phone charge hour keep lose percentage shit'),\n",
              " (806, 'jdelaneyxo beta test new product isee'),\n",
              " (807, 'think 100 reason fuck'),\n",
              " (808, 'protester stage diein protest store nyc anger misplace retweet agree'),\n",
              " (809, 'studio 45,000 outlet computer need battery future'),\n",
              " (810, '19-year old wizkid turn nab back hollywood star'),\n",
              " (811, 'twitter'),\n",
              " (812, 'previously deal issue annoying try reset nvram'),\n",
              " (813, 'apple dilemma apple aapl aapl'),\n",
              " (814,\n",
              "  'aapl new 4-inch iphone report reason apple it...http://t.co/qntqdiytxk'),\n",
              " (815, 'aapl:6 reason apple fall yesterday...http://t.co/rvjreh9ijf'),\n",
              " (816, 'photo amazing customer service today utc store work form store hour'),\n",
              " (817, 'wish prosecute admin violation privacy criminal search seizure'),\n",
              " (818, 'aapl bidu nte stock buy list aapl bidu nte'),\n",
              " (819, 'apple iphone international price high aapl aapl'),\n",
              " (820, '2nd day new iphone wtf switch'),\n",
              " (821, 'apple seed second 10.10.2 yosemite beta developer mac blog aapl'),\n",
              " (822,\n",
              "  'trade aapl free nightly update post twitter visit trade aapl free website'),\n",
              " (823, 'restart phone siri speak selection annoying fixit'),\n",
              " (824, 'studio 45,000 outlet computer need battery future'),\n",
              " (825, 'studio 45,000 outlet computer need battery future'),\n",
              " (826, 'let forget press effect stock defend ipod antitrust suit'),\n",
              " (827, 'aapl exchange iphone passport receive 550...http://t.co/diskjki4ch'),\n",
              " (828, 'iphone day break shout'),\n",
              " (829, 'studio 45,000 outlet computer need battery future'),\n",
              " (830, 'apple inc flash crash need know aapl'),\n",
              " (831, 'aapl aapl green right hope stay'),\n",
              " (832,\n",
              "  'video show size 12.2-inch ipad air plus mockup iphone ipad macbook aapl'),\n",
              " (833, 'debunk apple big myth '),\n",
              " (834, ' '),\n",
              " (835, ' aapl'),\n",
              " (836, 'yea let pay 600 dollar phone die fix shit'),\n",
              " (837, 'hey reading list safari device rock let list item delete iphone'),\n",
              " (838,\n",
              "  'aapl:10 best cool tech gadget 2014 holiday season...http://t.co/teeyocbb4l'),\n",
              " (839, 'hate phone use go completely silent help'),\n",
              " (840, 'protester stage diein protest store nyc anger misplace retweet agree'),\n",
              " (841,\n",
              "  'happy monday camera fancy iphone6plus suddenly stop work weekend instead meme'),\n",
              " (842, 'explain'),\n",
              " (843, 'studio 45,000 outlet computer need battery future'),\n",
              " (844,\n",
              "  'love applepay security feature pls work itune eliminate need info pay ahead payitsafe'),\n",
              " (845,\n",
              "  'onthisdayindigital sign deal china today 2013 finally sell iphone country'),\n",
              " (846, 'silver merchant prefer bitcoin applepay payment retail banking'),\n",
              " (847, 'give huge middle finger face'),\n",
              " (848, 'make smart elevate app year congratulation team'),\n",
              " (849, 'apple inc catch iphone6 supply lag demand motley fool aapl'),\n",
              " (850, 'protester stage diein protest store nyc anger misplace retweet agree'),\n",
              " (851, 'bruh real niggas need 128 ipod touch'),\n",
              " (852, 'apple force think ipod touch demand surge aapl aapl'),\n",
              " (853,\n",
              "  'promoproduct supplier carry brandable compliant adapter headsaregoingtoroll mfi'),\n",
              " (854,\n",
              "  'apple warm social medium apple hire social medium guru l.a finally twe'),\n",
              " (855, 'apple inc aapl iphone sale dent android market share aapl'),\n",
              " (856, 'find store'),\n",
              " (857, 'world murder facetime thank innovation'),\n",
              " (858, 'begin think product crap'),\n",
              " (859, 'nice1 say good app 2014'),\n",
              " (860, 'way well'),\n",
              " (861, 'hell 5gbs datum phone'),\n",
              " (862, 'macbook pro unboxing macbook macbookpro startup hipster unboxing'),\n",
              " (863, 'cnbctv apple take stand aapl'),\n",
              " (864, 'studio 45,000 outlet computer need battery future'),\n",
              " (865,\n",
              "  'apple act unfairly suppress digital music competition paul kedrosky aapl aapl'),\n",
              " (866, 'itunes piss'),\n",
              " (867, 'maketh thee pesky appear end people text message'),\n",
              " (868, 'minute minute'),\n",
              " (869, 'kashka clave mind'),\n",
              " (870, 'apple drop aapl aapl'),\n",
              " (871, 'applewatch detail expose aapl'),\n",
              " (872,\n",
              "  'apple lower analyst see risk sharp production cut iphone plus aapl aapl'),\n",
              " (873, 'hopefully endanger life'),\n",
              " (874, 'yea let pay 600 dollar phone die fix shit'),\n",
              " (875, 'bet radioshack lol'),\n",
              " (876, 'go buy iphone6 tell stock reserve return tomorrow buy goodbye'),\n",
              " (877, 'sit wait half hour appt watch genius talk crap customer open nice'),\n",
              " (878,\n",
              "  'stop make installation damn bloody difficult stop ask clear space hard disk'),\n",
              " (879, 'rumoured r8207 look similar certain iphone6'),\n",
              " (880, 'macbook pro non retina startup macbook macbookpro startup hipster'),\n",
              " (881, 'bad addition improve non existent customer service fail'),\n",
              " (882, 'nyc flagship store spare visit ericgarner protest'),\n",
              " (883, 'use congrat give government permission spy apple'),\n",
              " (884, 'nail build success amp brand appleid nomorepayword'),\n",
              " (885, 'apple release 4-inch iphone mini year aapl aapl'),\n",
              " (886, 'mobile iphone nightmare iphone6'),\n",
              " (887, 'autocorrect change muslim awesome okay'),\n",
              " (888, 'short menu 3.1 live appstore'),\n",
              " (889, 'watch weekend new ad'),\n",
              " (890, 'imac catch fire use sit desk luckily nearby able sort'),\n",
              " (891, 'mark zuckerberg jabs apple pricey product aapl aapl'),\n",
              " (892, 'apple fibonacci technical level intraday update aapl aapl'),\n",
              " (893, 'fucking software update'),\n",
              " (894, 'go iphone charger past montht hank'),\n",
              " (895, 'haha tech see condosenior cookery jump opportunity'),\n",
              " (896, 'hour buzz aapl bobe amp check company make headline bell tuesday'),\n",
              " (897, 'studio 45,000 outlet computer need battery future'),\n",
              " (898, 'emanon record apple premium product average product premium price'),\n",
              " (899, 'happening itune account secretly delete non itunes music'),\n",
              " (900, 'studio 45,000 outlet computer need battery future'),\n",
              " (901, 'gay stuff fucking iphone'),\n",
              " (902,\n",
              "  'pop bostonholiday urbannutcracker amp krumper store boylston today dancing amp chat'),\n",
              " (903,\n",
              "  'aapl update 1-alabama anti discrimination bill name apple ti...http://t.co/8rearteomu'),\n",
              " (904,\n",
              "  'iphone6 sale success give apple good market position thursday december'),\n",
              " (905, 'apple mean healthy'),\n",
              " (906, 'iphone long upgrade cycle expect unit sale fall aapl aapl'),\n",
              " (907, 'book grow global brand book grow stickybrand'),\n",
              " (908, 'try turn problem'),\n",
              " (909, 'probably thank ship carrier'),\n",
              " (910, 'apple aapl plan launch iphone6mini version 2015 dec 2014'),\n",
              " (911, 'world demand employer'),\n",
              " (912, 'watch dad struggle answer iphone let answer great job ios'),\n",
              " (913, 'terrify suck ass'),\n",
              " (914,\n",
              "  'utterly rediculous take hrs simple thing like sync ringtone itunes accessability horific rediculous'),\n",
              " (915, 'apple drop google map good apple map roll aapl'),\n",
              " (916, 'like new product apple'),\n",
              " (917,\n",
              "  'judge rule bank sue credit card breach pay value proposition intensifie'),\n",
              " (918, 'want delete email turn'),\n",
              " (919, 'protester stage diein protest store nyc anger misplace retweet agree'),\n",
              " (920, 'studio 45,000 outlet computer need battery future'),\n",
              " (921, 'protester stage diein protest store nyc anger misplace retweet agree'),\n",
              " (922, 'rumor roundup tale rumor blog aapl aapl'),\n",
              " (923, 'stop try like samsung choose samsung reason'),\n",
              " (924, 'happy mac yosemite file vault boot camp right thankful'),\n",
              " (925, 'apple inc sell million apple watch 2015 aapl aapl'),\n",
              " (926, 'bad day life'),\n",
              " (927, 'ipod replace set foot store world well place'),\n",
              " (928, 'love new spot'),\n",
              " (929,\n",
              "  'steve hayman national consulting engineer present app development umich'),\n",
              " (930, 'certify partner business collaborate'),\n",
              " (931,\n",
              "  'apple intraday comment update range premium user aapl stockaction trading stock mkt'),\n",
              " (932,\n",
              "  'happy monday camera fancy iphone6plus suddenly stop work weekend instead meme'),\n",
              " (933, 'send computer twice repair month time come new problem right'),\n",
              " (934, 'aapl think value 140 145s year.death steve jobs damage samsung apple'),\n",
              " (935, 'apple head trial itunes update aapl'),\n",
              " (936, 'block trade detect aapl'),\n",
              " (937, 'happy backwards compatibility give app aperture money grab'),\n",
              " (938, 'protester stage diein protest store nyc anger misplace retweet agree'),\n",
              " (939, 'excellent news houseofcard 27/2 wonder yosemite amp wifi talk wks'),\n",
              " (940, 'iphone plus huge china spring aapl aapl'),\n",
              " (941,\n",
              "  'cool minute later yosemite macbook bad year old computer run strong win'),\n",
              " (942, 'definitely think carefully future buy support tell go wrong'),\n",
              " (943, 'evolution apple product'),\n",
              " (944, 'support say test nfc assume phone work say help'),\n",
              " (945, 'cnbctv iphone growth peak aapl'),\n",
              " (946, 'app store work'),\n",
              " (947, 'cunt printer work fuck yosemite update prick'),\n",
              " (948, 'deal take phone beat shit fuck damn twitter fuck'),\n",
              " (949, 'apple fibonacci technical level intraday update aapl aapl'),\n",
              " (950, 'apple fibonacci technical level intraday update aapl aapl'),\n",
              " (951, 'cocky ass apple talk bout fruit fuck'),\n",
              " (952, 'offensive thing lack trashcan emoji stop discrimination'),\n",
              " (953, '.@apple need consider emoji need life'),\n",
              " (954, '.@ikea channel hilarious new catalog bookbook time ikea'),\n",
              " (955, 'protester stage diein protest store nyc anger misplace retweet agree'),\n",
              " (956,\n",
              "  '.@apple patent new tech shift iphone center gravity falls land minimal damage'),\n",
              " (957, 'need send iphone cancel'),\n",
              " (958, 'link bring pre order thing'),\n",
              " (959,\n",
              "  'finally decide buy big ipad phone iphone6 grey normally excited smartphone'),\n",
              " (960, 'fix'),\n",
              " (961, 'studio 45,000 outlet computer need battery future'),\n",
              " (962,\n",
              "  'aside apple google alibaba enter connected car space forbe baba goog aapl'),\n",
              " (963,\n",
              "  'anti trust expert peter carstensen discuss antitrust case california federal court'),\n",
              " (964, 'yesterday tell issue .this add bad month customer service'),\n",
              " (965,\n",
              "  'aapl watch list at&amp;t nyse apple nasdaq aapl pandora media inc nys...http://t.co/dg5bxrxgda'),\n",
              " (966, 'good stakeholderengagement'),\n",
              " (967, 'apple tech support nice free stuff suck ringtone issue'),\n",
              " (968, 'studio 45,000 outlet computer need battery future'),\n",
              " (969,\n",
              "  'tim cook show apple watch chinese internet official discuss security issue aapl aapl'),\n",
              " (970, 'studio 45,000 outlet computer need battery future'),\n",
              " (971, 'dear '),\n",
              " (972, ' kindly fuck .m4a format '),\n",
              " (973, ' regard music listener'),\n",
              " (974, 'paper fes watch cool piece wearable tech sorry'),\n",
              " (975, 'aapl '),\n",
              " (976,\n",
              "  '     audio auto sale apple lawsuit head court...http://t.co/kvb1l61oln'),\n",
              " (977, 'get kid'),\n",
              " (978, 'lol tryna figure file 1984'),\n",
              " (979, 'wtf live kirkby'),\n",
              " (980, 'aapl apple executive stand antitrust trial...http://t.co/mzzn6vffi4'),\n",
              " (981, 'apple fibonacci technical level intraday update aapl aapl'),\n",
              " (982, 'wait technology analysis firm public stock symbol rong'),\n",
              " (983, 'setting page horrific'),\n",
              " (984, 'mustbuy outfit ipodnano'),\n",
              " (985,\n",
              "  'apple 115 fit 8.4 increase earning use 2014q3 eps=$1.42 free ios app donkey stock aapl'),\n",
              " (986, 'favorite tweet'),\n",
              " (987, 'good stakeholderengagement'),\n",
              " (988, 'tear note iphone '),\n",
              " (989, ' lol apple soul need save money android'),\n",
              " (990, 'justice department cite 18th century federal law unlock iphone'),\n",
              " (991, 'month cable month earpiece break'),\n",
              " (992,\n",
              "  'customer service good year have enjoy product zero complain thank apple'),\n",
              " (993, 'rumor surface apple iphone6s iphone7 2015 aapl'),\n",
              " (994, 'tell santa claus emoji'),\n",
              " (995, 'ipad glitche bad charge wtf'),\n",
              " (996, 'make fun french people rude new iphone'),\n",
              " (997, 'realistic song length drum track logic pro drummer proaudio'),\n",
              " (998, 'love support hourofcode workshop'),\n",
              " (999, 'studio 45,000 outlet computer need battery future'),\n",
              " (1000, 'trash'),\n",
              " ...]"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Mapeamos y mostramos sus TFs"
      ],
      "metadata": {
        "id": "oP3Qrm889jw7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "map1 = rows.flatMap(lambda x: [((x[0],i),1) for i in x[1].split()])\n",
        "reduce = map1.reduceByKey(lambda x,y:x+y)\n",
        "tf = reduce.map(lambda x: (x[0][1],(x[0][0],x[1])))\n",
        "tf.collect()"
      ],
      "metadata": {
        "id": "wmTyTzuwlpBf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "db557869-b160-4520-c029-27a1dbb39342"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('protester', (1, 1)),\n",
              " ('stage', (1, 1)),\n",
              " ('diein', (1, 1)),\n",
              " ('protest', (1, 1)),\n",
              " ('store', (1, 1)),\n",
              " ('nyc', (1, 1)),\n",
              " ('anger', (1, 1)),\n",
              " ('misplace', (1, 1)),\n",
              " ('retweet', (1, 1)),\n",
              " ('agree', (1, 1)),\n",
              " ('apple', (2, 1)),\n",
              " ('intraday', (2, 1)),\n",
              " ('comment', (2, 1)),\n",
              " ('update', (2, 1)),\n",
              " ('range', (2, 1)),\n",
              " ('premium', (2, 1)),\n",
              " ('user', (2, 1)),\n",
              " ('aapl', (2, 1)),\n",
              " ('stockaction', (2, 1)),\n",
              " ('trading', (2, 1)),\n",
              " ('stock', (2, 1)),\n",
              " ('mkt', (2, 1)),\n",
              " ('ios', (3, 1)),\n",
              " ('app', (3, 2)),\n",
              " ('2014', (3, 1)),\n",
              " ('name', (3, 1)),\n",
              " ('elevate', (3, 1)),\n",
              " ('brain', (3, 1)),\n",
              " ('training', (3, 1)),\n",
              " ('iphone', (3, 1)),\n",
              " ('shit', (4, 1)),\n",
              " ('founder', (5, 1)),\n",
              " ('attack', (5, 1)),\n",
              " ('boss', (5, 1)),\n",
              " ('ridiculous', (5, 1)),\n",
              " ('comment', (5, 1)),\n",
              " ('ad', (5, 1)),\n",
              " ('evidence', (6, 1)),\n",
              " ('factcheckthis', (6, 1)),\n",
              " ('educate', (7, 1)),\n",
              " ('hard', (8, 1)),\n",
              " ('reach', (8, 1)),\n",
              " ('buy', (8, 1)),\n",
              " ('suicide', (8, 1)),\n",
              " ('squad', (8, 1)),\n",
              " ('comic_strip', (8, 1)),\n",
              " ('apple', (8, 1)),\n",
              " ('store', (8, 1)),\n",
              " ('turkey', (8, 1)),\n",
              " ('delete', (9, 1)),\n",
              " ('music', (9, 1)),\n",
              " ('customer', (9, 1)),\n",
              " ('ipod', (9, 1)),\n",
              " ('apple', (10, 1)),\n",
              " ('intraday', (10, 1)),\n",
              " ('comment', (10, 1)),\n",
              " ('update', (10, 1)),\n",
              " ('range', (10, 1)),\n",
              " ('premium', (10, 1)),\n",
              " ('user', (10, 1)),\n",
              " ('aapl', (10, 1)),\n",
              " ('stockaction', (10, 1)),\n",
              " ('trading', (10, 1)),\n",
              " ('stock', (10, 1)),\n",
              " ('mkt', (10, 1)),\n",
              " ('studio', (11, 1)),\n",
              " ('45,000', (11, 1)),\n",
              " ('outlet', (11, 1)),\n",
              " ('computer', (11, 1)),\n",
              " ('need', (11, 1)),\n",
              " ('battery', (11, 1)),\n",
              " ('future', (11, 1)),\n",
              " ('apple', (12, 1)),\n",
              " ('great', (12, 1)),\n",
              " ('business', (12, 1)),\n",
              " ('aapl', (12, 2)),\n",
              " ('investwall', (12, 1)),\n",
              " ('dear', (13, 1)),\n",
              " ('love', (13, 1)),\n",
              " ('iphone', (13, 2)),\n",
              " ('plus', (13, 1)),\n",
              " ('lot', (13, 1)),\n",
              " ('great', (13, 1)),\n",
              " ('achievement', (13, 1)),\n",
              " ('reboot', (13, 1)),\n",
              " ('day', (13, 1)),\n",
              " ('fail', (13, 1)),\n",
              " ('survey', (14, 1)),\n",
              " ('feedback', (14, 1)),\n",
              " ('iwatch', (14, 1)),\n",
              " ('positioning', (14, 1)),\n",
              " ('fashion', (14, 1)),\n",
              " ('accessory', (14, 1)),\n",
              " ('geek', (14, 1)),\n",
              " ('centric', (14, 1)),\n",
              " ('gadget', (14, 1)),\n",
              " ('similar', (15, 1)),\n",
              " ('cloud', (15, 1)),\n",
              " ('backup', (15, 1)),\n",
              " ('picture', (15, 1)),\n",
              " ('onlinefootprint', (15, 1)),\n",
              " ('modicumofprudence', (15, 1)),\n",
              " ('protester', (16, 1)),\n",
              " ('stage', (16, 1)),\n",
              " ('diein', (16, 1)),\n",
              " ('protest', (16, 1)),\n",
              " ('store', (16, 1)),\n",
              " ('nyc', (16, 1)),\n",
              " ('anger', (16, 1)),\n",
              " ('misplace', (16, 1)),\n",
              " ('retweet', (16, 1)),\n",
              " ('agree', (16, 1)),\n",
              " ('fuck', (17, 1)),\n",
              " ('make', (17, 1)),\n",
              " ('shit', (17, 1)),\n",
              " ('product', (17, 1)),\n",
              " ('try', (18, 1)),\n",
              " ('turn', (18, 1)),\n",
              " ('problem', (18, 1)),\n",
              " ('macbook', (19, 1)),\n",
              " ('pro', (19, 1)),\n",
              " ('annoying', (19, 1)),\n",
              " ('asus', (19, 1)),\n",
              " ('window', (19, 1)),\n",
              " ('computer', (19, 1)),\n",
              " ('freezing', (19, 1)),\n",
              " ('laggy', (19, 1)),\n",
              " ('etc', (19, 1)),\n",
              " ('excellence', (19, 1)),\n",
              " ('speak', (20, 1)),\n",
              " ('wearable', (20, 1)),\n",
              " ('new', (20, 1)),\n",
              " ('chargehr', (20, 1)),\n",
              " ('amp', (20, 1)),\n",
              " ('iphone', (20, 1)),\n",
              " ('want', (20, 1)),\n",
              " ('eat', (20, 1)),\n",
              " ('latke', (20, 1)),\n",
              " ('run', (20, 1)),\n",
              " ('place', (20, 1)),\n",
              " ('tl_chat', (20, 1)),\n",
              " ('forbe', (21, 1)),\n",
              " ('whoop', (21, 1)),\n",
              " ('plaintiff', (21, 1)),\n",
              " ('apple', (21, 1)),\n",
              " ('tell', (21, 1)),\n",
              " ('court', (21, 1)),\n",
              " ('ipod', (21, 1)),\n",
              " ('owner', (21, 1)),\n",
              " ('class', (21, 1)),\n",
              " ('represent', (21, 1)),\n",
              " ('aapl', (21, 1)),\n",
              " ('thanks', (22, 1)),\n",
              " ('3-way', (22, 1)),\n",
              " ('call', (22, 2)),\n",
              " ('facetime', (22, 1)),\n",
              " ('ability', (22, 1)),\n",
              " ('device', (22, 1)),\n",
              " ('seamlessly', (22, 1)),\n",
              " ('mkt', (23, 1)),\n",
              " ('final', (23, 1)),\n",
              " ('aapl', (23, 1)),\n",
              " ('putcallratio', (23, 1)),\n",
              " ('monday', (23, 1)),\n",
              " ('december', (23, 1)),\n",
              " ('2014', (23, 1)),\n",
              " ('julian', (24, 1)),\n",
              " ('robertson', (24, 1)),\n",
              " ('bullish', (24, 1)),\n",
              " ('apple', (24, 1)),\n",
              " ('inc', (24, 1)),\n",
              " ('aapl', (24, 1)),\n",
              " ('apple', (25, 1)),\n",
              " ('intraday', (25, 1)),\n",
              " ('comment', (25, 1)),\n",
              " ('update', (25, 1)),\n",
              " ('range', (25, 1)),\n",
              " ('premium', (25, 1)),\n",
              " ('user', (25, 1)),\n",
              " ('aapl', (25, 1)),\n",
              " ('stockaction', (25, 1)),\n",
              " ('trading', (25, 1)),\n",
              " ('stock', (25, 1)),\n",
              " ('mkt', (25, 1)),\n",
              " ('new', (26, 1)),\n",
              " ('problem', (26, 1)),\n",
              " ('airport', (26, 1)),\n",
              " ('board', (26, 1)),\n",
              " ('pass', (26, 1)),\n",
              " ('phone', (26, 1)),\n",
              " ('hold', (26, 1)),\n",
              " ('scanner', (26, 1)),\n",
              " ('security', (26, 1)),\n",
              " ('applepay', (26, 1)),\n",
              " ('credit', (26, 1)),\n",
              " ('card', (26, 1)),\n",
              " ('take', (26, 1)),\n",
              " ('screen', (26, 1)),\n",
              " ('help', (27, 1)),\n",
              " ('mac', (27, 1)),\n",
              " ('memory', (27, 1)),\n",
              " ('clear', (27, 1)),\n",
              " ('ask', (27, 1)),\n",
              " ('password', (27, 1)),\n",
              " ('old', (27, 1)),\n",
              " ('ask', (28, 1)),\n",
              " ('use', (28, 1)),\n",
              " ('voice', (28, 1)),\n",
              " ('attribute', (28, 1)),\n",
              " ('dude', (28, 1)),\n",
              " ('ace', (28, 1)),\n",
              " ('vocal', (28, 1)),\n",
              " ('clone', (28, 1)),\n",
              " ('fuck', (29, 2)),\n",
              " ('hate', (29, 1)),\n",
              " ('apple', (30, 1)),\n",
              " ('want', (30, 1)),\n",
              " ('commute', (30, 1)),\n",
              " ('easy', (30, 1)),\n",
              " ('accord', (30, 1)),\n",
              " ('new', (30, 1)),\n",
              " ('patent', (30, 1)),\n",
              " ('aapl', (30, 1)),\n",
              " ('studio', (31, 1)),\n",
              " ('45,000', (31, 1)),\n",
              " ('outlet', (31, 1)),\n",
              " ('computer', (31, 1)),\n",
              " ('need', (31, 1)),\n",
              " ('battery', (31, 1)),\n",
              " ('future', (31, 1)),\n",
              " ('need', (32, 1)),\n",
              " ('help', (32, 1)),\n",
              " ('apple', (32, 1)),\n",
              " ('iphone6', (32, 1)),\n",
              " ('amp', (32, 1)),\n",
              " ('iphone6plus', (32, 1)),\n",
              " ('checkitout', (32, 1)),\n",
              " ('invest', (33, 1)),\n",
              " ('terabyte', (33, 1)),\n",
              " ('storage', (33, 1)),\n",
              " ('ceo', (34, 1)),\n",
              " ('warn', (34, 1)),\n",
              " ('wearable', (34, 1)),\n",
              " ('maker', (34, 1)),\n",
              " ('tech', (34, 1)),\n",
              " ('need', (34, 1)),\n",
              " ('productivity', (34, 1)),\n",
              " ('novelty', (34, 1)),\n",
              " ('like', (34, 1)),\n",
              " ('siri', (34, 1)),\n",
              " ('gva', (35, 1)),\n",
              " ('lounge', (35, 1)),\n",
              " ('sight', (35, 1)),\n",
              " ('mac', (35, 1)),\n",
              " ('pc', (35, 1)),\n",
              " ('undetermined', (35, 1)),\n",
              " ('number', (35, 1)),\n",
              " ('ipxs', (35, 1)),\n",
              " ('aapl', (35, 1)),\n",
              " ('afp', (36, 1)),\n",
              " ('request', (36, 1)),\n",
              " ('apple', (36, 1)),\n",
              " ('reveal', (36, 1)),\n",
              " ('warrant', (36, 1)),\n",
              " ('pushback', (36, 1)),\n",
              " ('tax', (36, 1)),\n",
              " ('evader', (36, 1)),\n",
              " ('rip', (36, 1)),\n",
              " ('aussie', (36, 1)),\n",
              " ('protester', (37, 1)),\n",
              " ('stage', (37, 1)),\n",
              " ('diein', (37, 1)),\n",
              " ('protest', (37, 1)),\n",
              " ('store', (37, 1)),\n",
              " ('nyc', (37, 1)),\n",
              " ('anger', (37, 1)),\n",
              " ('misplace', (37, 1)),\n",
              " ('retweet', (37, 1)),\n",
              " ('agree', (37, 1)),\n",
              " ('yeah', (38, 1)),\n",
              " ('monarchywpb', (38, 1)),\n",
              " ('sticker', (38, 1)),\n",
              " ('ride', (38, 1)),\n",
              " ('boommovement', (38, 1)),\n",
              " ('afternoon', (39, 1)),\n",
              " ('tea', (39, 1)),\n",
              " ('ipadair2', (39, 1)),\n",
              " ('touchpoint', (39, 1)),\n",
              " ('reward', (39, 1)),\n",
              " ('visit', (39, 1)),\n",
              " ('info', (39, 1)),\n",
              " ('drain', (40, 1)),\n",
              " ('battery', (40, 1)),\n",
              " ('fix', (40, 1)),\n",
              " ('.@apple', (41, 1)),\n",
              " ('ceo', (41, 1)),\n",
              " ('visit', (41, 1)),\n",
              " ('promoproduct', (42, 1)),\n",
              " ('supplier', (42, 1)),\n",
              " ('carry', (42, 1)),\n",
              " ('brandable', (42, 1)),\n",
              " ('compliant', (42, 1)),\n",
              " ('adapter', (42, 1)),\n",
              " ('headsaregoingtoroll', (42, 1)),\n",
              " ('new', (43, 1)),\n",
              " ('sony', (43, 1)),\n",
              " ('apple', (44, 2)),\n",
              " ('pay', (44, 1)),\n",
              " ('service', (44, 1)),\n",
              " ('lead', (44, 1)),\n",
              " ('price', (44, 1)),\n",
              " ('target', (44, 1)),\n",
              " ('upgrade', (44, 1)),\n",
              " ('inc', (44, 1)),\n",
              " ('aapl', (44, 2)),\n",
              " ('studio', (45, 1)),\n",
              " ('45,000', (45, 1)),\n",
              " ('outlet', (45, 1)),\n",
              " ('computer', (45, 1)),\n",
              " ('need', (45, 1)),\n",
              " ('battery', (45, 1)),\n",
              " ('future', (45, 1)),\n",
              " ('go', (46, 1)),\n",
              " ('canal', (46, 1)),\n",
              " ('street', (46, 1)),\n",
              " ('knockoff', (46, 1)),\n",
              " ('cmonman', (46, 1)),\n",
              " ('pay', (46, 1)),\n",
              " ('lightning', (46, 1)),\n",
              " ('cord', (46, 1)),\n",
              " ('excited', (47, 1)),\n",
              " ('name', (47, 1)),\n",
              " ('app', (47, 1)),\n",
              " ('store', (47, 1)),\n",
              " ('best', (47, 1)),\n",
              " ('2014', (47, 1)),\n",
              " ('list', (47, 1)),\n",
              " ('year', (47, 1)),\n",
              " ('apple', (47, 1)),\n",
              " ('gold', (48, 1)),\n",
              " ('macbook', (48, 1)),\n",
              " ('studio', (49, 1)),\n",
              " ('45,000', (49, 1)),\n",
              " ('outlet', (49, 1)),\n",
              " ('computer', (49, 1)),\n",
              " ('need', (49, 1)),\n",
              " ('battery', (49, 1)),\n",
              " ('future', (49, 1)),\n",
              " ('hey', (50, 1)),\n",
              " ('teach', (50, 1)),\n",
              " ('people', (50, 1)),\n",
              " ('use', (50, 1)),\n",
              " ('pay', (50, 1)),\n",
              " ('protester', (51, 1)),\n",
              " ('stage', (51, 1)),\n",
              " ('diein', (51, 1)),\n",
              " ('protest', (51, 1)),\n",
              " ('store', (51, 1)),\n",
              " ('nyc', (51, 1)),\n",
              " ('anger', (51, 1)),\n",
              " ('misplace', (51, 1)),\n",
              " ('retweet', (51, 1)),\n",
              " ('agree', (51, 1)),\n",
              " ('well', (52, 1)),\n",
              " ('iphone', (52, 1)),\n",
              " ('app', (52, 1)),\n",
              " ('year', (52, 1)),\n",
              " ('accord', (52, 1)),\n",
              " ('apple', (52, 1)),\n",
              " ('monday', (52, 1)),\n",
              " ('december', (52, 1)),\n",
              " ('protester', (53, 1)),\n",
              " ('stage', (53, 1)),\n",
              " ('diein', (53, 1)),\n",
              " ('protest', (53, 1)),\n",
              " ('store', (53, 1)),\n",
              " ('nyc', (53, 1)),\n",
              " ('anger', (53, 1)),\n",
              " ('misplace', (53, 1)),\n",
              " ('retweet', (53, 1)),\n",
              " ('agree', (53, 1)),\n",
              " ('make', (54, 1)),\n",
              " ('smart', (54, 1)),\n",
              " ('elevate', (54, 1)),\n",
              " ('app', (54, 1)),\n",
              " ('year', (54, 1)),\n",
              " ('congratulation', (54, 1)),\n",
              " ('team', (54, 1)),\n",
              " ('final', (55, 1)),\n",
              " ('aapl', (55, 1)),\n",
              " ('putcallratio', (55, 1)),\n",
              " ('monday', (55, 1)),\n",
              " ('december', (55, 1)),\n",
              " ('2014', (55, 1)),\n",
              " ('hamzei', (55, 1)),\n",
              " ('game', (56, 1)),\n",
              " ('trader', (56, 1)),\n",
              " ('play', (56, 1)),\n",
              " ('market', (56, 1)),\n",
              " ('liquidity', (56, 1)),\n",
              " ('hft', (56, 1)),\n",
              " ('darkpool', (56, 1)),\n",
              " ('stock', (56, 1)),\n",
              " ('trading', (56, 1)),\n",
              " ('algorithm', (56, 1)),\n",
              " ('aapl', (56, 1)),\n",
              " ('studio', (57, 1)),\n",
              " ('45,000', (57, 1)),\n",
              " ('outlet', (57, 1)),\n",
              " ('computer', (57, 1)),\n",
              " ('need', (57, 1)),\n",
              " ('battery', (57, 1)),\n",
              " ('future', (57, 1)),\n",
              " ('cool', (58, 2)),\n",
              " ('bait', (58, 1)),\n",
              " ('switch', (58, 1)),\n",
              " ('pay', (58, 1)),\n",
              " ('upgrade', (58, 1)),\n",
              " ('server', (58, 1)),\n",
              " ('free', (58, 1)),\n",
              " ('upgd', (58, 1)),\n",
              " ('10.10.1', (58, 1)),\n",
              " ('.@apple', (59, 1)),\n",
              " ('macmail', (59, 1)),\n",
              " ('yosemite', (59, 1)),\n",
              " ('give', (59, 1)),\n",
              " ('hard', (59, 1)),\n",
              " ('time', (59, 1)),\n",
              " ('alternative', (59, 1)),\n",
              " ('email', (59, 1)),\n",
              " ('program', (59, 1)),\n",
              " ('yosemiteproblem', (59, 1)),\n",
              " ('.@apple', (60, 1)),\n",
              " ('make', (60, 1)),\n",
              " ('hard', (60, 1)),\n",
              " ('spend', (60, 1)),\n",
              " ('money', (60, 1)),\n",
              " ('app', (60, 1)),\n",
              " ('functionality', (60, 1)),\n",
              " ('soon', (60, 1)),\n",
              " ('disappear', (60, 1)),\n",
              " ('today', (60, 1)),\n",
              " ('menu', (60, 1)),\n",
              " ('stop', (60, 1)),\n",
              " ('congrat', (61, 1)),\n",
              " ('mary', (61, 1)),\n",
              " ('sotos', (61, 1)),\n",
              " ('green', (61, 1)),\n",
              " ('power', (61, 1)),\n",
              " ('leadership', (61, 1)),\n",
              " ('award', (61, 1)),\n",
              " ('need', (62, 1)),\n",
              " ('battery', (62, 1)),\n",
              " ('game', (62, 1)),\n",
              " ('get', (62, 1)),\n",
              " ('time', (62, 1)),\n",
              " ('charge', (62, 2)),\n",
              " ('phone', (62, 1)),\n",
              " ('furstrate', (62, 1)),\n",
              " ('annoy', (62, 1)),\n",
              " ('hoe', (63, 1)),\n",
              " ('music', (64, 2)),\n",
              " ('library', (64, 1)),\n",
              " ('sync', (64, 2)),\n",
              " ('new', (64, 2)),\n",
              " ('etc', (64, 1)),\n",
              " ('itunes', (64, 1)),\n",
              " ('tell', (64, 1)),\n",
              " ('complete', (64, 1)),\n",
              " ('uploaded', (64, 1)),\n",
              " ('fix', (64, 1)),\n",
              " ('frustrating', (64, 1)),\n",
              " ('apple', (65, 1)),\n",
              " ('make', (65, 1)),\n",
              " ('bad', (65, 1)),\n",
              " ('charger', (65, 1)),\n",
              " ('genius', (65, 1)),\n",
              " ('say', (65, 1)),\n",
              " ('wrap', (65, 1)),\n",
              " ('electrical', (65, 1)),\n",
              " ('tape', (65, 1)),\n",
              " ('wonder', (65, 1)),\n",
              " ('jony', (65, 1)),\n",
              " ('think', (65, 1)),\n",
              " ('amp', (66, 1)),\n",
              " ('delete', (66, 1)),\n",
              " ('music', (66, 1)),\n",
              " ('customer', (66, 1)),\n",
              " ('ipod', (66, 1)),\n",
              " ('tell', (66, 1)),\n",
              " ('studio', (67, 1)),\n",
              " ('45,000', (67, 1)),\n",
              " ('outlet', (67, 1)),\n",
              " ('computer', (67, 1)),\n",
              " ('need', (67, 1)),\n",
              " ('battery', (67, 1)),\n",
              " ('future', (67, 1)),\n",
              " ('apple', (68, 1)),\n",
              " ('inc', (68, 1)),\n",
              " ('aapl', (68, 1)),\n",
              " ('price', (68, 1)),\n",
              " ('target', (68, 1)),\n",
              " ('eps', (68, 1)),\n",
              " ('estimate', (68, 1)),\n",
              " ('raise', (68, 1)),\n",
              " ('bmo', (68, 1)),\n",
              " ('want', (69, 1)),\n",
              " ('android', (69, 1)),\n",
              " ('apple', (69, 1)),\n",
              " ('torrent?@apple', (69, 1)),\n",
              " ('iphone', (70, 1)),\n",
              " ('ipad', (70, 1)),\n",
              " ('game', (70, 1)),\n",
              " ('2014', (70, 1)),\n",
              " ('apple', (70, 1)),\n",
              " ('name', (70, 1)),\n",
              " ('monument', (70, 1)),\n",
              " ('valley', (70, 1)),\n",
              " ('amp', (70, 1)),\n",
              " ('three', (70, 1)),\n",
              " ('tuesday', (70, 1)),\n",
              " ('december', (70, 1)),\n",
              " ('apple', (71, 1)),\n",
              " ('intraday', (71, 1)),\n",
              " ('comment', (71, 1)),\n",
              " ('pre', (71, 1)),\n",
              " ('opening', (71, 1)),\n",
              " ('premium', (71, 1)),\n",
              " ('user', (71, 1)),\n",
              " ('aapl', (71, 1)),\n",
              " ('stockaction', (71, 1)),\n",
              " ('trading', (71, 1)),\n",
              " ('stock', (71, 1)),\n",
              " ('mkt', (71, 1)),\n",
              " ('apple', (72, 1)),\n",
              " ('great', (72, 1)),\n",
              " ('business', (72, 1)),\n",
              " ('aapl', (72, 1)),\n",
              " ('amazing', (73, 1)),\n",
              " ('customer', (73, 1)),\n",
              " ('service', (73, 1)),\n",
              " ('today', (73, 1)),\n",
              " ('utc', (73, 1)),\n",
              " ('store', (73, 2)),\n",
              " ('work', (73, 1)),\n",
              " ('form', (73, 1)),\n",
              " ('hour', (73, 1)),\n",
              " ('tbjapodcast', (73, 1)),\n",
              " ('aww', (74, 1)),\n",
              " ('look', (74, 1)),\n",
              " ('tht', (74, 1)),\n",
              " ('lot', (74, 1)),\n",
              " ('work', (74, 1)),\n",
              " ('guy', (74, 1)),\n",
              " ('good', (74, 1)),\n",
              " ('luck', (74, 1)),\n",
              " ('kantar', (75, 1)),\n",
              " ('apple', (75, 1)),\n",
              " ('track', (75, 1)),\n",
              " ('record', (75, 1)),\n",
              " ('quarter', (75, 1)),\n",
              " ('iphone6', (75, 1)),\n",
              " ('sale', (75, 1)),\n",
              " ('bump', (75, 1)),\n",
              " ('wednesday', (75, 1)),\n",
              " ('december', (75, 1)),\n",
              " ('iphone', (76, 3)),\n",
              " ('battery', (76, 1)),\n",
              " ('life', (76, 1)),\n",
              " ('take', (76, 1)),\n",
              " ('piss', (76, 1)),\n",
              " ('sort', (76, 1)),\n",
              " ('apple', (76, 1)),\n",
              " ('spy', (77, 1)),\n",
              " ('pair', (77, 1)),\n",
              " ('m50', (77, 1)),\n",
              " ('good', (77, 1)),\n",
              " ('work', (77, 1)),\n",
              " ('product', (78, 1)),\n",
              " ('line', (78, 1)),\n",
              " ('compete', (78, 1)),\n",
              " ('iphone6', (78, 1)),\n",
              " ('vs.', (78, 1)),\n",
              " ('ipad', (78, 2)),\n",
              " ('need', (78, 1)),\n",
              " ('long', (78, 1)),\n",
              " ('dominate', (79, 1)),\n",
              " ('commerce', (79, 1)),\n",
              " ('device', (79, 1)),\n",
              " ('grab', (79, 1)),\n",
              " ('market', (79, 1)),\n",
              " ('share', (79, 1)),\n",
              " ('try', (80, 1)),\n",
              " ('turn', (80, 1)),\n",
              " ('problem', (80, 1)),\n",
              " ('apple', (81, 2)),\n",
              " ('iphone', (81, 1)),\n",
              " ('iphone4s', (81, 1)),\n",
              " ('iphone4problem', (81, 1)),\n",
              " ('fucking', (81, 2)),\n",
              " ('help', (81, 2)),\n",
              " ('work', (81, 1)),\n",
              " ('job', (81, 1)),\n",
              " ('cunt', (81, 1)),\n",
              " ('idk', (82, 1)),\n",
              " ('happend', (82, 1)),\n",
              " ('computer', (83, 1)),\n",
              " ('slow', (83, 1)),\n",
              " ('right', (83, 1)),\n",
              " ('make', (83, 1)),\n",
              " ('want', (83, 1)),\n",
              " ('shoot', (83, 1)),\n",
              " ('god', (83, 1)),\n",
              " ('dam', (83, 1)),\n",
              " ('mac', (83, 1)),\n",
              " ('hav', (83, 1)),\n",
              " ('deal', (83, 1)),\n",
              " ('good', (84, 1)),\n",
              " ('iphone', (84, 1)),\n",
              " ('app', (84, 1)),\n",
              " ('year', (84, 1)),\n",
              " ('accord', (84, 1)),\n",
              " ('computer', (85, 1)),\n",
              " ('science', (85, 1)),\n",
              " ('education', (85, 1)),\n",
              " ('week', (85, 1)),\n",
              " ('come', (85, 1)),\n",
              " ('check', (85, 1)),\n",
              " ('code', (85, 1)),\n",
              " ('opportunity', (85, 1)),\n",
              " ('help', (85, 1)),\n",
              " ('protester', (86, 1)),\n",
              " ('stage', (86, 1)),\n",
              " ('diein', (86, 1)),\n",
              " ('protest', (86, 1)),\n",
              " ('store', (86, 1)),\n",
              " ('nyc', (86, 1)),\n",
              " ('anger', (86, 1)),\n",
              " ('misplace', (86, 1)),\n",
              " ('retweet', (86, 1)),\n",
              " ('agree', (86, 1)),\n",
              " ('apple', (87, 1)),\n",
              " ('recent', (87, 1)),\n",
              " ('pullback', (87, 1)),\n",
              " ('buy', (87, 1)),\n",
              " ('opportunity', (87, 1)),\n",
              " ('aapl', (87, 1)),\n",
              " ('know', (88, 1)),\n",
              " ('fix', (88, 1)),\n",
              " ('xcode', (88, 1)),\n",
              " ('simulator', (88, 1)),\n",
              " ('try', (88, 1)),\n",
              " ('complete', (88, 1)),\n",
              " ('reinstall', (88, 1)),\n",
              " ('ios', (88, 1)),\n",
              " ('real', (89, 1)),\n",
              " ('tired', (89, 1)),\n",
              " ('charger', (89, 1)),\n",
              " ('break', (89, 1)),\n",
              " ('month', (89, 1)),\n",
              " ('protester', (90, 1)),\n",
              " ('stage', (90, 1)),\n",
              " ('diein', (90, 1)),\n",
              " ('protest', (90, 1)),\n",
              " ('store', (90, 1)),\n",
              " ('nyc', (90, 1)),\n",
              " ('anger', (90, 1)),\n",
              " ('misplace', (90, 1)),\n",
              " ('retweet', (90, 1)),\n",
              " ('agree', (90, 1)),\n",
              " ('twitter', (91, 1)),\n",
              " ('fuck', (92, 1)),\n",
              " ('charger', (92, 1)),\n",
              " ('like', (92, 1)),\n",
              " ('shit', (92, 1)),\n",
              " ('apple', (93, 2)),\n",
              " ('warm', (93, 1)),\n",
              " ('social', (93, 2)),\n",
              " ('medium', (93, 2)),\n",
              " ('hire', (93, 1)),\n",
              " ('guru', (93, 1)),\n",
              " ('l.a', (93, 1)),\n",
              " ('finally', (93, 1)),\n",
              " ('tweet?her', (93, 1)),\n",
              " ('thank', (94, 1)),\n",
              " ('good', (94, 1)),\n",
              " ('coverage', (94, 1)),\n",
              " ('nofear', (94, 1)),\n",
              " ('apple', (95, 1)),\n",
              " ('hedge', (95, 1)),\n",
              " ('bet', (95, 1)),\n",
              " ('small', (95, 1)),\n",
              " ('iphone', (95, 1)),\n",
              " ('aapl', (95, 1)),\n",
              " ('aapl', (96, 1)),\n",
              " ('ios8', (96, 1)),\n",
              " ('browser', (96, 1)),\n",
              " ('share', (96, 1)),\n",
              " ('bad', (97, 1)),\n",
              " ('idea', (97, 1)),\n",
              " ('bring', (97, 1)),\n",
              " ('tap', (97, 1)),\n",
              " ('tweet', (97, 1)),\n",
              " ('function', (97, 1)),\n",
              " ('guy', (97, 1)),\n",
              " ('.@apple', (98, 1)),\n",
              " ('ban', (98, 1)),\n",
              " ('school', (98, 1)),\n",
              " ('yik', (98, 1)),\n",
              " ('yak', (98, 1)),\n",
              " ('app', (98, 3)),\n",
              " ('itunes', (98, 1)),\n",
              " ('store', (98, 1)),\n",
              " ('anonymous', (98, 1)),\n",
              " ('bullying', (98, 1)),\n",
              " ('amp', (98, 1)),\n",
              " ('threat', (98, 1)),\n",
              " ('enjoy', (99, 1)),\n",
              " ('introduction', (99, 1)),\n",
              " ('connect', (99, 1)),\n",
              " ('launch', (99, 1)),\n",
              " ('event', (99, 1)),\n",
              " ('amazing', (99, 1)),\n",
              " ('edtech', (99, 1)),\n",
              " ('leader', (99, 1)),\n",
              " ('room', (99, 1)),\n",
              " ('txe', (99, 1)),\n",
              " ('apple', (100, 1)),\n",
              " ('important', (100, 1)),\n",
              " ('stock', (100, 1)),\n",
              " ('earth', (100, 1)),\n",
              " ('aapl', (100, 1)),\n",
              " ('go', (101, 1)),\n",
              " ('come', (101, 1)),\n",
              " ('studio', (102, 1)),\n",
              " ('45,000', (102, 1)),\n",
              " ('outlet', (102, 1)),\n",
              " ('computer', (102, 1)),\n",
              " ('need', (102, 1)),\n",
              " ('battery', (102, 1)),\n",
              " ('future', (102, 1)),\n",
              " ('blackberry', (103, 1)),\n",
              " ('want', (103, 1)),\n",
              " ('iphone', (103, 1)),\n",
              " ('pay', (103, 1)),\n",
              " ('bbry', (104, 2)),\n",
              " ('blackberry', (104, 1)),\n",
              " ('iphone', (104, 1)),\n",
              " ('aapl', (104, 2)),\n",
              " ('iupdate', (105, 1)),\n",
              " ('new', (105, 1)),\n",
              " ('need', (105, 1)),\n",
              " ('dun', (105, 1)),\n",
              " ('year', (105, 1)),\n",
              " ('ago', (105, 1)),\n",
              " ('web', (105, 1)),\n",
              " ('form', (105, 1)),\n",
              " ('phone', (105, 1)),\n",
              " ('ironic', (105, 1)),\n",
              " ('req', (105, 1)),\n",
              " ('support', (105, 1)),\n",
              " ('ie8', (105, 1)),\n",
              " ('asshole', (106, 1)),\n",
              " ('shit', (106, 1)),\n",
              " ('report', (107, 1)),\n",
              " ('apple', (107, 1)),\n",
              " ('hire', (107, 1)),\n",
              " ('fashionista', (107, 1)),\n",
              " ('help', (107, 1)),\n",
              " ('flog', (107, 1)),\n",
              " ('watch', (107, 1)),\n",
              " ('aapl', (107, 2)),\n",
              " ('apple', (108, 1)),\n",
              " ('build', (108, 1)),\n",
              " ('major', (108, 1)),\n",
              " ('new', (108, 1)),\n",
              " ('r&amp;d', (108, 1)),\n",
              " ('facility', (108, 1)),\n",
              " ('japan', (108, 1)),\n",
              " ('prime', (108, 1)),\n",
              " ('minister', (108, 1)),\n",
              " ('reveal', (108, 1)),\n",
              " ('aapl', (108, 2)),\n",
              " ('tim', (109, 1)),\n",
              " ('cook', (109, 1)),\n",
              " ('show', (109, 1)),\n",
              " ('apple', (109, 1)),\n",
              " ('watch', (109, 1)),\n",
              " ('chinese', (109, 1)),\n",
              " ('internet', (109, 1)),\n",
              " ('official', (109, 1)),\n",
              " ('discuss', (109, 1)),\n",
              " ('security', (109, 1)),\n",
              " ('issue', (109, 1)),\n",
              " ('aapl', (109, 1)),\n",
              " ('translate', (110, 1)),\n",
              " ('app', (110, 1)),\n",
              " ('success', (110, 1)),\n",
              " ('story', (110, 1)),\n",
              " ('taus', (110, 1)),\n",
              " ('member', (110, 1)),\n",
              " ('global', (110, 1)),\n",
              " ('lol', (111, 1)),\n",
              " ('quicktime', (111, 1)),\n",
              " ('movs', (111, 1)),\n",
              " ('apple', (112, 1)),\n",
              " ('inc', (112, 2)),\n",
              " ('google', (112, 1)),\n",
              " ('battle', (112, 1)),\n",
              " ('tech', (112, 1)),\n",
              " ('giant', (112, 1)),\n",
              " ('aapl', (112, 1)),\n",
              " ('big', (113, 1)),\n",
              " ('difference', (113, 1)),\n",
              " ('mac', (113, 2)),\n",
              " ('yep', (113, 1)),\n",
              " ('stick', (113, 1)),\n",
              " ('apple', (113, 1)),\n",
              " ('studio', (114, 1)),\n",
              " ('45,000', (114, 1)),\n",
              " ('outlet', (114, 1)),\n",
              " ('computer', (114, 1)),\n",
              " ('need', (114, 1)),\n",
              " ('battery', (114, 1)),\n",
              " ('future', (114, 1)),\n",
              " ('new', (115, 1)),\n",
              " ('4-inch', (115, 1)),\n",
              " ('iphone', (115, 1)),\n",
              " ('report', (115, 1)),\n",
              " ('reason', (115, 1)),\n",
              " ('apple', (115, 1)),\n",
              " ('aapl', (115, 2)),\n",
              " ('office', (116, 1)),\n",
              " ('today', (116, 1)),\n",
              " ('remotesupport', (116, 1)),\n",
              " ('techlife', (116, 1)),\n",
              " ('studio', (117, 1)),\n",
              " ('45,000', (117, 1)),\n",
              " ('outlet', (117, 1)),\n",
              " ('computer', (117, 1)),\n",
              " ('need', (117, 1)),\n",
              " ('battery', (117, 1)),\n",
              " ('future', (117, 1)),\n",
              " ('jmp', (118, 2)),\n",
              " ('raise', (118, 1)),\n",
              " ('apple', (118, 1)),\n",
              " ('price', (118, 1)),\n",
              " ('target', (118, 1)),\n",
              " ('130', (118, 1)),\n",
              " ('150', (118, 1)),\n",
              " ('reason', (118, 1)),\n",
              " ('aapl', (118, 1)),\n",
              " ('stock', (118, 1)),\n",
              " ('wallstreet', (118, 1)),\n",
              " ('protester', (119, 1)),\n",
              " ('stage', (119, 1)),\n",
              " ('diein', (119, 1)),\n",
              " ('protest', (119, 1)),\n",
              " ('store', (119, 1)),\n",
              " ('nyc', (119, 1)),\n",
              " ('anger', (119, 1)),\n",
              " ('misplace', (119, 1)),\n",
              " ('retweet', (119, 1)),\n",
              " ('agree', (119, 1)),\n",
              " ('studio', (120, 1)),\n",
              " ('45,000', (120, 1)),\n",
              " ('outlet', (120, 1)),\n",
              " ('computer', (120, 1)),\n",
              " ('need', (120, 1)),\n",
              " ('battery', (120, 1)),\n",
              " ('future', (120, 1)),\n",
              " ('aapl', (121, 1)),\n",
              " ('alabama', (121, 1)),\n",
              " ('anti', (121, 1)),\n",
              " ('discrimination', (121, 1)),\n",
              " ('bill', (121, 1)),\n",
              " ('name', (121, 1)),\n",
              " ('apple', (121, 1)),\n",
              " ('ceo', (121, 1)),\n",
              " ('tim', (121, 1)),\n",
              " ('cook...http://t.co/j6hgjmjbzd', (121, 1)),\n",
              " ('apple', (122, 1)),\n",
              " ('intraday', (122, 1)),\n",
              " ('comment', (122, 1)),\n",
              " ('pre', (122, 1)),\n",
              " ('opening', (122, 1)),\n",
              " ('premium', (122, 1)),\n",
              " ('user', (122, 1)),\n",
              " ('aapl', (122, 1)),\n",
              " ('stockaction', (122, 1)),\n",
              " ('trading', (122, 1)),\n",
              " ('stock', (122, 1)),\n",
              " ('mkt', (122, 1)),\n",
              " ('result', (123, 1)),\n",
              " ('mobility', (123, 1)),\n",
              " ('pilothouse', (123, 1)),\n",
              " ('program', (123, 1)),\n",
              " ('loyal', (123, 1)),\n",
              " ('customer', (123, 1)),\n",
              " ('aapl', (124, 1)),\n",
              " ('apple', (124, 1)),\n",
              " ('donate', (124, 1)),\n",
              " ('portion', (124, 1)),\n",
              " ('profit', (124, 1)),\n",
              " ('fight', (124, 1)),\n",
              " ('aids...http://t.co/br05n1u3qr', (124, 1)),\n",
              " ('bloombergtv', (125, 1)),\n",
              " ('stevejobs', (125, 1)),\n",
              " ('testimony', (125, 1)),\n",
              " ('play', (125, 1)),\n",
              " ('key', (125, 1)),\n",
              " ('role', (125, 1)),\n",
              " ('ipod', (125, 1)),\n",
              " ('trial', (125, 1)),\n",
              " ('aapl', (125, 1)),\n",
              " ('apple', (126, 1)),\n",
              " ('macbook', (126, 1)),\n",
              " ('949.86', (126, 1)),\n",
              " ('tech', (126, 1)),\n",
              " ('app', (127, 1)),\n",
              " ('ipodtouch5thgen', (127, 1)),\n",
              " ('offensive', (128, 1)),\n",
              " ('thing', (128, 1)),\n",
              " ('lack', (128, 1)),\n",
              " ('trashcan', (128, 1)),\n",
              " ('emoji', (128, 1)),\n",
              " ('stop', (128, 1)),\n",
              " ('discrimination', (128, 1)),\n",
              " ('major', (129, 1)),\n",
              " ('crisis', (129, 1)),\n",
              " ('avoid', (129, 1)),\n",
              " ('guy', (129, 1)),\n",
              " ('able', (129, 1)),\n",
              " ('restore', (129, 1)),\n",
              " ('daughter', (129, 1)),\n",
              " ('iphone', (129, 1)),\n",
              " ('great', (129, 1)),\n",
              " ('service', (129, 1)),\n",
              " ('thank', (129, 1)),\n",
              " ('5starservice', (129, 1)),\n",
              " ('tell', (130, 1)),\n",
              " ('feel', (130, 1)),\n",
              " ('stop', (131, 1)),\n",
              " ('replace', (131, 1)),\n",
              " ('iphone', (131, 1)),\n",
              " ('unit', (131, 1)),\n",
              " ('defect', (131, 1)),\n",
              " ('scratch', (131, 1)),\n",
              " ('phone', (131, 1)),\n",
              " ('mean', (131, 1)),\n",
              " ('drop', (131, 1)),\n",
              " ('live', (132, 1)),\n",
              " ('streaming', (132, 1)),\n",
              " ('blow', (132, 1)),\n",
              " ('jmp', (133, 1)),\n",
              " ('raise', (133, 1)),\n",
              " ('apple', (133, 1)),\n",
              " ('inc', (133, 1)),\n",
              " ('price', (133, 1)),\n",
              " ('target', (133, 1)),\n",
              " ('150', (133, 1)),\n",
              " ('exceptionally', (133, 1)),\n",
              " ('strong', (133, 1)),\n",
              " ('demand', (133, 1)),\n",
              " ('aapl', (133, 1)),\n",
              " ('phone', (134, 1)),\n",
              " ('keep', (134, 1)),\n",
              " ('fuck', (134, 1)),\n",
              " ('freezing', (134, 1)),\n",
              " ('apple', (135, 1)),\n",
              " ('iphone', (135, 1)),\n",
              " ('lead', (135, 1)),\n",
              " ('time', (135, 1)),\n",
              " ('long', (135, 1)),\n",
              " ('previous', (135, 1)),\n",
              " ('model', (135, 1)),\n",
              " ('aapl', (135, 2)),\n",
              " ('sit', (136, 1)),\n",
              " ('home', (136, 1)),\n",
              " ('friday', (136, 1)),\n",
              " ('night', (136, 1)),\n",
              " ('wait', (136, 1)),\n",
              " ('invitation', (136, 1)),\n",
              " ('join', (136, 1)),\n",
              " ('dev', (136, 1)),\n",
              " ('team', (136, 1)),\n",
              " ('look', (136, 1)),\n",
              " ('phone', (136, 1)),\n",
              " ('day', (136, 1)),\n",
              " ('apple', (137, 1)),\n",
              " ('raise', (137, 1)),\n",
              " ('barclay', (137, 1)),\n",
              " ('140.00', (137, 1)),\n",
              " ('overweight', (137, 1)),\n",
              " ('rating', (137, 1)),\n",
              " ('aapl', (137, 2)),\n",
              " ('iphone', (138, 1)),\n",
              " ('come', (138, 1)),\n",
              " ('rareearth', (138, 1)),\n",
              " ('thisn#yosemite', (139, 1)),\n",
              " ...]"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Algoritmo 2: Inverse Document Frecuency (IDF)\n"
      ],
      "metadata": {
        "id": "oUuImAYNrn6N"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Mapeamos los valores de un TF"
      ],
      "metadata": {
        "id": "6wCZ8tjBrquV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "map3 = reduce.map(lambda x: (x[0][1],(x[0][0],x[1],1)))\n",
        "map4 = map3.map(lambda x:(x[0],x[1][2]))\n",
        "reduce2 = map4.reduceByKey(lambda x,y:x+y)\n"
      ],
      "metadata": {
        "id": "ZY8bkQFwrxBX"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Reducimos por la llave"
      ],
      "metadata": {
        "id": "btwvjvLV49Zn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import math\n",
        "from pyspark.sql.functions import *\n",
        "idf = reduce2.map(lambda x: (x[0],math.log10(len(data)/x[1])))\n",
        "# idf.collect()"
      ],
      "metadata": {
        "id": "Q3IRkh97vEbG"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Mostramos el Term Frecuency - Inverse Document Frecuency (TF - IDF)"
      ],
      "metadata": {
        "id": "b1We9bpN5R-q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "rdd = tf.join(idf)\n",
        "rdd1 = rdd.map(lambda x: (x[1][0][0],(x[0],x[1][0][1],x[1][1],x[1][0][1]*x[1][1]))).sortByKey()\n",
        "\n",
        "rdd2 = rdd1.map(lambda x: (x[0],x[1][0],x[1][1],x[1][2],x[1][3]))\n",
        "rdd2.toDF([\"DocumentId\",\"Token\",\"TF\",\"IDF\",\"TF-IDF\"]).show(100)"
      ],
      "metadata": {
        "id": "ieRcL2VbvJFi",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6c7bb37d-8b6a-4b1b-f3e3-3750afabfc19"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----------+-----------------+---+------------------+------------------+\n",
            "|DocumentId|            Token| TF|               IDF|            TF-IDF|\n",
            "+----------+-----------------+---+------------------+------------------+\n",
            "|         1|            stage|  1|1.3798696809532192|1.3798696809532192|\n",
            "|         1|          protest|  1| 1.377146822617746| 1.377146822617746|\n",
            "|         1|            store|  1| 1.105595616949241| 1.105595616949241|\n",
            "|         1|              nyc|  1| 1.353380100659997| 1.353380100659997|\n",
            "|         1|            anger|  1| 1.388142206919209| 1.388142206919209|\n",
            "|         1|         misplace|  1| 1.390935107103379| 1.390935107103379|\n",
            "|         1|          retweet|  1| 1.399423217328898| 1.399423217328898|\n",
            "|         1|        protester|  1| 1.388142206919209| 1.388142206919209|\n",
            "|         1|            diein|  1| 1.399423217328898| 1.399423217328898|\n",
            "|         1|            agree|  1|1.3690792008697128|1.3690792008697128|\n",
            "|         2|           update|  1|1.3937460844372076|1.3937460844372076|\n",
            "|         2|             aapl|  1|0.5944950710074257|0.5944950710074257|\n",
            "|         2|      stockaction|  1|2.0249643045063834|2.0249643045063834|\n",
            "|         2|            apple|  1| 0.578668824553762| 0.578668824553762|\n",
            "|         2|         intraday|  1|1.6270242958343457|1.6270242958343457|\n",
            "|         2|          comment|  1| 2.076116826953765| 2.076116826953765|\n",
            "|         2|            range|  1|2.2195389692560776|2.2195389692560776|\n",
            "|         2|          premium|  1| 2.076116826953765| 2.076116826953765|\n",
            "|         2|             user|  1|1.8178388117107334|1.8178388117107334|\n",
            "|         2|          trading|  1| 1.928054291498327| 1.928054291498327|\n",
            "|         2|            stock|  1| 1.457415164306585| 1.457415164306585|\n",
            "|         2|              mkt|  1| 1.968482948553935| 1.968482948553935|\n",
            "|         3|             2014|  1|1.8330787782674702|1.8330787782674702|\n",
            "|         3|             name|  1|2.1662934573028525|2.1662934573028525|\n",
            "|         3|          elevate|  1|2.4673234529668338|2.4673234529668338|\n",
            "|         3|         training|  1|3.2802368096096894|3.2802368096096894|\n",
            "|         3|              ios|  1|1.7424177145364153|1.7424177145364153|\n",
            "|         3|              app|  2|1.4639955096179063|2.9279910192358125|\n",
            "|         3|            brain|  1| 3.104145550554008| 3.104145550554008|\n",
            "|         3|           iphone|  1|0.9913172039479629|0.9913172039479629|\n",
            "|         4|             shit|  1|1.6891722025831901|1.6891722025831901|\n",
            "|         5|             boss|  1| 3.104145550554008| 3.104145550554008|\n",
            "|         5|          comment|  1| 2.076116826953765| 2.076116826953765|\n",
            "|         5|          founder|  1|2.5812668052736707|2.5812668052736707|\n",
            "|         5|           attack|  1| 2.882296800937652| 2.882296800937652|\n",
            "|         5|       ridiculous|  1| 2.979206813945708| 2.979206813945708|\n",
            "|         5|               ad|  1|2.4351387695954325|2.4351387695954325|\n",
            "|         6|         evidence|  1|2.7361687652594138|2.7361687652594138|\n",
            "|         6|    factcheckthis|  1|3.5812668052736707|3.5812668052736707|\n",
            "|         7|          educate|  1|3.2802368096096894|3.2802368096096894|\n",
            "|         8|            store|  1| 1.105595616949241| 1.105595616949241|\n",
            "|         8|          suicide|  1|3.2802368096096894|3.2802368096096894|\n",
            "|         8|           turkey|  1|3.2802368096096894|3.2802368096096894|\n",
            "|         8|            apple|  1| 0.578668824553762| 0.578668824553762|\n",
            "|         8|             hard|  1|2.3025132043208414|2.3025132043208414|\n",
            "|         8|            reach|  1| 2.678176818281727| 2.678176818281727|\n",
            "|         8|              buy|  1|1.7120350855426945|1.7120350855426945|\n",
            "|         8|            squad|  1|3.5812668052736707|3.5812668052736707|\n",
            "|         8|      comic_strip|  1|3.5812668052736707|3.5812668052736707|\n",
            "|         9|           delete|  1|1.9091689473379532|1.9091689473379532|\n",
            "|         9|            music|  1| 1.928054291498327| 1.928054291498327|\n",
            "|         9|         customer|  1| 1.968482948553935| 1.968482948553935|\n",
            "|         9|             ipod|  1| 1.636784133123502| 1.636784133123502|\n",
            "|        10|           update|  1|1.3937460844372076|1.3937460844372076|\n",
            "|        10|             aapl|  1|0.5944950710074257|0.5944950710074257|\n",
            "|        10|      stockaction|  1|2.0249643045063834|2.0249643045063834|\n",
            "|        10|            apple|  1| 0.578668824553762| 0.578668824553762|\n",
            "|        10|         intraday|  1|1.6270242958343457|1.6270242958343457|\n",
            "|        10|          comment|  1| 2.076116826953765| 2.076116826953765|\n",
            "|        10|            range|  1|2.2195389692560776|2.2195389692560776|\n",
            "|        10|          premium|  1| 2.076116826953765| 2.076116826953765|\n",
            "|        10|             user|  1|1.8178388117107334|1.8178388117107334|\n",
            "|        10|          trading|  1| 1.928054291498327| 1.928054291498327|\n",
            "|        10|            stock|  1| 1.457415164306585| 1.457415164306585|\n",
            "|        10|              mkt|  1| 1.968482948553935| 1.968482948553935|\n",
            "|        11|           45,000|  1| 1.089905111439398| 1.089905111439398|\n",
            "|        11|          battery|  1|1.0347241417955395|1.0347241417955395|\n",
            "|        11|           studio|  1| 1.089905111439398| 1.089905111439398|\n",
            "|        11|           outlet|  1| 1.089905111439398| 1.089905111439398|\n",
            "|        11|         computer|  1|1.0347241417955395|1.0347241417955395|\n",
            "|        11|             need|  1| 0.947798349694084| 0.947798349694084|\n",
            "|        11|           future|  1|1.0614388114979518|1.0614388114979518|\n",
            "|        12|             aapl|  2|0.5944950710074257|1.1889901420148514|\n",
            "|        12|         business|  1|2.4351387695954325|2.4351387695954325|\n",
            "|        12|       investwall|  1|3.5812668052736707|3.5812668052736707|\n",
            "|        12|            apple|  1| 0.578668824553762| 0.578668824553762|\n",
            "|        12|            great|  1|1.8652634616388715|1.8652634616388715|\n",
            "|        13|             love|  1|1.8330787782674702|1.8330787782674702|\n",
            "|        13|           reboot|  1|3.5812668052736707|3.5812668052736707|\n",
            "|        13|           iphone|  2|0.9913172039479629|1.9826344078959257|\n",
            "|        13|            great|  1|1.8652634616388715|1.8652634616388715|\n",
            "|        13|             dear|  1|2.0497878882314153|2.0497878882314153|\n",
            "|        13|             plus|  1|2.0014832086568606|2.0014832086568606|\n",
            "|        13|              lot|  1|2.4351387695954325|2.4351387695954325|\n",
            "|        13|      achievement|  1|3.5812668052736707|3.5812668052736707|\n",
            "|        13|              day|  1|1.9000255678980833|1.9000255678980833|\n",
            "|        13|             fail|  1| 2.259047510539751| 2.259047510539751|\n",
            "|        14|           survey|  1| 2.882296800937652| 2.882296800937652|\n",
            "|        14|         feedback|  1| 3.104145550554008| 3.104145550554008|\n",
            "|        14|           iwatch|  1| 2.627024295834346| 2.627024295834346|\n",
            "|        14|        accessory|  1| 2.979206813945708| 2.979206813945708|\n",
            "|        14|           gadget|  1| 3.104145550554008| 3.104145550554008|\n",
            "|        14|      positioning|  1|3.5812668052736707|3.5812668052736707|\n",
            "|        14|          fashion|  1|2.4351387695954325|2.4351387695954325|\n",
            "|        14|             geek|  1| 3.104145550554008| 3.104145550554008|\n",
            "|        14|          centric|  1|3.5812668052736707|3.5812668052736707|\n",
            "|        15|          similar|  1|2.7361687652594138|2.7361687652594138|\n",
            "|        15|            cloud|  1| 2.979206813945708| 2.979206813945708|\n",
            "|        15|  onlinefootprint|  1|3.5812668052736707|3.5812668052736707|\n",
            "|        15|modicumofprudence|  1|3.5812668052736707|3.5812668052736707|\n",
            "+----------+-----------------+---+------------------+------------------+\n",
            "only showing top 100 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Algoritmo 3: Bolsa de palabras o Bag of Words (BoW)"
      ],
      "metadata": {
        "id": "u5itTTBd-f-7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Importamos la librerías a utilizar\n",
        "from pyspark.sql.functions import explode, split, regexp_replace, col, lower\n",
        "#Data\n",
        "data = [\n",
        "    ['a', 'Jan', 'John', 'This is a document'],\n",
        "    ['b', 'Feb', 'Mary', 'A book by Mary'],\n",
        "    ['c', 'Mar', 'Luke', 'Newspaper article'],\n",
        "    ['d', 'Apr', 'Mark', None]\n",
        "]\n",
        "columns = ['Title', 'Month', 'Author', 'Document']\n",
        "#Creando un data frame df\n",
        "df = spark.createDataFrame(data, columns)\n",
        "#Mostrando el df\n",
        "df.show()\n",
        "#BOG\n",
        "df.select(explode(split(regexp_replace(\"Document\", \"[,.-]\", \" \"), \"\\s+\")).alias(\"word\"))\\\n",
        "    .groupby(lower(col(\"word\")).alias(\"lower\"))\\\n",
        "    .count()\\\n",
        "    .show()"
      ],
      "metadata": {
        "id": "MInNCDGh-J-M",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d0f860ed-6cbc-4a4a-b3de-9bae3dc6fbea"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----+-----+------+------------------+\n",
            "|Title|Month|Author|          Document|\n",
            "+-----+-----+------+------------------+\n",
            "|    a|  Jan|  John|This is a document|\n",
            "|    b|  Feb|  Mary|    A book by Mary|\n",
            "|    c|  Mar|  Luke| Newspaper article|\n",
            "|    d|  Apr|  Mark|              null|\n",
            "+-----+-----+------+------------------+\n",
            "\n",
            "+---------+-----+\n",
            "|    lower|count|\n",
            "+---------+-----+\n",
            "| document|    1|\n",
            "|       by|    1|\n",
            "|newspaper|    1|\n",
            "|  article|    1|\n",
            "|     mary|    1|\n",
            "|       is|    1|\n",
            "|        a|    2|\n",
            "|     this|    1|\n",
            "|     book|    1|\n",
            "+---------+-----+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Algoritmo 4: Tokenizacion"
      ],
      "metadata": {
        "id": "7aGrEf5G_J1E"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.ml.feature import Tokenizer\n",
        "\n",
        "import os.path\n",
        "\n",
        "df = spark.createDataFrame([\n",
        "    (0, '''Sombrero\n",
        "I showed my masterpiece to the grown-ups, and asked them whether the drawing frightened them.\n",
        "But they answered: \"Frighten? Why should any one be frightened by a hat?\"\n",
        "My drawing was not a picture of a hat.\n",
        "It was a picture of a boa constrictor digesting an elephant.\n",
        "But since the grown-ups were not able to understand it, I made another drawing: I drew the inside of a boa constrictor, so that the grown-ups could see it clearly.\n",
        "They always need to have things explained.\n",
        "My Drawing Number Two looked like this:\n",
        "Boa\n",
        "The grown-ups' response, this time, was to advise me to lay aside my drawings of boa constrictors, whether from the inside or the outside, and devote myself instead to geography, history, arithmetic, and grammar.\n",
        "That is why, at the age of six, I gave up what might have been a magnificent career as a painter.''')\n",
        "    ], ['id', 'sentence'])\n",
        "\n",
        "tokenizer = Tokenizer(inputCol=\"sentence\", outputCol=\"words\")\n",
        "tokenized = tokenizer.transform(df)\n",
        "tokenized.select('words').show(truncate=False)"
      ],
      "metadata": {
        "id": "vZ-65cT__Mrg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c24eb580-0937-4907-ed29-b12c11b6a549"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
            "|words                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       |\n",
            "+----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
            "|[sombrero, i, showed, my, masterpiece, to, the, grown-ups,, and, asked, them, whether, the, drawing, frightened, them., but, they, answered:, \"frighten?, why, should, any, one, be, frightened, by, a, hat?\", my, drawing, was, not, a, picture, of, a, hat., it, was, a, picture, of, a, boa, constrictor, digesting, an, elephant., but, since, the, grown-ups, were, not, able, to, understand, it,, i, made, another, drawing:, i, drew, the, inside, of, a, boa, constrictor,, so, that, the, grown-ups, could, see, it, clearly., they, always, need, to, have, things, explained., my, drawing, number, two, looked, like, this:, boa, the, grown-ups', response,, this, time,, was, to, advise, me, to, lay, aside, my, drawings, of, boa, constrictors,, whether, from, the, inside, or, the, outside,, and, devote, myself, instead, to, geography,, history,, arithmetic,, and, grammar., that, is, why,, at, the, age, of, six,, i, gave, up, what, might, have, been, a, magnificent, career, as, a, painter.]|\n",
            "+----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Algoritmo 5: Normalizacion"
      ],
      "metadata": {
        "id": "oREAPK6b_tUI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Importamos la librerías a utilizar\n",
        "from pyspark.ml.feature import Normalizer\n",
        "from pyspark.ml.linalg import Vectors\n",
        "\n",
        "#Crea dataframe\n",
        "dataFrame = spark.createDataFrame([\n",
        "    (0, Vectors.dense([1.0, 0.5, -1.0]),),\n",
        "    (1, Vectors.dense([2.0, 1.0, 1.0]),),\n",
        "    (2, Vectors.dense([4.0, 10.0, 2.0]),)\n",
        "], [\"id\", \"features\"])\n",
        "\n",
        "# Normaliza cada vector usando la Normalizer.\n",
        "normalizer = Normalizer(inputCol=\"features\", outputCol=\"normFeatures\", p=1.0)\n",
        "l1NormData = normalizer.transform(dataFrame)\n",
        "print(\"Normalizando....\")\n",
        "l1NormData.show()"
      ],
      "metadata": {
        "id": "ucrl_dD9_wXH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b4cfc833-51a4-4e6e-d0c4-ef006e6bf941"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Normalizando....\n",
            "+---+--------------+------------------+\n",
            "| id|      features|      normFeatures|\n",
            "+---+--------------+------------------+\n",
            "|  0|[1.0,0.5,-1.0]|    [0.4,0.2,-0.4]|\n",
            "|  1| [2.0,1.0,1.0]|   [0.5,0.25,0.25]|\n",
            "|  2|[4.0,10.0,2.0]|[0.25,0.625,0.125]|\n",
            "+---+--------------+------------------+\n",
            "\n"
          ]
        }
      ]
    }
  ]
}